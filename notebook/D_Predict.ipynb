{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><font size=\"6\">WALOUS</font></strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><font size=\"6\">Fusion LC classifications results</font></strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><font size=\"6\">Predict on tiles</font></strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This python code implement the method developed by ANAGEO (ULB). \n",
    "\n",
    "Code developped on Linux Mint 18.1 (Ubuntu Xenial 16.04) and GRASS GIS 7.3.svn (r71315)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is a Javascript section of code for building the Jupyter notebook's table of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define working environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries needed for setting parameters of operating system \n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import tempfile\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import multiprocessing and functools libraries\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Add folder with SCR provided belong to this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add local module to the path\n",
    "src = os.path.abspath('../SRC')\n",
    "if src not in sys.path:\n",
    "    sys.path.append(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Setup environment variables for TAIS DESKTOP (Linux Mint + GRASS Dev) **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please edit the file in `../SRC/config.py`, containing the configuration parameters, according to your own computer setup. The following cell is used to run this file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run ../SRC/config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputfolder_classifRF_tiles': '../../../Results_V2/Classif_RF/classif_tiles', 'outputfolder_classifRF': '../../../Results_V2/Classif_RF', 'outputfolder_Logfile': '../../../Results_V2/Log_file', 'permanent_mapset': 'PERMANENT', 'outputfolder_training_sample': '../../../Results_V2/Training_sample', 'locationepsg': '31370', 'outputfolder': '../../../Results_V2', 'list_tiles': '../../../Results_V2/list_tiles', 'pixel_classes_list': '../../../Results_V2/pixel_classes_list', 'outputfolder_classifRF_csv': '../../../Results_V2/Classif_RF/classif_csv', 'gisdb': '../../GRASSDATA', 'location': 'WALOUS_31370', 'outputfolder_classfeatures': '../../../Results_V2/Classification_features', 'PYTHONLIB': '/usr/lib/python2.7', 'njobs': 6, 'outputfolder_classifRF_valid': '../../../Results_V2/Classif_RF/test_valid', 'rf_trained_model': '../../../Results_V2/Classif_RF/rf_trained_model.rda', 'GISBASE': '/usr/lib/grass76'}\n"
     ]
    }
   ],
   "source": [
    "print config_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import functions that setup the environmental variables\n",
    "import environ_variables as envi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDMSESSION = mate \t\n",
      "MANDATORY_PATH = /usr/share/gconf/mate.mandatory.path \t\n",
      "MATE_DESKTOP_SESSION_ID = this-is-deprecated \t\n",
      "LESSOPEN = | /usr/bin/lesspipe %s \t\n",
      "MDM_LANG = fr_BE.UTF-8 \t\n",
      "LOGNAME = tais \t\n",
      "USER = tais \t\n",
      "HOME = /home/tais \t\n",
      "XDG_VTNR = 8 \t\n",
      "PATH = /usr/local/bin:/home/tais/BIN:/home/tais/bin:/home/tais/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/grass76/bin:/usr/lib/grass76/script:/usr/lib/grass76/lib \t\n",
      "CLICOLOR = 1 \t\n",
      "DISPLAY = :0.0 \t\n",
      "SSH_AGENT_PID = 1986 \t\n",
      "LANG = fr_BE.UTF-8 \t\n",
      "TERM = xterm-color \t\n",
      "SHELL = /bin/bash \t\n",
      "GIS_LOCK = $$ \t\n",
      "XAUTHORITY = /home/tais/.Xauthority \t\n",
      "SESSION_MANAGER = local/tais-HP-Z620-Workstation:@/tmp/.ICE-unix/1915,unix/tais-HP-Z620-Workstation:/tmp/.ICE-unix/1915 \t\n",
      "SHLVL = 1 \t\n",
      "QT_LINUX_ACCESSIBILITY_ALWAYS_ON = 1 \t\n",
      "INSIDE_CAJA_PYTHON =  \t\n",
      "QT_ACCESSIBILITY = 1 \t\n",
      "LD_LIBRARY_PATH = :/usr/lib/grass76/lib \t\n",
      "COMPIZ_CONFIG_PROFILE = mate \t\n",
      "WINDOWPATH = 8 \t\n",
      "GTK_OVERLAY_SCROLLING = 0 \t\n",
      "PYTHONPATH = :/usr/lib/grass76/etc/python:/usr/lib/grass76/etc/python/grass:/usr/lib/grass76/etc/python/grass/script \t\n",
      "GISBASE = /usr/lib/grass76 \t\n",
      "CLUTTER_BACKEND = x11 \t\n",
      "USERNAME = tais \t\n",
      "XDG_SESSION_DESKTOP = mate \t\n",
      "GDM_XSERVER_LOCATION = local \t\n",
      "XDG_RUNTIME_DIR = /run/user/1000 \t\n",
      "JPY_PARENT_PID = 23668 \t\n",
      "QT_STYLE_OVERRIDE = gtk \t\n",
      "SSH_AUTH_SOCK = /run/user/1000/keyring/ssh \t\n",
      "VTE_VERSION = 4205 \t\n",
      "GDMSESSION = mate \t\n",
      "GISRC = /home/tais/.grass7/rc \t\n",
      "GIT_PAGER = cat \t\n",
      "XDG_CONFIG_DIRS = /etc/xdg/xdg-mate:/etc/xdg \t\n",
      "XDG_CURRENT_DESKTOP = MATE \t\n",
      "XDG_SESSION_ID = c1 \t\n",
      "DBUS_SESSION_BUS_ADDRESS = unix:abstract=/tmp/dbus-Cdbeh7LCdd,guid=a02767871f27bb60d182f0b15cf7a7c8 \t\n",
      "_ = /usr/local/bin/jupyter \t\n",
      "XDG_SESSION_COOKIE = 8441891e86e24d76b9616edf516d5734-1559734215.914737-1689936333 \t\n",
      "DESKTOP_SESSION = mate \t\n",
      "WINDOWID = 77610815 \t\n",
      "LESSCLOSE = /usr/bin/lesspipe %s %s \t\n",
      "DEFAULTS_PATH = /usr/share/gconf/mate.default.path \t\n",
      "MPLBACKEND = module://ipykernel.pylab.backend_inline \t\n",
      "MDM_XSERVER_LOCATION = local \t\n",
      "GTK_MODULES = gail:atk-bridge \t\n",
      "XDG_DATA_DIRS = /usr/share/mate:/usr/local/share/:/usr/share/:/usr/share/mdm/ \t\n",
      "PWD = /media/tais/data/WALOUS/Processing \t\n",
      "COLORTERM = mate-terminal \t\n",
      "PYTHONLIB = /usr/lib/python2.7 \t\n",
      "LS_COLORS = rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36: \t\n",
      "PAGER = cat \t\n",
      "XDG_SEAT = seat0 \t\n"
     ]
    }
   ],
   "source": [
    "# Set environmental variables\n",
    "envi.setup_environmental_variables() \n",
    "# Display current environment variables of your computer\n",
    "envi.print_environmental_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** GRASS GIS Python libraries **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries needed to launch GRASS GIS in the jupyter notebook\n",
    "import grass.script.setup as gsetup\n",
    "# Import libraries needed to call GRASS using Python\n",
    "import grass.script as gscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import function that check existance and create GRASS GIS database folder if needed\n",
    "from grass_database import check_gisdb, check_location, check_mapset, working_mapset\n",
    "# Import functions for processing time information\n",
    "from processing_time import start_processing, print_processing_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function that create a R script for the prediction on the current tile\n",
    "def CreateRScript(tile_cat, r_ncores=2):\n",
    "    import tempfile\n",
    "    # Define names, input and output path... \n",
    "    classif_features = os.path.join(config_parameters['outputfolder_classfeatures'],\"features_tile_%s.csv\"%tile_cat).replace(\"\\\\\", \"/\")\n",
    "    classif_result = os.path.join(config_parameters['outputfolder_classifRF_csv'],\"RF_fusion_tile_%s.csv\"%tile_cat).replace(\"\\\\\", \"/\")\n",
    "    \n",
    "    # Create and open new temporary R script\n",
    "    r_commands = \"%s.R\"%tempfile.mktemp().replace(\"\\\\\", \"/\")\n",
    "    r_file = open(r_commands, 'w')\n",
    "\n",
    "    # Create a list with all lines to write in the script\n",
    "    r_instuction = []\n",
    "\n",
    "    # Piece of R script for intallation of R package\n",
    "    install_package = \"if(!is.element('%s', installed.packages()[,1])){\\n\"\n",
    "    install_package += \"cat('\\\\n\\\\nInstalling %s package from CRAN\\n')\\n\"\n",
    "    install_package += \"if(!file.exists(Sys.getenv('R_LIBS_USER'))){\\n\"\n",
    "    install_package += \"dir.create(Sys.getenv('R_LIBS_USER'), recursive=TRUE)\\n\"\n",
    "    install_package += \".libPaths(Sys.getenv('R_LIBS_USER'))}\\n\"\n",
    "    install_package += \"chooseCRANmirror(ind=1)\\n\"\n",
    "    install_package += \"install.packages('%s', dependencies=TRUE)}\"\n",
    "    r_instuction.append(install_package % ('doParallel', 'doParallel', 'doParallel')) #Package for parallel processing in R\n",
    "    r_instuction.append(install_package % ('caret', 'caret', 'caret')) #Package for machine learning in R\n",
    "    r_instuction.append(install_package % ('e1071', 'e1071', 'e1071')) \n",
    "    r_instuction.append(install_package % ('randomForest', 'randomForest', 'randomForest')) #Package for Random Forest\n",
    "    r_instuction.append(install_package % ('pROC', 'pROC', 'pROC')) \n",
    "\n",
    "    # Piece of R script for loading libraries and dependencies\n",
    "    lib_require = \"library(%s)\\n\"\n",
    "    lib_require += \"require(%s)\"\n",
    "    r_instuction.append(lib_require % ('parallel', 'parallel')) \n",
    "    r_instuction.append(lib_require % ('doParallel', 'doParallel')) \n",
    "    r_instuction.append(lib_require % ('caret', 'caret')) \n",
    "    r_instuction.append(lib_require % ('randomForest', 'randomForest')) \n",
    "    r_instuction.append(lib_require % ('e1071', 'e1071')) \n",
    "    r_instuction.append(lib_require % ('pROC', 'pROC')) \n",
    "\n",
    "    # Set number of cores to use\n",
    "    r_instuction.append(\"# Set number of cores to use\")\n",
    "    r_instuction.append(\"usedcores=%s\"%r_ncores)\n",
    "    #r_instuction.append(\"usedcores=detectCores()-5\")\n",
    "    r_instuction.append(\"registerDoParallel(usedcores)\")\n",
    "\n",
    "    # Import object statistics as dataframe\n",
    "    r_instuction.append(\"# Import object statistics as dataframe\")\n",
    "    r_instuction.append(\"features <- read.csv('%s', sep=',', header=TRUE, row.names=1)\"%classif_features)\n",
    "    \n",
    "    # Load trained RF model\n",
    "    r_instuction.append(\"# Load trained RF model\")\n",
    "    r_instuction.append(\"rfModel <- readRDS('%s')\"%config_parameters['rf_trained_model'].replace(\"\\\\\", \"/\"))\n",
    "   \n",
    "    # Predict class \n",
    "    r_instuction.append(\"# Predict probability of each class\")\n",
    "    r_instuction.append(\"predicted <- data.frame(predict(rfModel, features,type='prob'))\")\n",
    "    r_instuction.append(\"rf_predictions <- data.frame(id=rownames(features), predicted)\")\n",
    "    r_instuction.append(\"names(rf_predictions) <- c('cat_', 'rf_prediction')\")\n",
    "\n",
    "    # Export to csv\n",
    "    r_instuction.append(\"# Export to csv\")\n",
    "    r_instuction.append(\"write.csv(rf_predictions, file='%s', row.names=FALSE, quote=FALSE)\"%classif_result)\n",
    "\n",
    "    # Write instructions to the R script file\n",
    "    r_file.write(\"\\n\".join(r_instuction))\n",
    "    r_file.close()\n",
    "    \n",
    "    # Return the path to the Rscript file\n",
    "    return r_commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def launch_mapset(mapset):\n",
    "    #Declare empty list that will contain the messages to return\n",
    "    return_message = []\n",
    "    # Check if the location exists and create it if not, with the CRS defined by the epsg code \n",
    "    return_message.append(check_location(config_parameters[\"gisdb\"],config_parameters['location'],config_parameters[\"locationepsg\"]))\n",
    "    # Check if mapset exists\n",
    "    return_message.append(check_mapset(config_parameters[\"gisdb\"],config_parameters['location'],mapset))\n",
    "    # Change the current working GRASS GIS session mapset\n",
    "    return_message.append(working_mapset(config_parameters[\"gisdb\"],config_parameters['location'],mapset))\n",
    "    # Return\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetMapsetsAccess():\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        # Add mapsets with input data to the GRASS GIS research path\n",
    "        gscript.run_command('g.mapsets', mapset=\"OBIA\", operation=\"add\")\n",
    "        return_message = \"Access to other mapset added\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Add access to other Mapsets failed. Please check for problem.\"\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DefineComputationRegion(tile_cat):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        return_message = \"Working on tile '%s'\\n\"%tile_cat\n",
    "        gscript.run_command('g.region', raster='segs_tile_%s'%tile_cat)\n",
    "        # Print\n",
    "        return_message += \"--> Computational region and MASK defined\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Setting of computional region failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ReclassWithLabel(tile_cat):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        # Create r.reclass rule file\n",
    "        classif_result = os.path.join(config_parameters['outputfolder_classifRF_csv'],\"RF_fusion_tile_%s.csv\"%tile_cat)\n",
    "        fin = open(classif_result)\n",
    "        reader = csv.reader(fin)\n",
    "        reader.next()\n",
    "        temprulecsv = tempfile.mktemp() # Define the csv output file name\n",
    "        fout = open(temprulecsv, 'w')\n",
    "        for in_row in reader:\n",
    "            fout.write(\"%s=%s\"%(in_row[0],in_row[1]))\n",
    "            fout.write(\"\\n\")\n",
    "        fout.write(\"*=NULL\")\n",
    "        fout.close()\n",
    "        ## Reclass segments raster layer to keep only outliers segments, using the reclas_rule.csv file (create temporary raster)\n",
    "        prediction_raster = 'RfFusion_tile_%s'%tile_cat\n",
    "        gscript.run_command('g.region', overwrite=True, raster='segs_tile_%s'%tile_cat)\n",
    "        gscript.run_command('r.reclass', overwrite=True, input='segs_tile_%s'%tile_cat, \n",
    "                          output=prediction_raster, rules=temprulecsv)\n",
    "        os.remove(temprulecsv)\n",
    "        # Print\n",
    "        return_message += \"--> Segmentation raster reclassed\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Reclassification of segmentation raster failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Colorize(tile_cat):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        gscript.run_command('r.colors', map='RfFusion_tile_%s'%tile_cat, rules=data['color_file'])\n",
    "        return_message += \"--> Colors applied\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Application of colors failed. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ExportTiff(tile_cat):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        export_path = os.path.join(config_parameters['outputfolder_classifRF_tiles'],\"RF_fusion_tile_%s.tif\"%tile_cat)\n",
    "        gscript.run_command('r.out.gdal', overwrite=True, input='RfFusion_tile_%s'%tile_cat,\n",
    "                            output=export_path, format='GTiff', createopt='COMPRESS=DEFLATE')\n",
    "        return_message += \"--> Classified raster exported\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Export of classified raster failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Clean(tile_cat):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        gscript.run_command('g.remove', flags='f', type=\"raster\", name='RfFusion_tile_%s'%tile_cat)\n",
    "        return_message += \"--> Mapset cleaned\"\n",
    "    except:\n",
    "        return_message += \"ERROR: during mapset cleaning. Please check for problem.\"\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetPrediction(tile_cat):\n",
    "    import subprocess\n",
    "    start_tile = start_processing() \n",
    "#    print \"Start processing on tile %s\"%tile_cat\n",
    "    #Declare empty list for saving output messages\n",
    "    output_message = [] \n",
    "\n",
    "    # Create R script\n",
    "    r_commands = CreateRScript(tile_cat, r_ncores=4)\n",
    "    \n",
    "    # Execute R script\n",
    "    message = \"Running R now. Following output is R output.\"\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    try:\n",
    "        subprocess.check_call(['Rscript', r_commands], stderr=subprocess.STDOUT, )\n",
    "    except subprocess.CalledProcessError:\n",
    "        message =  \"There was an error in the execution of the R script.\\nPlease check the R output.\"\n",
    "        output_message.append(message)\n",
    "#        print message\n",
    "    message =  \"Finished running R.\"\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    \n",
    "    # Launch mapset\n",
    "    message = launch_mapset(tile_cat)  \n",
    "    [output_message.append(a) for a in message]\n",
    "#    print \"\\n\".join(message)\n",
    "    \n",
    "    # Allow access to other mapset \n",
    "    message = GetMapsetsAccess()\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    \n",
    "    # Define computional region and mask\n",
    "    message = DefineComputationRegion(tile_cat)\n",
    "    output_message.append(message)\n",
    "#    print message    \n",
    "    \n",
    "    # Reclass \n",
    "    message = ReclassWithLabel(tile_cat)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    \n",
    "    # Colorize \n",
    "    message = Colorize(tile_cat)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "\n",
    "    # Export \n",
    "    message = ExportTiff(tile_cat)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    \n",
    "    # Clean \n",
    "    message = Clean(tile_cat)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "\n",
    "    #Print processing time\n",
    "    message = print_processing_time(start_tile, \"Prediction for tile '%s' achieved in \"%tile_cat)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    \n",
    "    #Export Log file\n",
    "    fout = open(os.path.join(config_parameters['outputfolder_Logfile'],\"Log_Prediction_tile_%s.txt\"%tile_cat),\"w\")\n",
    "    [fout.writelines('%s\\n'%content) for content in output_message]\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import list of tiles from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(config_parameters['list_tiles'], 'rb') as outputfile: \n",
    "    tile_list = pickle.load(outputfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tile_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create exemple of R script for prediction on first tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = os.path.join(config_parameters['outputfolder_classifRF'],\"Fusion_walous_RF_Predict.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_commands = CreateRScript(tile_list[0],r_ncores=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR : An issue occurend when saving a copy of R script for prediction. Please check.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "try:\n",
    "    shutil.copy2(r_commands, output)\n",
    "    print \"Example of R script for prediction was saved on '%s'\"%output\n",
    "except:\n",
    "    print \"ERROR : An issue occurend when saving a copy of R script for prediction. Please check.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using random forest model (R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set number of cores to use\n",
    "ncores = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "not all arguments converted during string formatting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f7f166b2fbc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart_parallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGetPrediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Launch the processes for as many items in the list (if function with a return, the returned results are ordered thanks to 'map' function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    249\u001b[0m         '''\n\u001b[1;32m    250\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mRUN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: not all arguments converted during string formatting"
     ]
    }
   ],
   "source": [
    "# Launch processes in parallel\n",
    "start_parallel = start_processing()\n",
    "p = Pool(ncores)\n",
    "output = p.map(GetPrediction, tile_list[:5])  # Launch the processes for as many items in the list (if function with a return, the returned results are ordered thanks to 'map' function)\n",
    "p.close()\n",
    "p.join()\n",
    "# Print\n",
    "print_processing_time(start_parallel, \"Computation (on %s cores) achieved in \"%ncores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check log file for ERRORS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375 log files in the folder\n"
     ]
    }
   ],
   "source": [
    "# Get list of csv with classification feature of individual tiles\n",
    "import glob\n",
    "list_log = glob.glob(os.path.join(config_parameters['outputfolder_Logfile'],\"Log_Prediction_tile_*.txt\"))\n",
    "print \"%s log files in the folder\"%len(list_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tile(s) faced an ERROR during the processing.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare new counter\n",
    "count = 0\n",
    "# Declare new list that will contain list of tile with error\n",
    "tile_error_list = []\n",
    "# Loop on list of log file\n",
    "for logfile in list_log:\n",
    "    got_error = False\n",
    "    tile_num = os.path.splitext(os.path.basename(logfile))[0].split(\"_\")[-1]\n",
    "    fin = open(logfile, 'r')\n",
    "    for row in fin:\n",
    "        if row[:5] == \"ERROR\":  # If at least one line have error message, the whole file will be counted as 1 error\n",
    "            got_error = True\n",
    "    if got_error:    \n",
    "        count += 1\n",
    "        tile_error_list.append(tile_num)  # Add tile number to the list\n",
    "# Print\n",
    "print \"%s tile(s) faced an ERROR during the processing.\\n\"%count\n",
    "\n",
    "# Update tile list with only tiles that have ERROR in log \n",
    "print \"\\n\".join([\"Error on tile %s\"%(a) for a in tile_error_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create VRT with all tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In GRASS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Work in CLASSIF_VRT\n",
    "launch_mapset(\"CLASSIF_VRT\")  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Allow access to other mapset \n",
    "gscript.run_command('g.mapsets', mapset=','.join(tile_list), operation=\"add\")    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Get a list of individual classifications\n",
    "classif_tiled = gscript.list_strings(type='raster', pattern=\"RfFusion_tile_*\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create virtual raster\n",
    "gscript.run_command('r.buildvrt', overwrite=True, \n",
    "                    input=\",\".join(classif_tiled), \n",
    "                    output='RfFusion_walous')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Colorize\n",
    "gscript.run_command('r.colors', map='RfFusion_walous', rules=data['color_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path for .vrt\n",
    "export_path = os.path.join(config_parameters['outputfolder_classifRF_tiles'],\"RF_fusion_walous.vrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a file with list of tiles\n",
    "tiles_path = glob.glob(os.path.join(config_parameters['outputfolder_classifRF_tiles'],\"RF_fusion_tile_*.tif\"))\n",
    "tmp_file = \"%s_VRT_LIST.txt\"%tempfile.mktemp()\n",
    "with open(tmp_file, 'w') as f:\n",
    "    f.writelines(\"\\n\".join(tiles_path))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create VRT\n",
    "try:\n",
    "    list_argument = ['gdalbuildvrt', '-resolution', 'average', '-input_file_list', tmp_file, export_path]\n",
    "    subprocess.check_call(list_argument, stderr=subprocess.STDOUT, )\n",
    "except subprocess.CalledProcessError:\n",
    "    print \"There was an error in the creation of VRT. Please check.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
