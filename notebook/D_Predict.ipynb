{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><font size=\"6\">WALOUS</font></strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><font size=\"6\">Fusion LC classifications results</font></strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><font size=\"6\">Predict on tiles</font></strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This python code implement the method developed by ANAGEO (ULB). \n",
    "\n",
    "Code developped on Linux Mint 18.1 (Ubuntu Xenial 16.04) and GRASS GIS 7.3.svn (r71315)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is a Javascript section of code for building the Jupyter notebook's table of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define working environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries needed for setting parameters of operating system \n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import tempfile\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import multiprocessing and functools libraries\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Add folder with SCR provided belong to this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add local module to the path\n",
    "src = os.path.abspath('../SRC')\n",
    "if src not in sys.path:\n",
    "    sys.path.append(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Setup environment variables for TAIS DESKTOP (Linux Mint + GRASS Dev) **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please edit the file in `../SRC/config.py`, containing the configuration parameters, according to your own computer setup. The following cell is used to run this file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run ../SRC/config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputfolder_classifRF_tiles': '../../../Results_V2/Classif_RF_All_points/classif_tiles', 'outputfolder_classifRF': '../../../Results_V2/Classif_RF_All_points', 'outputfolder_Logfile': '../../../Results_V2/Log_file', 'permanent_mapset': 'PERMANENT', 'outputfolder_training_sample': '../../../Results_V2/Training_sample', 'locationepsg': '31370', 'outputfolder': '../../../Results_V2', 'list_tiles': '../../../Results_V2/list_tiles', 'pixel_classes_list': '../../../Results_V2/pixel_classes_list', 'outputfolder_classifRF_csv': '../../../Results_V2/Classif_RF_All_points/classif_csv', 'gisdb': '../../GRASSDATA', 'location': 'WALOUS_31370', 'outputfolder_classfeatures': '../../../Results_V2/Classification_features', 'PYTHONLIB': '/usr/bin/python2', 'njobs': 6, 'outputfolder_classifRF_valid': '../../../Results_V2/Classif_RF_All_points/test_valid', 'rf_trained_model': '../../../Results_V2/Classif_RF_All_points/rf_trained_model.rda', 'GISBASE': '/usr/lib/grass76'}\n"
     ]
    }
   ],
   "source": [
    "print config_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import functions that setup the environmental variables\n",
    "import environ_variables as envi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDMSESSION = mate \t\n",
      "MANDATORY_PATH = /usr/share/gconf/mate.mandatory.path \t\n",
      "MATE_DESKTOP_SESSION_ID = this-is-deprecated \t\n",
      "LESSOPEN = | /usr/bin/lesspipe %s \t\n",
      "MDM_LANG = fr_BE.UTF-8 \t\n",
      "LOGNAME = tais \t\n",
      "USER = tais \t\n",
      "HOME = /home/tais \t\n",
      "XDG_VTNR = 8 \t\n",
      "PATH = /usr/local/bin:/home/tais/BIN:/home/tais/bin:/home/tais/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/grass76/bin:/usr/lib/grass76/script:/usr/lib/grass76/lib \t\n",
      "CLICOLOR = 1 \t\n",
      "DISPLAY = :0.0 \t\n",
      "SSH_AGENT_PID = 2018 \t\n",
      "LANG = fr_BE.UTF-8 \t\n",
      "TERM = xterm-color \t\n",
      "SHELL = /bin/bash \t\n",
      "GIS_LOCK = $$ \t\n",
      "XAUTHORITY = /home/tais/.Xauthority \t\n",
      "SESSION_MANAGER = local/tais-HP-Z620-Workstation:@/tmp/.ICE-unix/1946,unix/tais-HP-Z620-Workstation:/tmp/.ICE-unix/1946 \t\n",
      "SHLVL = 1 \t\n",
      "QT_LINUX_ACCESSIBILITY_ALWAYS_ON = 1 \t\n",
      "INSIDE_CAJA_PYTHON =  \t\n",
      "QT_ACCESSIBILITY = 1 \t\n",
      "LD_LIBRARY_PATH = :/usr/lib/grass76/lib \t\n",
      "COMPIZ_CONFIG_PROFILE = mate \t\n",
      "WINDOWPATH = 8 \t\n",
      "GTK_OVERLAY_SCROLLING = 0 \t\n",
      "PYTHONPATH = :/usr/lib/grass76/etc/python:/usr/lib/grass76/etc/python/grass:/usr/lib/grass76/etc/python/grass/script \t\n",
      "GISBASE = /usr/lib/grass76 \t\n",
      "CLUTTER_BACKEND = x11 \t\n",
      "USERNAME = tais \t\n",
      "XDG_SESSION_DESKTOP = mate \t\n",
      "GDM_XSERVER_LOCATION = local \t\n",
      "XDG_RUNTIME_DIR = /run/user/1000 \t\n",
      "JPY_PARENT_PID = 31227 \t\n",
      "QT_STYLE_OVERRIDE = gtk \t\n",
      "SSH_AUTH_SOCK = /run/user/1000/keyring/ssh \t\n",
      "VTE_VERSION = 4205 \t\n",
      "GDMSESSION = mate \t\n",
      "GISRC = /home/tais/.grass7/rc \t\n",
      "GIT_PAGER = cat \t\n",
      "XDG_CONFIG_DIRS = /etc/xdg/xdg-mate:/etc/xdg \t\n",
      "XDG_CURRENT_DESKTOP = MATE \t\n",
      "XDG_SESSION_ID = c1 \t\n",
      "DBUS_SESSION_BUS_ADDRESS = unix:abstract=/tmp/dbus-13LvXlhRYH,guid=2a99a4a7611ab765f04ca0f25d6e1988 \t\n",
      "_ = /usr/local/bin/jupyter \t\n",
      "XDG_SESSION_COOKIE = 8441891e86e24d76b9616edf516d5734-1567496584.624166-218486724 \t\n",
      "DESKTOP_SESSION = mate \t\n",
      "WINDOWID = 54526889 \t\n",
      "LESSCLOSE = /usr/bin/lesspipe %s %s \t\n",
      "DEFAULTS_PATH = /usr/share/gconf/mate.default.path \t\n",
      "MPLBACKEND = module://ipykernel.pylab.backend_inline \t\n",
      "MDM_XSERVER_LOCATION = local \t\n",
      "GTK_MODULES = gail:atk-bridge \t\n",
      "XDG_DATA_DIRS = /usr/share/mate:/usr/local/share/:/usr/share/:/usr/share/mdm/ \t\n",
      "PWD = /media/tais/data/WALOUS/Landcover/Processing/GithubRepository_WALOUS \t\n",
      "COLORTERM = mate-terminal \t\n",
      "PYTHONLIB = /usr/bin/python2 \t\n",
      "LS_COLORS = rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36: \t\n",
      "PAGER = cat \t\n",
      "XDG_SEAT = seat0 \t\n"
     ]
    }
   ],
   "source": [
    "# Set environmental variables\n",
    "envi.setup_environmental_variables() \n",
    "# Display current environment variables of your computer\n",
    "envi.print_environmental_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** GRASS GIS Python libraries **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries needed to launch GRASS GIS in the jupyter notebook\n",
    "import grass.script.setup as gsetup\n",
    "# Import libraries needed to call GRASS using Python\n",
    "import grass.script as gscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import function that check and create folder\n",
    "from mkdir import check_create_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import function that generate a random name in the GRASS GIS environement\n",
    "from random_layer_name import random_layer_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import function that check existance and create GRASS GIS database folder if needed\n",
    "from grass_database import check_gisdb, check_location, check_mapset, working_mapset\n",
    "# Import functions for processing time information\n",
    "from processing_time import start_processing, print_processing_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function that create a R script for the prediction on the current tile\n",
    "def CreateRScript(tile_cat, r_ncores=2):\n",
    "    import tempfile\n",
    "    # Define names, input and output path... \n",
    "    classif_features = os.path.join(config_parameters['outputfolder_classfeatures'],\"features_tile_%s.csv\"%tile_cat).replace(\"\\\\\", \"/\")\n",
    "    classif_result = os.path.join(config_parameters['outputfolder_classifRF_csv'],\"RF_fusion_tile_%s.csv\"%tile_cat).replace(\"\\\\\", \"/\")\n",
    "    \n",
    "    # Create and open new temporary R script\n",
    "    r_commands = \"%s.R\"%tempfile.mktemp().replace(\"\\\\\", \"/\")\n",
    "    r_file = open(r_commands, 'w')\n",
    "\n",
    "    # Create a list with all lines to write in the script\n",
    "    r_instuction = []\n",
    "\n",
    "    # Piece of R script for intallation of R package\n",
    "    install_package = \"if(!is.element('%s', installed.packages()[,1])){\\n\"\n",
    "    install_package += \"cat('\\\\n\\\\nInstalling %s package from CRAN\\n')\\n\"\n",
    "    install_package += \"if(!file.exists(Sys.getenv('R_LIBS_USER'))){\\n\"\n",
    "    install_package += \"dir.create(Sys.getenv('R_LIBS_USER'), recursive=TRUE)\\n\"\n",
    "    install_package += \".libPaths(Sys.getenv('R_LIBS_USER'))}\\n\"\n",
    "    install_package += \"chooseCRANmirror(ind=1)\\n\"\n",
    "    install_package += \"install.packages('%s', dependencies=TRUE)}\"\n",
    "    r_instuction.append(install_package % ('doParallel', 'doParallel', 'doParallel')) #Package for parallel processing in R\n",
    "    r_instuction.append(install_package % ('caret', 'caret', 'caret')) #Package for machine learning in R\n",
    "    r_instuction.append(install_package % ('e1071', 'e1071', 'e1071')) \n",
    "    r_instuction.append(install_package % ('randomForest', 'randomForest', 'randomForest')) #Package for Random Forest\n",
    "    r_instuction.append(install_package % ('pROC', 'pROC', 'pROC')) \n",
    "    r_instuction.append(install_package % ('reticulate', 'reticulate', 'reticulate')) #Package for executing python script directly in Rscript\n",
    "\n",
    "    # Piece of R script for loading libraries and dependencies\n",
    "    lib_require = \"library(%s)\\n\"\n",
    "    lib_require += \"require(%s)\"\n",
    "    r_instuction.append(lib_require % ('parallel', 'parallel')) \n",
    "    r_instuction.append(lib_require % ('doParallel', 'doParallel')) \n",
    "    r_instuction.append(lib_require % ('caret', 'caret')) \n",
    "    r_instuction.append(lib_require % ('randomForest', 'randomForest')) \n",
    "    r_instuction.append(lib_require % ('e1071', 'e1071')) \n",
    "    r_instuction.append(lib_require % ('pROC', 'pROC')) \n",
    "    r_instuction.append(lib_require % ('reticulate', 'reticulate')) \n",
    "\n",
    "    # Set parameter for enabling use of Python function for ERP computation inside of R\n",
    "    r_instuction.append(\"# Set the path to the Python executable file\")\n",
    "    r_instuction.append(\"use_python('%s', required = T)\"%config_parameters['PYTHONLIB'])\n",
    "    r_instuction.append(\"source_python('../SRC/EquivalentReferenceProbability.py')\")\n",
    "                        \n",
    "    # Set number of cores to use\n",
    "    r_instuction.append(\"# Set number of cores to use\")\n",
    "    r_instuction.append(\"usedcores=%s\"%r_ncores)\n",
    "    #r_instuction.append(\"usedcores=detectCores()-5\")\n",
    "    r_instuction.append(\"registerDoParallel(usedcores)\")\n",
    "\n",
    "    # Import object statistics as dataframe\n",
    "    r_instuction.append(\"# Import object statistics as dataframe\")\n",
    "    r_instuction.append(\"features <- read.csv('%s', sep=',', header=TRUE, row.names=1)\"%classif_features)\n",
    "    \n",
    "    # Load trained RF model\n",
    "    r_instuction.append(\"# Load trained RF model\")\n",
    "    r_instuction.append(\"rfModel <- readRDS('%s')\"%config_parameters['rf_trained_model'].replace(\"\\\\\", \"/\"))\n",
    "   \n",
    "    # Predict class probability (SoftProb)\n",
    "    r_instuction.append(\"# Predict probability of each class (SoftProb)\")\n",
    "    r_instuction.append(\"predicted_prob <- data.frame(predict(rfModel, features, type='prob'))\")\n",
    "    r_instuction.append(\"names(predicted_prob) <- substring(names(predicted_prob),2)\")\n",
    "    r_instuction.append(\"colnames(predicted_prob) <- paste('prob', colnames(predicted_prob), sep = '_')\")\n",
    "    # Export class prob to csv\n",
    "    r_instuction.append(\"# Export class prob to csv\")\n",
    "    r_instuction.append(\"path_tmp_csv <- tempfile(pattern = 'file', tmpdir = tempdir(), fileext = '.csv')\")\n",
    "    r_instuction.append(\"write.csv(predicted_prob, file=path_tmp_csv, row.names=TRUE, quote=FALSE)\")\n",
    "                        \n",
    "    # Compute ERP using dedicated Python function \n",
    "    r_instuction.append(\"# Compute ERP (Equivalent Reference Probability) using Python function\")\n",
    "    r_instuction.append(\"path_tmp_csv_ERP = ComputeERPfromCsv(path_tmp_csv, delimiter=',', erp_name='ERP', start_index=1L, stop_index=FALSE)\")\n",
    "    r_instuction.append(\"predicted_prob_ERP <- read.csv(path_tmp_csv_ERP, sep=',', header=TRUE, row.names=1)\")\n",
    "    \n",
    "    # Predict class label (SoftMAX)\n",
    "    r_instuction.append(\"# Predict label (SoftMAX)\")    \n",
    "    r_instuction.append(\"predicted_label <- data.frame(predict(rfModel, features))\")\n",
    "    r_instuction.append(\"names(predicted_label) <- 'rf_label'\")\n",
    "    \n",
    "    # Merge all results in one final dataframe\n",
    "    r_instuction.append(\"# Merge probabilities and label in final dataframe\")\n",
    "    r_instuction.append(\"rf_predictions <- data.frame(cat_=rownames(features), predicted_prob_ERP, predicted_label)\")\n",
    "\n",
    "    # Export final result to csv\n",
    "    r_instuction.append(\"# Export final result to csv\")\n",
    "    r_instuction.append(\"write.csv(rf_predictions, file='%s', row.names=FALSE, quote=FALSE)\"%classif_result)\n",
    "\n",
    "    # Write instructions to the R script file\n",
    "    r_file.write(\"\\n\".join(r_instuction))\n",
    "    r_file.close()\n",
    "    \n",
    "    # Return the path to the Rscript file\n",
    "    return r_commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def launch_mapset(mapset):\n",
    "    #Declare empty list that will contain the messages to return\n",
    "    return_message = []\n",
    "    # Check if the location exists and create it if not, with the CRS defined by the epsg code \n",
    "    return_message.append(check_location(config_parameters[\"gisdb\"],config_parameters['location'],config_parameters[\"locationepsg\"]))\n",
    "    # Check if mapset exists\n",
    "    return_message.append(check_mapset(config_parameters[\"gisdb\"],config_parameters['location'],mapset))\n",
    "    # Change the current working GRASS GIS session mapset\n",
    "    return_message.append(working_mapset(config_parameters[\"gisdb\"],config_parameters['location'],mapset))\n",
    "    # Return\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetMapsetsAccess():\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        # Add mapsets with input data to the GRASS GIS research path\n",
    "        gscript.run_command('g.mapsets', mapset=\"OBIA\", operation=\"add\")\n",
    "        return_message = \"Access to other mapset added\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Add access to other Mapsets failed. Please check for problem.\"\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DefineComputationRegion(tile_cat):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        return_message = \"Working on tile '%s'\\n\"%tile_cat\n",
    "        gscript.run_command('g.region', raster='segs_tile_%s'%tile_cat)\n",
    "        # Print\n",
    "        return_message += \"--> Computational region and MASK defined\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Setting of computional region failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ReclassWithPropsERPLabel(tile_cat):\n",
    "    global list_rast_fusion\n",
    "    list_rast_fusion = []\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        # Read the header of the CSV file with results from R\n",
    "        classif_result = os.path.join(config_parameters['outputfolder_classifRF_csv'],\"RF_fusion_tile_%s.csv\"%tile_cat)\n",
    "        fin = open(classif_result)\n",
    "        reader = csv.reader(fin)\n",
    "        header = reader.next()\n",
    "        \n",
    "        # Recode or reclass segments according to R outputs (probabilities, ERP and label)\n",
    "        for i,col in enumerate(header):\n",
    "            if col == header[0]: #Skip first colunm with 'cat_'\n",
    "                continue\n",
    "            reader = csv.reader(open(classif_result))\n",
    "            reader.next() #Skip the header\n",
    "            #Only if current loop is related to the last columns (label in Integer)\n",
    "            if col == header[-1]: \n",
    "                temprulecsv = tempfile.mktemp() # Define the csv output file name\n",
    "                fout = open(temprulecsv, 'w')\n",
    "                for in_row in reader:\n",
    "                    fout.write(\"%s=%s\"%(in_row[0],in_row[i]))\n",
    "                    fout.write(\"\\n\")\n",
    "                fout.write(\"*=NULL\")\n",
    "                fout.close()\n",
    "                ## Reclass segments raster layer to keep only outliers segments, using the reclas_rule.csv file (create temporary raster)\n",
    "                prediction_raster = 'Fusion_%s'%col\n",
    "                list_rast_fusion.append(prediction_raster)\n",
    "                gscript.run_command('g.region', overwrite=True, raster='segs_tile_%s'%tile_cat)\n",
    "                gscript.run_command('r.reclass', overwrite=True, input='segs_tile_%s'%tile_cat, \n",
    "                                  output=prediction_raster, rules=temprulecsv)\n",
    "                os.remove(temprulecsv)            \n",
    "            \n",
    "            #For all the other columns (probs and ERP in float)\n",
    "            else: \n",
    "                temprulecsv = tempfile.mktemp() #Define the csv output file name\n",
    "                fout = open(temprulecsv, 'w')\n",
    "                for in_row in reader:\n",
    "                    fout.write(\"%s=%s\"%(in_row[0],float(in_row[i])*10000))  #Multiply by 10.000 because r.recode support only integers (will round the value of the rule)\n",
    "                    fout.write(\"\\n\")\n",
    "                fout.close()\n",
    "                ## Reclass segments raster layer to keep only outliers segments, using the reclas_rule.csv file (create temporary raster)\n",
    "                gscript.run_command('g.region', overwrite=True, raster='segs_tile_%s'%tile_cat)\n",
    "                tmp_raster = random_layer_name()\n",
    "                gscript.run_command('r.reclass', overwrite=True, input='segs_tile_%s'%tile_cat, \n",
    "                                  output=tmp_raster, rules=temprulecsv)\n",
    "                prediction_raster = 'Fusion_%s'%col\n",
    "                list_rast_fusion.append(prediction_raster)\n",
    "                formula = \"%s=%s/10000.0\"%(prediction_raster,tmp_raster) #Divide by 10.000 to have the initial float value rounded at the 4th decimal (O.XXXX)\n",
    "                gscript.mapcalc(formula, overwrite=True)\n",
    "                gscript.run_command('g.remove', flags='f', type=\"raster\", name=tmp_raster)\n",
    "                os.remove(temprulecsv)\n",
    "        # Print\n",
    "        return_message += \"--> Segmentation raster reclassed\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Reclassification of segmentation raster failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Colorize(tile_cat):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        gscript.run_command('r.colors', map='Fusion_rf_label', rules=data['color_file'])\n",
    "        gscript.run_command('r.colors', flags='e', map='Fusion_ERP', color='viridis')\n",
    "        return_message += \"--> Colors applied\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Application of colors failed for tile %s. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Export only the label of the RF classification (majority class)\n",
    "\"\"\"\n",
    "def ExportTiff(tile_cat):\n",
    "    global list_rast_fusion\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        export_path = os.path.join(config_parameters['outputfolder_classifRF_tiles'],\"RF_fusion_tile_%s.tif\"%tile_cat)\n",
    "        # Export the group as a .tif file\n",
    "        gscript.run_command('r.out.gdal', quiet=True, overwrite=True, flags='m', input=\"Fusion_rf_label\", output=export_path,\n",
    "                            format='GTiff', createopt='COMPRESS=DEFLATE') #Use flag c to not export colortable. Flag m to not export non-standard format of meta-data\n",
    "        return_message += \"--> Classified raster exported\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Export of classified raster failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Export all the ouput of RF classification (probabilities, ERP and majority class \"Label\")\n",
    "\"\"\"\n",
    "\n",
    "def ExportTiffProbs(tile_cat):\n",
    "    global list_rast_fusion\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        export_path = os.path.join(config_parameters['outputfolder_classifRF_tiles_probs'],\"Prob_RF_fusion_tile_%s.tif\"%tile_cat)\n",
    "        # Create a group in GRASS GIS with the layers to be exported\n",
    "        gscript.run_command('i.group', overwrite=True, group='Export', input=','.join(list_rast_fusion))\n",
    "        # Export the group as a .tif file\n",
    "        gscript.run_command('r.out.gdal', quiet=True, overwrite=True, flags='cm', input='Export', output=export_path,\n",
    "                            format='GTiff', createopt='COMPRESS=DEFLATE') #Flag c to not export colortable. Flag m to not export non-standard format of meta-data\n",
    "        return_message += \"--> Classified raster exported\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Export of classified raster failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Clean(tile_cat):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        for layer in list_rast_fusion:\n",
    "            gscript.run_command('g.remove', flags='f', type=\"raster\", name=layer)\n",
    "        return_message += \"--> Mapset cleaned\"\n",
    "    except:\n",
    "        return_message += \"ERROR: during mapset cleaning. Please check for problem.\"\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetPrediction(tile_cat):\n",
    "    import subprocess\n",
    "    start_tile = start_processing() \n",
    "#    print \"Start processing on tile %s\"%tile_cat\n",
    "    #Declare empty list for saving output messages\n",
    "    output_message = [] \n",
    "\n",
    "    # Create R script\n",
    "    r_commands = CreateRScript(tile_cat, r_ncores=4)\n",
    "    \n",
    "    # Execute R script\n",
    "    message = \"Running R now. Following output is R output.\"\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    try:\n",
    "        subprocess.check_call(['Rscript', r_commands], stderr=subprocess.STDOUT, )\n",
    "    except subprocess.CalledProcessError:\n",
    "        message =  \"There was an error in the execution of the R script.\\nPlease check the R output.\"\n",
    "        output_message.append(message)\n",
    "#        print message\n",
    "    message =  \"Finished running R.\"\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    \n",
    "    # Launch mapset\n",
    "    message = launch_mapset(tile_cat)  \n",
    "    [output_message.append(a) for a in message]\n",
    "#    print \"\\n\".join(message)\n",
    "    \n",
    "    # Allow access to other mapset \n",
    "    message = GetMapsetsAccess()\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    \n",
    "    # Define computional region and mask\n",
    "    message = DefineComputationRegion(tile_cat)\n",
    "    output_message.append(message)\n",
    "#    print message    \n",
    "    \n",
    "    # Reclass with classification probabilities, ERP and labels\n",
    "    message = ReclassWithPropsERPLabel(tile_cat)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    \n",
    "    # Colorize \n",
    "    message = Colorize(tile_cat)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "\n",
    "    # Export \n",
    "    message = ExportTiff(tile_cat)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "\n",
    "    # Export \n",
    "    message = ExportTiffProbs(tile_cat)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    \n",
    "    # Clean \n",
    "    #message = Clean(tile_cat)\n",
    "    #output_message.append(message)\n",
    "#    print message\n",
    "\n",
    "    #Print processing time\n",
    "    message = print_processing_time(start_tile, \"Prediction for tile '%s' achieved in \"%tile_cat)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    \n",
    "    #Export Log file\n",
    "    fout = open(os.path.join(config_parameters['outputfolder_Logfile'],\"Log_Prediction_tile_%s.txt\"%tile_cat),\"w\")\n",
    "    [fout.writelines('%s\\n'%content) for content in output_message]\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder '../../../Results_V2/Classif_RF_All_points' already exists\n",
      "The folder '../../../Results_V2/Classif_RF_All_points/classif_csv' already exists\n",
      "The folder '../../../Results_V2/Classif_RF_All_points/classif_tiles' already exists\n"
     ]
    }
   ],
   "source": [
    "# Check and create folder if needed\n",
    "check_create_dir(config_parameters['outputfolder_classifRF'])\n",
    "check_create_dir(config_parameters['outputfolder_classifRF_csv'])\n",
    "check_create_dir(config_parameters['outputfolder_classifRF_tiles'])\n",
    "check_create_dir(config_parameters['outputfolder_classifRF_tiles_probs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import list of tiles from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(config_parameters['list_tiles'], 'rb') as outputfile: \n",
    "    tile_list = pickle.load(outputfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tile_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create exemple of R script for prediction on first tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = os.path.join(config_parameters['outputfolder_classifRF'],\"Fusion_walous_RF_Predict.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_commands = CreateRScript(tile_list[0],r_ncores=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of R script for prediction was saved on '../../../Results_V2/Classif_RF_All_points/Fusion_walous_RF_Predict.R'\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "try:\n",
    "    shutil.copy2(r_commands, output)\n",
    "    print \"Example of R script for prediction was saved on '%s'\"%output\n",
    "except:\n",
    "    print \"ERROR : An issue occurend when saving a copy of R script for prediction. Please check.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using random forest model (R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set number of cores to use\n",
    "ncores = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'5787'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_list[tile_list.index(\"5787\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Launch processes in parallel\n",
    "GetPrediction(tile_list[tile_list.index(\"5787\")])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Launch processes in parallel\n",
    "start_parallel = start_processing()\n",
    "p = Pool(ncores)\n",
    "output = p.map(GetPrediction, tile_list[:])  # Launch the processes for as many items in the list (if function with a return, the returned results are ordered thanks to 'map' function)\n",
    "p.close()\n",
    "p.join()\n",
    "# Print\n",
    "print_processing_time(start_parallel, \"Computation (on %s cores) achieved in \"%ncores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check log file for ERRORS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375 log files in the folder\n"
     ]
    }
   ],
   "source": [
    "# Get list of csv with classification feature of individual tiles\n",
    "import glob\n",
    "list_log = glob.glob(os.path.join(config_parameters['outputfolder_Logfile'],\"Log_Prediction_tile_*.txt\"))\n",
    "print \"%s log files in the folder\"%len(list_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tile(s) faced an ERROR during the processing.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare new counter\n",
    "count = 0\n",
    "# Declare new list that will contain list of tile with error\n",
    "tile_error_list = []\n",
    "# Loop on list of log file\n",
    "for logfile in list_log:\n",
    "    got_error = False\n",
    "    tile_num = os.path.splitext(os.path.basename(logfile))[0].split(\"_\")[-1]\n",
    "    fin = open(logfile, 'r')\n",
    "    for row in fin:\n",
    "        if row[:5] == \"ERROR\":  # If at least one line have error message, the whole file will be counted as 1 error\n",
    "            got_error = True\n",
    "    if got_error:    \n",
    "        count += 1\n",
    "        tile_error_list.append(tile_num)  # Add tile number to the list\n",
    "# Print\n",
    "print \"%s tile(s) faced an ERROR during the processing.\\n\"%count\n",
    "\n",
    "# Update tile list with only tiles that have ERROR in log \n",
    "print \"\\n\".join([\"Error on tile %s\"%(a) for a in tile_error_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create VRT with all tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path for .vrt\n",
    "export_path = os.path.join(config_parameters['outputfolder_classifRF_tiles'],\"RF_fusion_walous.vrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a file with list of tiles\n",
    "tiles_path = glob.glob(os.path.join(config_parameters['outputfolder_classifRF_tiles'],\"RF_fusion_tile_*.tif\"))\n",
    "tmp_file = \"%s_VRT_LIST.txt\"%tempfile.mktemp()\n",
    "with open(tmp_file, 'w') as f:\n",
    "    f.writelines(\"\\n\".join(tiles_path))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create VRT\n",
    "try:\n",
    "    list_argument = ['gdalbuildvrt', '-resolution', 'average', '-input_file_list', tmp_file, export_path]\n",
    "    subprocess.check_call(list_argument, stderr=subprocess.STDOUT, )\n",
    "except subprocess.CalledProcessError:\n",
    "    print \"There was an error in the creation of VRT. Please check.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Band 11 only (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path for .vrt\n",
    "export_path = os.path.join(config_parameters['outputfolder_classifRF_tiles'],\"RF_fusion_walous_label.vrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a file with list of tiles\n",
    "tiles_path = glob.glob(os.path.join(config_parameters['outputfolder_classifRF_tiles'],\"RF_fusion_tile_*.tif\"))\n",
    "tmp_file = \"%s_VRT_LIST.txt\"%tempfile.mktemp()\n",
    "with open(tmp_file, 'w') as f:\n",
    "    f.writelines(\"\\n\".join(tiles_path))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create VRT\n",
    "try:\n",
    "    list_argument = ['gdalbuildvrt', '-b', '11', '-resolution', 'average', '-input_file_list', tmp_file, export_path]\n",
    "    subprocess.check_call(list_argument, stderr=subprocess.STDOUT, )\n",
    "except subprocess.CalledProcessError:\n",
    "    print \"There was an error in the creation of VRT. Please check.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
