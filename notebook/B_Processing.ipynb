{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><font size=\"6\">WALOUS</font></strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><font size=\"6\">Fusion LC classifications results</font></strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><font size=\"6\">Compute feature statistics</font></strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This python code implement the method developed by ANAGEO (ULB). \n",
    "\n",
    "Code developped on Linux Mint 18.1 (Ubuntu Xenial 16.04) and GRASS GIS 7.3.svn (r71315)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is a Javascript section of code for building the Jupyter notebook's table of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define working environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries needed for setting parameters of operating system \n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import tempfile\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import multiprocessing and functools libraries\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Add folder with SCR provided belong to this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add local module to the path\n",
    "src = os.path.abspath('../SRC')\n",
    "if src not in sys.path:\n",
    "    sys.path.append(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Setup environment variables for TAIS DESKTOP (Linux Mint + GRASS Dev) **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please edit the file in `../SRC/config.py`, containing the configuration parameters, according to your own computer setup. The following cell is used to run this file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run ../SRC/config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputfolder_classifRF_tiles': '../../../Results/Classif_RF/classif_tiles', 'outputfolder_classifRF': '../../../Results/Classif_RF', 'outputfolder_Logfile': '../../../Results/Log_file', 'permanent_mapset': 'PERMANENT', 'outputfolder_training_sample': '../../../Results/Training_sample', 'locationepsg': '31370', 'outputfolder': '../../../Results', 'list_tiles': '../../../Results/list_tiles', 'pixel_classes_list': '../../../Results/pixel_classes_list', 'outputfolder_classifRF_csv': '../../../Results/Classif_RF/classif_csv', 'gisdb': '../../GRASSDATA', 'location': 'WALOUS_31370', 'outputfolder_classfeatures': '../../../Results/Classification_features', 'PYTHONLIB': '/usr/lib/python2.7', 'njobs': 6, 'rf_trained_model': '../../../Results/Classif_RF/rf_trained_model.rda', 'GISBASE': '/usr/lib/grass76'}\n"
     ]
    }
   ],
   "source": [
    "print config_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import functions that setup the environmental variables\n",
    "import environ_variables as envi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDMSESSION = mate \t\n",
      "MANDATORY_PATH = /usr/share/gconf/mate.mandatory.path \t\n",
      "MATE_DESKTOP_SESSION_ID = this-is-deprecated \t\n",
      "LESSOPEN = | /usr/bin/lesspipe %s \t\n",
      "MDM_LANG = fr_BE.UTF-8 \t\n",
      "LOGNAME = tais \t\n",
      "USER = tais \t\n",
      "HOME = /home/tais \t\n",
      "XDG_VTNR = 8 \t\n",
      "PATH = /usr/local/bin:/home/tais/BIN:/home/tais/bin:/home/tais/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/grass76/bin:/usr/lib/grass76/script:/usr/lib/grass76/lib \t\n",
      "CLICOLOR = 1 \t\n",
      "DISPLAY = :0.0 \t\n",
      "SSH_AGENT_PID = 1986 \t\n",
      "LANG = fr_BE.UTF-8 \t\n",
      "TERM = xterm-color \t\n",
      "SHELL = /bin/bash \t\n",
      "GIS_LOCK = $$ \t\n",
      "XAUTHORITY = /home/tais/.Xauthority \t\n",
      "SESSION_MANAGER = local/tais-HP-Z620-Workstation:@/tmp/.ICE-unix/1915,unix/tais-HP-Z620-Workstation:/tmp/.ICE-unix/1915 \t\n",
      "SHLVL = 1 \t\n",
      "QT_LINUX_ACCESSIBILITY_ALWAYS_ON = 1 \t\n",
      "INSIDE_CAJA_PYTHON =  \t\n",
      "QT_ACCESSIBILITY = 1 \t\n",
      "LD_LIBRARY_PATH = :/usr/lib/grass76/lib \t\n",
      "COMPIZ_CONFIG_PROFILE = mate \t\n",
      "WINDOWPATH = 8 \t\n",
      "GTK_OVERLAY_SCROLLING = 0 \t\n",
      "PYTHONPATH = :/usr/lib/grass76/etc/python:/usr/lib/grass76/etc/python/grass:/usr/lib/grass76/etc/python/grass/script \t\n",
      "GISBASE = /usr/lib/grass76 \t\n",
      "CLUTTER_BACKEND = x11 \t\n",
      "USERNAME = tais \t\n",
      "XDG_SESSION_DESKTOP = mate \t\n",
      "GDM_XSERVER_LOCATION = local \t\n",
      "XDG_RUNTIME_DIR = /run/user/1000 \t\n",
      "JPY_PARENT_PID = 3539 \t\n",
      "QT_STYLE_OVERRIDE = gtk \t\n",
      "SSH_AUTH_SOCK = /run/user/1000/keyring/ssh \t\n",
      "VTE_VERSION = 4205 \t\n",
      "GDMSESSION = mate \t\n",
      "GISRC = /home/tais/.grass7/rc \t\n",
      "GIT_PAGER = cat \t\n",
      "XDG_CONFIG_DIRS = /etc/xdg/xdg-mate:/etc/xdg \t\n",
      "XDG_CURRENT_DESKTOP = MATE \t\n",
      "XDG_SESSION_ID = c1 \t\n",
      "DBUS_SESSION_BUS_ADDRESS = unix:abstract=/tmp/dbus-Cdbeh7LCdd,guid=a02767871f27bb60d182f0b15cf7a7c8 \t\n",
      "_ = /usr/local/bin/jupyter \t\n",
      "XDG_SESSION_COOKIE = 8441891e86e24d76b9616edf516d5734-1559734215.914737-1689936333 \t\n",
      "DESKTOP_SESSION = mate \t\n",
      "WINDOWID = 79691782 \t\n",
      "LESSCLOSE = /usr/bin/lesspipe %s %s \t\n",
      "DEFAULTS_PATH = /usr/share/gconf/mate.default.path \t\n",
      "MPLBACKEND = module://ipykernel.pylab.backend_inline \t\n",
      "MDM_XSERVER_LOCATION = local \t\n",
      "GTK_MODULES = gail:atk-bridge \t\n",
      "XDG_DATA_DIRS = /usr/share/mate:/usr/local/share/:/usr/share/:/usr/share/mdm/ \t\n",
      "PWD = /media/tais/data/WALOUS/Processing \t\n",
      "COLORTERM = mate-terminal \t\n",
      "PYTHONLIB = /usr/lib/python2.7 \t\n",
      "LS_COLORS = rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36: \t\n",
      "PAGER = cat \t\n",
      "XDG_SEAT = seat0 \t\n"
     ]
    }
   ],
   "source": [
    "# Set environmental variables\n",
    "envi.setup_environmental_variables() \n",
    "# Display current environment variables of your computer\n",
    "envi.print_environmental_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** GRASS GIS Python libraries **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries needed to launch GRASS GIS in the jupyter notebook\n",
    "import grass.script.setup as gsetup\n",
    "# Import libraries needed to call GRASS using Python\n",
    "import grass.script as gscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Other functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import function that check existance and create GRASS GIS database folder if needed\n",
    "from grass_database import check_gisdb, check_location, check_mapset, working_mapset\n",
    "# Import functions for processing time information\n",
    "from processing_time import start_processing, print_processing_time\n",
    "# Import function that generate a random name in the GRASS GIS environement\n",
    "from random_layer_name import random_layer_name\n",
    "# Import function that check and create folder\n",
    "from mkdir import check_create_dir\n",
    "# Import function that check if GRASS GIS add-on is installed and install it if needed\n",
    "from gextension import check_install_addon\n",
    "# Import function for .gzip archive management\n",
    "from gzip_management import decompress_gzip\n",
    "# Import function for computation of proportion of categorical raster in zones (segments)\n",
    "from compute_proportion_categorical import CategoStats\n",
    "# Import function for getting list of class of a raster\n",
    "from data_prep import data_prep\n",
    "# Import function the allow sorting strings with number as if they was number (natural order)\n",
    "from sorting_natural import natural_keys\n",
    "# Import function that compute ERP on csv file\n",
    "from EquivalentReferenceProbability import ComputeERPfromCsv\n",
    "# Import function that replace \"empty\" values from output .csv to zero\n",
    "from CsvEmptyValues import CsvChangeEmptyByO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def launch_mapset(mapset):\n",
    "    #Declare empty list that will contain the messages to return\n",
    "    return_message = []\n",
    "    # Check if the location exists and create it if not, with the CRS defined by the epsg code \n",
    "    return_message.append(check_location(config_parameters[\"gisdb\"],config_parameters['location'],config_parameters[\"locationepsg\"]))\n",
    "    # Check if mapset exists\n",
    "    return_message.append(check_mapset(config_parameters[\"gisdb\"],config_parameters['location'],mapset))\n",
    "    # Change the current working GRASS GIS session mapset\n",
    "    return_message.append(working_mapset(config_parameters[\"gisdb\"],config_parameters['location'],mapset))\n",
    "    # Return\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetMapsetsAccess():\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        # Add mapsets with input data to the GRASS GIS research path\n",
    "        gscript.run_command('g.mapsets', mapset=\"BINARIES,OBIA,PIXEL_ORTHO_LC,PIXEL_SENTINEL\", operation=\"add\")\n",
    "        return_message = \"Access to other mapset added\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Add access to other Mapsets failed. Please check for problem.\"\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DefineComputationRegion(tile_cat):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        return_message = \"Working on tile '%s'\\n\"%tile_cat\n",
    "        # Extract the cutline polygon to work on\n",
    "        condition = 'cat=%s'%tile_cat\n",
    "        gscript.run_command('v.extract', overwrite=True, input='tiles', where=condition, output='tmp_tile')\n",
    "        # Define computational region based on this polygon\n",
    "        gscript.run_command('g.region', raster='segmentation') # To get resolution of segmentation \n",
    "        gscript.run_command('g.region', flags='a', vector='tmp_tile') # Keep resolution but change extent\n",
    "        # Mask according to this polygon\n",
    "        gscript.run_command('r.mask', overwrite=True, vector='tmp_tile')\n",
    "        # Copy the mask layer\n",
    "        gscript.run_command('g.copy', overwrite=True, raster='MASK,mask_copy')\n",
    "        # Print\n",
    "        return_message += \"--> Computational region and MASK defined\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Setting of computional region and MASK failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetObiaAttributes(tile_cat):    \n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:   \n",
    "        # Decompress and import attribute table of segments of the current tile\n",
    "        in_path = os.path.join(data['obia_folder'],'CLASSIF','walous_2018_classification_tile_%s.csv'%tile_cat)\n",
    "        #in_path = os.path.join(data['obia_folder'],'CLASSIF','walous_2018_classification_tile_%s.csv.gz'%tile_cat) #Uncomment if .csv is compressed with Gzip\n",
    "        #decompress_path = in_path[:-3] #Uncomment if .csv is compressed with Gzip\n",
    "        #decompress_gzip(in_path, decompress_path) #Uncomment if .csv is compressed with Gzip\n",
    "        #in_path = decompress_path #Uncomment if .csv is compressed with Gzip\n",
    "        obia_erp_path = ComputeERPfromCsv(in_path, erp_name=\"OBIA_ERP\", start_index=2)\n",
    "        gscript.run_command('db.in.ogr', overwrite=True, input=obia_erp_path, output='attribute')\n",
    "        # Rename the first column (id -> cat_)\n",
    "        columns = gscript.read_command('db.columns', table='attribute').split()[1:] #All columns except first ('id')\n",
    "        sql_query = \"DROP TABLE IF EXISTS tmp_a;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"CREATE TABLE tmp_a AS SELECT a.id AS cat_, %s \\\n",
    "        FROM attribute AS a;\"%','.join(['a.%s'%col for col in columns])\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"DROP TABLE IF EXISTS attribute;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"CREATE TABLE attribute AS SELECT * FROM tmp_a;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        # Remove temp files \n",
    "        #os.remove(decompress_path) #Remove decompressed .csv #Uncomment if .csv is compressed with Gzip\n",
    "        os.remove(obia_erp_path) #Remove .csv with ERP\n",
    "        # Print\n",
    "        return_message = \"--> Attribute table from OBIA classification imported in GRASS\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Importation of attribute table from OBIA classification failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CutCsv(input_csv, indexcol=False, nb_col_from_end=False):   \n",
    "    \"\"\"If provided, 'indexcol' should be a list\"\"\"\n",
    "    \"\"\"If provided, 'nb_col_from_end' should be an integer\"\"\"\n",
    "    import subprocess, sys\n",
    "    # Check if at least one option is asked   \n",
    "    if not indexcol and not nb_col_from_end:\n",
    "        return \"ERROR: At least parameter 'indexcol' or 'nb_col_from_end' should be provided\"\n",
    "        sys.exit()\n",
    "    # Create a new .csv with only the first and the X lasts columns (X = nb_col_from_end. By default, first and last only)\n",
    "    path, ext = os.path.splitext(input_csv)\n",
    "    cut_csv = \"%s_cut%s\"%(path,ext)\n",
    "    f = open(cut_csv, \"w\")\n",
    "    if nb_col_from_end:\n",
    "        # Get number of colums in the .csv\n",
    "        p1 = subprocess.Popen((\"head -1 %s\"%input_csv).split(), stdout=subprocess.PIPE)\n",
    "        p2 = subprocess.Popen((\"tr ',' '\\\\n'\").split(), stdin=p1.stdout, stdout=subprocess.PIPE)\n",
    "        p3 = subprocess.Popen((\"wc -l\").split(), stdin=p2.stdout, stdout=subprocess.PIPE)\n",
    "        nb_columns = int(p3.communicate()[0])\n",
    "        index_start = nb_columns-nb_col_from_end\n",
    "    #Extract first and several specific columns whose indexes are provided in 'indexcol' \n",
    "    if indexcol and not nb_col_from_end:\n",
    "        cut_process =  subprocess.Popen((\"cut -d, -f1,%s %s\"%(','.join(indexcol),input_csv)).split(), stdout=f)\n",
    "        cut_process.wait()\n",
    "    #Extract first and the X last columns according to the value provided in 'nb_col_from_end' \n",
    "    if nb_col_from_end and not indexcol:\n",
    "        cut_process =  subprocess.Popen((\"cut -d, -f1,%s-%s %s\"%(index_start,nb_columns,input_csv)).split(), stdout=f)\n",
    "        cut_process.wait()\n",
    "    #Extract first column, several specific columns ('indexcol') and the X last columns ('nb_col_from_end') \n",
    "    if nb_col_from_end and indexcol:\n",
    "        cut_process =  subprocess.Popen((\"cut -d, -f1,%s,%s-%s %s\"%(','.join(indexcol),index_start,nb_columns,input_csv)).split(), stdout=f)\n",
    "        cut_process.wait()\n",
    "    f.close()\n",
    "    return cut_csv\n",
    "\n",
    "def GetObiaNdsm(tile_cat):    \n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:   \n",
    "        # Decompress and import attribute table of segments the current cutline\n",
    "        in_path = os.path.join(data['obia_folder'],'ATTRIBUTS','walous_2018_stats_tile_%s.csv'%tile_cat)\n",
    "        #in_path = os.path.join(data['obia_folder'],'ATTRIBUTS','walous_2018_stats_tile_%s.csv.gz'%tile_cat) #Uncomment if .csv is compressed with Gzip\n",
    "        #decompress_path = in_path[:-3] # Uncomment if .csv is compressed with Gzip\n",
    "        #decompress_gzip(in_path, decompress_path) #Uncomment if .csv is compressed with Gzip\n",
    "        #in_path = decompress_path #Uncomment if .csv is compressed with Gzip\n",
    "        cut_csv = CutCsv(in_path, indexcol=['24',])  #'24' correspond to the position of the nDSM value in statistics csv file\n",
    "        table_name = 'ndsm_mean'\n",
    "        gscript.run_command('db.in.ogr', overwrite=True, input=cut_csv, output=table_name)\n",
    "        # Add to 'attribute' table\n",
    "        sql_query = \"DROP TABLE IF EXISTS tmp_a;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"CREATE TABLE tmp_a AS SELECT a.*,b.mnh2018_mean FROM attribute \\\n",
    "        AS a LEFT JOIN %s AS b ON a.cat_ = b.cat_;\"%table_name\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"DROP TABLE IF EXISTS attribute;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"CREATE TABLE attribute AS SELECT * FROM tmp_a;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        #os.remove(decompress_path) #Remove decompressed .csv #Uncomment if .csv is compressed with Gzip\n",
    "        os.remove(cut_csv) #Remove cutted .csv \n",
    "        # Print\n",
    "        return_message = \"--> MNH value (nDSM) added to attribute table\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Importation of MNH (nDSM) table failed. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetPixelProportion(basemap, zonemap, prefixcolumn=\"\"):        \n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        ### Compute percentage of each class from pixel-based classification\n",
    "        output_csv = CategoStats(basemap, zonemap, cl_list=pixel_classes_list, colpref=prefixcolumn,\n",
    "                                 prop=True, mode=True, countnullformode=True)\n",
    "        pixel_erp_path = ComputeERPfromCsv(output_csv, erp_name=\"ortho_lc_ERP\", start_index=2)\n",
    "        ## Join to the attribute table\n",
    "        table_name = '_'.join(os.path.split(pixel_erp_path)[-1].split(\".csv\")[0].split('_')[1:])\n",
    "        gscript.run_command('db.in.ogr', overwrite=True, input=pixel_erp_path, output=table_name)\n",
    "        proportion_columns = gscript.read_command('db.columns', table=table_name).split()[1:] #All columns except firts ('cat')\n",
    "        sql_query = \"DROP TABLE IF EXISTS tmp_a;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"CREATE TABLE tmp_a AS SELECT a.*,%s FROM attribute \\\n",
    "        AS a LEFT JOIN %s AS b ON a.cat_ = b.cat_;\"%(','.join(['b.%s'%col for col in proportion_columns]),table_name)\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"DROP TABLE IF EXISTS attribute;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"CREATE TABLE attribute AS SELECT * FROM tmp_a;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        # Print\n",
    "        return_message = \"--> Proportion of pixel-based classification '%s' computed\"%basemap\n",
    "    except:\n",
    "        return_message += \"ERROR: Computation of proportion of pixel-based classification '%s' failed. Please check for problem.\"%basemap\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetPixelModal(basemap, zonemap, prefixcolumn=\"\"):        \n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        # Get mode of pixel-based classification for each segments\n",
    "        output_csv = CategoStats(basemap, zonemap, cl_list=pixel_classes_list, colpref=prefixcolumn,\n",
    "                                 prop=False, mode=True, countnullformode=True)\n",
    "        # Joint attribute from OBIA classification and modal class from pixel-based classification\n",
    "        mode_raster = '%s_%s_mode'%(basemap,zonemap)\n",
    "        gscript.run_command('db.in.ogr', overwrite=True, input=output_csv, output=mode_raster)\n",
    "        sql_query = \"DROP TABLE IF EXISTS tmp_a\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"CREATE TABLE tmp_a AS SELECT a.*,b.%s_mode \\\n",
    "        FROM attribute AS a LEFT JOIN %s AS b ON a.cat_ = b.cat_;\"%(prefixcolumn,mode_raster)\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"DROP TABLE IF EXISTS attribute;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"CREATE TABLE attribute AS SELECT * FROM tmp_a;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        return_message = \"--> Modal class of pixel-based classification '%s' computed\"%basemap\n",
    "    except:\n",
    "        return_message += \"ERROR: Computation of modal class of pixel-based classification '%s' failed. Please check for problem.\"%basemap\n",
    "    return  return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ExportFeatureCsv(tile_cat):        \n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        ## Export attribute table with all features to .csv file\n",
    "        output_csv = os.path.join(config_parameters['outputfolder_classfeatures'],'features_tile_%s.csv'%tile_cat)\n",
    "        gscript.run_command('db.select', overwrite=True, sql=\"SELECT * FROM attribute\", separator='comma', output=output_csv)\n",
    "        CsvChangeEmptyByO(output_csv, sep=',')\n",
    "        return_message += \"--> Attribute table with segment feature exported to csv\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Export attribute table with feature statistics to csv failed. Please check for problem.\"\n",
    "\n",
    "    # Return\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DeleteTmpData(tile_cat):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    #Delete layers that are not needed anymore\n",
    "    list_of_tmp_rast = ['mask_copy',]\n",
    "    list_of_tmp_vect = ['tmp_tile',]\n",
    "    try:\n",
    "        # Remove mask if exists\n",
    "        if \"MASK@%s\"%tile_cat in gscript.list_strings(type=\"raster\",mapset=tile_cat):\n",
    "            gscript.run_command('r.mask', flags='r')\n",
    "        # Remove layers not needed anymore \n",
    "        gscript.run_command('g.remove', quiet=True, flags='f', type='vector', name=','.join(list_of_tmp_vect))    \n",
    "        gscript.run_command('g.remove', quiet=True, flags='f', type='raster', name=','.join(list_of_tmp_rast))\n",
    "        return_message += \"--> Mask and temporary layers have been deleted\"\n",
    "    except:\n",
    "        return_message = \"WARNING: Something went wrong during the deleting of temporary layer. Please check.\"\n",
    "    #Return\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetTileFeatures(current_tile):\n",
    "    start_tile = start_processing() \n",
    "    #Declare empty list for saving output messages\n",
    "    output_message = [] \n",
    "    #Launch mapset and create it if not exists\n",
    "    message = launch_mapset(current_tile)  \n",
    "    [output_message.append(a) for a in message]\n",
    "#    print \"\\n\".join(message)\n",
    "    #Add access to other mapset with input data\n",
    "    message = GetMapsetsAccess()  \n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Define computational region and mask\n",
    "    message = DefineComputationRegion(current_tile) \n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Unzip attributes from OBIA classification and import as SQlite table\n",
    "    message = GetObiaAttributes(current_tile) \n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Get nDSM value\n",
    "    message = GetObiaNdsm(current_tile)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Compute proportion and modal value of ORTHO_LC\n",
    "    message = GetPixelProportion(data['ortho_lc'][0], \"segmentation\", prefixcolumn=data['ortho_lc'][0])  \n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Compute modal value SENTI_LC\n",
    "    message = GetPixelModal(data['senti_lc'][0], \"segmentation\", prefixcolumn=data['senti_lc'][0]) \n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Compute modal value SENT2AGRI\n",
    "    message = GetPixelModal(data['senti_croptype'][0], \"segmentation\", prefixcolumn=data['senti_croptype'][0]) \n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Compute modal value MASK CROP \n",
    "    #message = GetPixelModal(data['binary_crop'][0], \"segmentation\", prefixcolumn=data['binary_crop'][0]) \n",
    "    #output_message.append(message)\n",
    "#    print message\n",
    "    #Compute modal value MASK SIGEC\n",
    "    message = GetPixelModal(data['binary_agri'][0], \"segmentation\", prefixcolumn=data['binary_agri'][0]) \n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Compute modal value MASK FOREST (Gembloux)\n",
    "    message = GetPixelModal(data['binary_forest'][0], \"segmentation\", prefixcolumn=data['binary_forest'][0]) \n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Compute modal value MASK HYDRO (Squelette vecto)\n",
    "    message = GetPixelModal(data['binary_hydro'][0], \"segmentation\", prefixcolumn=data['binary_hydro'][0]) \n",
    "    output_message.append(message)\n",
    "#    print message    \n",
    "    #Compute modal value MASK ROADNET (Squelette vecto)\n",
    "    message = GetPixelModal(data['binary_roadnet'][0], \"segmentation\", prefixcolumn=data['binary_roadnet'][0]) \n",
    "    output_message.append(message)\n",
    "#    print message    \n",
    "    #Compute modal value MASK BUILT (Squelette vecto)\n",
    "    message = GetPixelModal(data['binary_built'][0], \"segmentation\", prefixcolumn=data['binary_built'][0]) \n",
    "    output_message.append(message)\n",
    "#    print message    \n",
    "    #Export GRASS GIS SQlite table to csv\n",
    "    message = ExportFeatureCsv(current_tile)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Delete temporary layers and MASK\n",
    "    message = DeleteTmpData(current_tile)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Print processing time\n",
    "    message = print_processing_time(start_tile, \"Extraction of classification feature for tile '%s' achieved in \"%current_tile)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Export Log file\n",
    "    fout = open(os.path.join(config_parameters['outputfolder_Logfile'],\"Log_feature_extrac_tile_%s.txt\"%current_tile),\"w\")\n",
    "    [fout.writelines('%s\\n'%content) for content in output_message]\n",
    "    fout.close()\n",
    "    # Print end\n",
    "    print print_processing_time(start_tile,\"Processing of tile %s achieved in \"%current_tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder '../../../Results/Classification_features' already exists\n",
      "The folder '../../../Results/Log_file' already exists\n"
     ]
    }
   ],
   "source": [
    "# Check and create folder if needed\n",
    "check_create_dir(config_parameters['outputfolder_classfeatures'])\n",
    "check_create_dir(config_parameters['outputfolder_Logfile'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Location 'WALOUS_31370' already exist\",\n",
       " \"'PERMANENT' mapset already exists in location 'WALOUS_31370'\",\n",
       " \"You are now working in mapset 'WALOUS_31370/PERMANENT'\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create mapset \n",
    "launch_mapset(\"PERMANENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import list of tiles to file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.techcoil.com/blog/how-to-save-and-load-objects-to-and-from-file-in-python-via-facilities-from-the-pickle-module/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'177',\n",
       " u'178',\n",
       " u'184',\n",
       " u'185',\n",
       " u'186',\n",
       " u'187',\n",
       " u'247',\n",
       " u'254',\n",
       " u'255',\n",
       " u'256',\n",
       " u'257',\n",
       " u'258',\n",
       " u'259',\n",
       " u'260',\n",
       " u'276',\n",
       " u'277',\n",
       " u'278',\n",
       " u'279',\n",
       " u'281',\n",
       " u'282',\n",
       " u'285',\n",
       " u'287',\n",
       " u'288',\n",
       " u'305',\n",
       " u'401',\n",
       " u'402',\n",
       " u'413',\n",
       " u'414',\n",
       " u'425',\n",
       " u'426',\n",
       " u'437',\n",
       " u'450',\n",
       " u'461',\n",
       " u'462',\n",
       " u'492',\n",
       " u'493',\n",
       " u'498',\n",
       " u'499',\n",
       " u'518',\n",
       " u'544',\n",
       " u'545',\n",
       " u'546',\n",
       " u'572',\n",
       " u'607',\n",
       " u'608',\n",
       " u'629',\n",
       " u'630',\n",
       " u'631',\n",
       " u'632',\n",
       " u'655',\n",
       " u'656',\n",
       " u'666',\n",
       " u'667',\n",
       " u'680',\n",
       " u'685',\n",
       " u'711',\n",
       " u'817',\n",
       " u'1059',\n",
       " u'1068',\n",
       " u'1069',\n",
       " u'1128',\n",
       " u'1157',\n",
       " u'1158',\n",
       " u'1177',\n",
       " u'1178',\n",
       " u'1179',\n",
       " u'1180',\n",
       " u'1181',\n",
       " u'1182',\n",
       " u'1183',\n",
       " u'1197',\n",
       " u'1205',\n",
       " u'1207',\n",
       " u'1208',\n",
       " u'1216',\n",
       " u'1217',\n",
       " u'1252',\n",
       " u'1253',\n",
       " u'1734',\n",
       " u'1789',\n",
       " u'1790',\n",
       " u'1791',\n",
       " u'1792',\n",
       " u'1793',\n",
       " u'1839',\n",
       " u'1840',\n",
       " u'1841',\n",
       " u'1842',\n",
       " u'1843',\n",
       " u'1844',\n",
       " u'1846',\n",
       " u'1847',\n",
       " u'1848',\n",
       " u'1875',\n",
       " u'1876',\n",
       " u'1892',\n",
       " u'1893',\n",
       " u'1894',\n",
       " u'1895',\n",
       " u'1896',\n",
       " u'1897',\n",
       " u'1914',\n",
       " u'1982',\n",
       " u'1986',\n",
       " u'1987',\n",
       " u'2016',\n",
       " u'2017',\n",
       " u'2018',\n",
       " u'2019',\n",
       " u'2020',\n",
       " u'2021',\n",
       " u'2022',\n",
       " u'2023',\n",
       " u'2024',\n",
       " u'2025',\n",
       " u'2028',\n",
       " u'2039',\n",
       " u'2040',\n",
       " u'2041',\n",
       " u'2042',\n",
       " u'2043',\n",
       " u'2044',\n",
       " u'2045',\n",
       " u'2138',\n",
       " u'2139',\n",
       " u'2140',\n",
       " u'2141',\n",
       " u'2146',\n",
       " u'2147',\n",
       " u'2153',\n",
       " u'2154',\n",
       " u'2197',\n",
       " u'2198',\n",
       " u'2211',\n",
       " u'2212',\n",
       " u'2213',\n",
       " u'2214',\n",
       " u'2219',\n",
       " u'2334',\n",
       " u'2335',\n",
       " u'2396',\n",
       " u'2397',\n",
       " u'2398',\n",
       " u'2399',\n",
       " u'2400',\n",
       " u'2401',\n",
       " u'2480',\n",
       " u'2481',\n",
       " u'2482',\n",
       " u'2483',\n",
       " u'2484',\n",
       " u'2485',\n",
       " u'2486',\n",
       " u'2487',\n",
       " u'2488',\n",
       " u'2494',\n",
       " u'2495',\n",
       " u'2496',\n",
       " u'2516',\n",
       " u'2517',\n",
       " u'2518',\n",
       " u'2520',\n",
       " u'2521',\n",
       " u'2522',\n",
       " u'2523',\n",
       " u'2524',\n",
       " u'2525',\n",
       " u'2526',\n",
       " u'2527',\n",
       " u'2538',\n",
       " u'2539',\n",
       " u'2540',\n",
       " u'2541',\n",
       " u'2542',\n",
       " u'2543',\n",
       " u'2544',\n",
       " u'2545',\n",
       " u'2546',\n",
       " u'2664',\n",
       " u'2665',\n",
       " u'2666',\n",
       " u'2770',\n",
       " u'2771',\n",
       " u'2772',\n",
       " u'2773',\n",
       " u'2774',\n",
       " u'2817',\n",
       " u'2820',\n",
       " u'2821',\n",
       " u'2895',\n",
       " u'2912',\n",
       " u'2949',\n",
       " u'2956',\n",
       " u'3048',\n",
       " u'3054',\n",
       " u'3077',\n",
       " u'3079',\n",
       " u'3098',\n",
       " u'3205',\n",
       " u'3219',\n",
       " u'3283',\n",
       " u'3287',\n",
       " u'3288',\n",
       " u'3292',\n",
       " u'3303',\n",
       " u'3304',\n",
       " u'3305',\n",
       " u'3306',\n",
       " u'3307',\n",
       " u'3308',\n",
       " u'3309',\n",
       " u'3310',\n",
       " u'3384',\n",
       " u'3385',\n",
       " u'3404',\n",
       " u'3405',\n",
       " u'3406',\n",
       " u'3407',\n",
       " u'3408',\n",
       " u'3409',\n",
       " u'3410',\n",
       " u'3510',\n",
       " u'3512',\n",
       " u'3544',\n",
       " u'3629',\n",
       " u'3630',\n",
       " u'3679',\n",
       " u'3719',\n",
       " u'3721',\n",
       " u'3723',\n",
       " u'3724',\n",
       " u'3726',\n",
       " u'3727',\n",
       " u'3728',\n",
       " u'3825',\n",
       " u'3826',\n",
       " u'3830',\n",
       " u'3831',\n",
       " u'3838',\n",
       " u'3839',\n",
       " u'3840',\n",
       " u'3871',\n",
       " u'3872',\n",
       " u'3888',\n",
       " u'3932',\n",
       " u'3933',\n",
       " u'3939',\n",
       " u'3966',\n",
       " u'3967',\n",
       " u'4003',\n",
       " u'4004',\n",
       " u'4019',\n",
       " u'4064',\n",
       " u'4065',\n",
       " u'4085',\n",
       " u'4086',\n",
       " u'4099',\n",
       " u'4108',\n",
       " u'4109',\n",
       " u'4110',\n",
       " u'4134',\n",
       " u'4146',\n",
       " u'4147',\n",
       " u'4149',\n",
       " u'4157',\n",
       " u'4324',\n",
       " u'4325',\n",
       " u'4326',\n",
       " u'4343',\n",
       " u'4344',\n",
       " u'4407',\n",
       " u'4441',\n",
       " u'4691',\n",
       " u'4692',\n",
       " u'4693',\n",
       " u'4704',\n",
       " u'4708',\n",
       " u'4748',\n",
       " u'4754',\n",
       " u'4755',\n",
       " u'4781',\n",
       " u'4785',\n",
       " u'4787',\n",
       " u'4797',\n",
       " u'4798',\n",
       " u'4808',\n",
       " u'4809',\n",
       " u'4810',\n",
       " u'4811',\n",
       " u'4813',\n",
       " u'4814',\n",
       " u'4816',\n",
       " u'4993',\n",
       " u'5027',\n",
       " u'5028',\n",
       " u'5029',\n",
       " u'5035',\n",
       " u'5036',\n",
       " u'5050',\n",
       " u'5054',\n",
       " u'5062',\n",
       " u'5063',\n",
       " u'5064',\n",
       " u'5065',\n",
       " u'5066',\n",
       " u'5082',\n",
       " u'5101',\n",
       " u'5267',\n",
       " u'5293',\n",
       " u'5294',\n",
       " u'5320',\n",
       " u'5337',\n",
       " u'5350',\n",
       " u'5351',\n",
       " u'5352',\n",
       " u'5359',\n",
       " u'5360',\n",
       " u'5361',\n",
       " u'5396',\n",
       " u'5398',\n",
       " u'5445',\n",
       " u'5462',\n",
       " u'5464',\n",
       " u'5491',\n",
       " u'5511',\n",
       " u'5563',\n",
       " u'5572',\n",
       " u'5648',\n",
       " u'5662',\n",
       " u'5663',\n",
       " u'5758',\n",
       " u'5761',\n",
       " u'5762',\n",
       " u'5763',\n",
       " u'5787',\n",
       " u'5788',\n",
       " u'5789',\n",
       " u'5792',\n",
       " u'5796',\n",
       " u'5797',\n",
       " u'5817',\n",
       " u'5818',\n",
       " u'5820',\n",
       " u'5830',\n",
       " u'5843',\n",
       " u'5844',\n",
       " u'5845',\n",
       " u'5846',\n",
       " u'5847',\n",
       " u'5848',\n",
       " u'5849',\n",
       " u'5851',\n",
       " u'5920',\n",
       " u'5921',\n",
       " u'5929',\n",
       " u'5930',\n",
       " u'5931',\n",
       " u'5934',\n",
       " u'5935',\n",
       " u'5936',\n",
       " u'6040',\n",
       " u'6061',\n",
       " u'6164',\n",
       " u'6192',\n",
       " u'6194',\n",
       " u'6217',\n",
       " u'6229',\n",
       " u'6231',\n",
       " u'6297',\n",
       " u'6325',\n",
       " u'6326',\n",
       " u'6327',\n",
       " u'6333',\n",
       " u'6351',\n",
       " u'6357']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(config_parameters['list_tiles'], 'rb') as outputfile: \n",
    "    tile_list = pickle.load(outputfile) \n",
    "tile_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get a list of classes in pixel-based classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '5', '6', '11', '12', '31', '32', '41', '42', '91', '92', '93', '94']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import list of class of 'ortho_lc' map\n",
    "with open(config_parameters['pixel_classes_list'], 'rb') as outputfile: \n",
    "    pixel_classes_list = pickle.load(outputfile) \n",
    "pixel_classes_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract classification features by segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define number of cores\n",
    "ncores = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to process 375 tiles on 10 cores\n"
     ]
    }
   ],
   "source": [
    "# Define current tile\n",
    "print \"Going to process %s tiles on %s cores\"%(len(tile_list),ncores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing on tile 1128\n",
      "Start processing on tile 1179\n",
      "Start processing on tile 1217\n",
      "Start processing on tile 1197\n",
      "Start processing on tile 1846\n",
      "Start processing on tile 711\n",
      "Start processing on tile 656\n",
      "Start processing on tile 2016\n",
      "Start processing on tile 1840\n",
      "Start processing on tile 1790\n",
      "Start processing on tile 2021\n",
      "Start processing on tile 1897\n",
      "Start processing on tile 2043\n",
      "Start processing on tile 1892\n",
      "Start processing on tile 2140\n",
      "Start processing on tile 2028\n",
      "Start processing on tile 2154\n",
      "Start processing on tile 2213\n",
      "Start processing on tile 2396\n",
      "Start processing on tile 2401\n"
     ]
    }
   ],
   "source": [
    "# Launch processes in parallel\n",
    "start_parallel = start_processing()\n",
    "p = Pool(ncores)\n",
    "output = p.map(GetTileFeatures, tile_list[:])  # Launch the processes for as many items in the list (if function with a return, the returned results are ordered thanks to 'map' function)\n",
    "p.close()\n",
    "p.join()\n",
    "# Print\n",
    "print_processing_time(start_parallel, \"Computation (on %s cores) achieved in \"%ncores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Check log file for ERRORS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 log files in the folder\n"
     ]
    }
   ],
   "source": [
    "# Get list of csv with classification feature of individual tiles\n",
    "import glob\n",
    "list_log = glob.glob(os.path.join(config_parameters['outputfolder_Logfile'],\"Log_feature_extrac_tile_*.txt\"))\n",
    "print \"%s log files in the folder\"%len(list_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tile(s) faced an ERROR during the processing.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare new counter\n",
    "count = 0\n",
    "# Declare new list that will contain list of tile with error\n",
    "tile_error_list = []\n",
    "# Loop on list of log file\n",
    "for logfile in list_log:\n",
    "    got_error = False\n",
    "    tile_num = os.path.splitext(os.path.basename(logfile))[0].split(\"_\")[-1]\n",
    "    fin = open(logfile, 'r')\n",
    "    for row in fin:\n",
    "        if row[:5] == \"ERROR\":  # If at least one line have error message, the whole file will be counted as 1 error\n",
    "            got_error = True\n",
    "    if got_error:    \n",
    "        count += 1\n",
    "        tile_error_list.append(tile_num)  # Add tile number to the list\n",
    "# Print\n",
    "print \"%s tile(s) faced an ERROR during the processing.\\n\"%count\n",
    "\n",
    "# Update tile list with only tiles that have ERROR in log \n",
    "print \"\\n\".join([\"Error on tile %s\"%(a) for a in tile_error_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tile_error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
