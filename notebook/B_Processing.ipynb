{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><font size=\"6\">WALOUS</font></strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><font size=\"6\">Fusion LC classifications results</font></strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><font size=\"6\">Compute feature statistics</font></strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This python code implement the method developed by ANAGEO (ULB). \n",
    "\n",
    "Code developped on Linux Mint 18.1 (Ubuntu Xenial 16.04) and GRASS GIS 7.3.svn (r71315)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is a Javascript section of code for building the Jupyter notebook's table of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define working environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries needed for setting parameters of operating system \n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import tempfile\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import multiprocessing and functools libraries\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Add folder with SCR provided belong to this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add local module to the path\n",
    "src = os.path.abspath('../SRC')\n",
    "if src not in sys.path:\n",
    "    sys.path.append(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Setup environment variables for TAIS DESKTOP (Linux Mint + GRASS Dev) **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please edit the file in `../SRC/config.py`, containing the configuration parameters, according to your own computer setup. The following cell is used to run this file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run ../SRC/config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-6-c09e0cc80e1a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-c09e0cc80e1a>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    print config_parameters\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "print config_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import functions that setup the environmental variables\n",
    "import environ_variables as envi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set environmental variables\n",
    "envi.setup_environmental_variables() \n",
    "# Display current environment variables of your computer\n",
    "envi.print_environmental_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** GRASS GIS Python libraries **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries needed to launch GRASS GIS in the jupyter notebook\n",
    "import grass.script.setup as gsetup\n",
    "# Import libraries needed to call GRASS using Python\n",
    "import grass.script as gscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Other functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import function that check existance and create GRASS GIS database folder if needed\n",
    "from grass_database import check_gisdb, check_location, check_mapset, working_mapset\n",
    "# Import functions for processing time information\n",
    "from processing_time import start_processing, print_processing_time\n",
    "# Import function that generate a random name in the GRASS GIS environement\n",
    "from random_layer_name import random_layer_name\n",
    "# Import function that check and create folder\n",
    "from mkdir import check_create_dir\n",
    "# Import function that check if GRASS GIS add-on is installed and install it if needed\n",
    "from gextension import check_install_addon\n",
    "# Import function for .gzip archive management\n",
    "from gzip_management import decompress_gzip\n",
    "# Import function for computation of proportion of categorical raster in zones (segments)\n",
    "from compute_proportion_categorical import CategoStats\n",
    "# Import function for getting list of class of a raster\n",
    "from data_prep import data_prep\n",
    "# Import function the allow sorting strings with number as if they was number (natural order)\n",
    "from sorting_natural import natural_keys\n",
    "# Import function that compute ERP on csv file\n",
    "from EquivalentReferenceProbability import ComputeERPfromCsv\n",
    "# Import function that replace \"empty\" values from output .csv to zero\n",
    "from CsvEmptyValues import CsvChangeEmptyByO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def launch_mapset(mapset):\n",
    "    #Declare empty list that will contain the messages to return\n",
    "    return_message = []\n",
    "    # Check if the location exists and create it if not, with the CRS defined by the epsg code \n",
    "    return_message.append(check_location(config_parameters[\"gisdb\"],config_parameters['location'],config_parameters[\"locationepsg\"]))\n",
    "    # Check if mapset exists\n",
    "    return_message.append(check_mapset(config_parameters[\"gisdb\"],config_parameters['location'],mapset))\n",
    "    # Change the current working GRASS GIS session mapset\n",
    "    return_message.append(working_mapset(config_parameters[\"gisdb\"],config_parameters['location'],mapset))\n",
    "    # Return\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetMapsetsAccess():\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        # Add mapsets with input data to the GRASS GIS research path\n",
    "        gscript.run_command('g.mapsets', mapset=\"BINARIES,OBIA,PIXEL_ORTHO_LC,PIXEL_SENTINEL\", operation=\"add\")\n",
    "        return_message = \"Access to other mapset added\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Add access to other Mapsets failed. Please check for problem.\"\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DefineComputationRegion(tile_cat):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        return_message = \"Working on tile '%s'\\n\"%tile_cat\n",
    "        # Extract the cutline polygon to work on\n",
    "        condition = 'cat=%s'%tile_cat\n",
    "        gscript.run_command('v.extract', overwrite=True, input='tiles', where=condition, output='tmp_tile')\n",
    "        # Define computational region based on this polygon\n",
    "        gscript.run_command('g.region', raster='segmentation') # To get resolution of segmentation \n",
    "        gscript.run_command('g.region', flags='a', vector='tmp_tile') # Keep resolution but change extent\n",
    "        # Mask according to this polygon\n",
    "        gscript.run_command('r.mask', overwrite=True, vector='tmp_tile')\n",
    "        # Copy the mask layer\n",
    "        gscript.run_command('g.copy', overwrite=True, raster='MASK,mask_copy')\n",
    "        # Print\n",
    "        return_message += \"--> Computational region and MASK defined\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Setting of computional region and MASK failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetObiaAttributes(tile_cat):    \n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:   \n",
    "        # Decompress and import attribute table of segments of the current tile\n",
    "        in_path = os.path.join(data['obia_folder'],'CLASSIF','walous_2018_classification_tile_%s.csv'%tile_cat)\n",
    "        #in_path = os.path.join(data['obia_folder'],'CLASSIF','walous_2018_classification_tile_%s.csv.gz'%tile_cat) #Uncomment if .csv is compressed with Gzip\n",
    "        #decompress_path = in_path[:-3] #Uncomment if .csv is compressed with Gzip\n",
    "        #decompress_gzip(in_path, decompress_path) #Uncomment if .csv is compressed with Gzip\n",
    "        #in_path = decompress_path #Uncomment if .csv is compressed with Gzip\n",
    "        obia_erp_path = ComputeERPfromCsv(in_path, erp_name=\"OBIA_ERP\", start_index=2)\n",
    "        gscript.run_command('db.in.ogr', overwrite=True, input=obia_erp_path, output='attribute')\n",
    "        # Rename the first column (id -> cat_)\n",
    "        columns = gscript.read_command('db.columns', table='attribute').split()[1:] #All columns except first ('id')\n",
    "        sql_query = \"DROP TABLE IF EXISTS tmp_a;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"CREATE TABLE tmp_a AS SELECT a.id AS cat_, %s \\\n",
    "        FROM attribute AS a;\"%','.join(['a.%s'%col for col in columns])\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"DROP TABLE IF EXISTS attribute;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"CREATE TABLE attribute AS SELECT * FROM tmp_a;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        # Remove temp files \n",
    "        #os.remove(decompress_path) #Remove decompressed .csv #Uncomment if .csv is compressed with Gzip\n",
    "        os.remove(obia_erp_path) #Remove .csv with ERP\n",
    "        # Print\n",
    "        return_message = \"--> Attribute table from OBIA classification imported in GRASS\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Importation of attribute table from OBIA classification failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CutCsv(input_csv, indexcol=False, nb_col_from_end=False):   \n",
    "    \"\"\"If provided, 'indexcol' should be a list\"\"\"\n",
    "    \"\"\"If provided, 'nb_col_from_end' should be an integer\"\"\"\n",
    "    import subprocess, sys\n",
    "    # Check if at least one option is asked   \n",
    "    if not indexcol and not nb_col_from_end:\n",
    "        return \"ERROR: At least parameter 'indexcol' or 'nb_col_from_end' should be provided\"\n",
    "        sys.exit()\n",
    "    # Create a new .csv with only the first and the X lasts columns (X = nb_col_from_end. By default, first and last only)\n",
    "    path, ext = os.path.splitext(input_csv)\n",
    "    cut_csv = \"%s_cut%s\"%(path,ext)\n",
    "    f = open(cut_csv, \"w\")\n",
    "    if nb_col_from_end:\n",
    "        # Get number of colums in the .csv\n",
    "        p1 = subprocess.Popen((\"head -1 %s\"%input_csv).split(), stdout=subprocess.PIPE)\n",
    "        p2 = subprocess.Popen((\"tr ',' '\\\\n'\").split(), stdin=p1.stdout, stdout=subprocess.PIPE)\n",
    "        p3 = subprocess.Popen((\"wc -l\").split(), stdin=p2.stdout, stdout=subprocess.PIPE)\n",
    "        nb_columns = int(p3.communicate()[0])\n",
    "        index_start = nb_columns-nb_col_from_end\n",
    "    #Extract first and several specific columns whose indexes are provided in 'indexcol' \n",
    "    if indexcol and not nb_col_from_end:\n",
    "        cut_process =  subprocess.Popen((\"cut -d, -f1,%s %s\"%(','.join(indexcol),input_csv)).split(), stdout=f)\n",
    "        cut_process.wait()\n",
    "    #Extract first and the X last columns according to the value provided in 'nb_col_from_end' \n",
    "    if nb_col_from_end and not indexcol:\n",
    "        cut_process =  subprocess.Popen((\"cut -d, -f1,%s-%s %s\"%(index_start,nb_columns,input_csv)).split(), stdout=f)\n",
    "        cut_process.wait()\n",
    "    #Extract first column, several specific columns ('indexcol') and the X last columns ('nb_col_from_end') \n",
    "    if nb_col_from_end and indexcol:\n",
    "        cut_process =  subprocess.Popen((\"cut -d, -f1,%s,%s-%s %s\"%(','.join(indexcol),index_start,nb_columns,input_csv)).split(), stdout=f)\n",
    "        cut_process.wait()\n",
    "    f.close()\n",
    "    return cut_csv\n",
    "\n",
    "def GetObiaNdsm(tile_cat):    \n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:   \n",
    "        # Decompress and import attribute table of segments the current cutline\n",
    "        in_path = os.path.join(data['obia_folder'],'ATTRIBUTS','walous_2018_stats_tile_%s.csv'%tile_cat)\n",
    "        #in_path = os.path.join(data['obia_folder'],'ATTRIBUTS','walous_2018_stats_tile_%s.csv.gz'%tile_cat) #Uncomment if .csv is compressed with Gzip\n",
    "        #decompress_path = in_path[:-3] # Uncomment if .csv is compressed with Gzip\n",
    "        #decompress_gzip(in_path, decompress_path) #Uncomment if .csv is compressed with Gzip\n",
    "        #in_path = decompress_path #Uncomment if .csv is compressed with Gzip\n",
    "        cut_csv = CutCsv(in_path, indexcol=['24',])  #'24' correspond to the position of the nDSM value in statistics csv file\n",
    "        table_name = 'ndsm_mean'\n",
    "        gscript.run_command('db.in.ogr', overwrite=True, input=cut_csv, output=table_name)\n",
    "        # Add to 'attribute' table\n",
    "        sql_query = \"DROP TABLE IF EXISTS tmp_a;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"CREATE TABLE tmp_a AS SELECT a.*,b.mnh2018_mean FROM attribute \\\n",
    "        AS a LEFT JOIN %s AS b ON a.cat_ = b.cat_;\"%table_name\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"DROP TABLE IF EXISTS attribute;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"CREATE TABLE attribute AS SELECT * FROM tmp_a;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        #os.remove(decompress_path) #Remove decompressed .csv #Uncomment if .csv is compressed with Gzip\n",
    "        os.remove(cut_csv) #Remove cutted .csv \n",
    "        # Print\n",
    "        return_message = \"--> MNH value (nDSM) added to attribute table\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Importation of MNH (nDSM) table failed. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetPixelProportion(basemap, zonemap, prefixcolumn=\"\"):        \n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        ### Compute percentage of each class from pixel-based classification\n",
    "        output_csv = CategoStats(basemap, zonemap, cl_list=pixel_classes_list, colpref=prefixcolumn,\n",
    "                                 prop=True, mode=True, countnullformode=True)\n",
    "        pixel_erp_path = ComputeERPfromCsv(output_csv, erp_name=\"ortho_lc_ERP\", start_index=2)\n",
    "        ## Join to the attribute table\n",
    "        table_name = '_'.join(os.path.split(pixel_erp_path)[-1].split(\".csv\")[0].split('_')[1:])\n",
    "        gscript.run_command('db.in.ogr', overwrite=True, input=pixel_erp_path, output=table_name)\n",
    "        proportion_columns = gscript.read_command('db.columns', table=table_name).split()[1:] #All columns except firts ('cat')\n",
    "        sql_query = \"DROP TABLE IF EXISTS tmp_a;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"CREATE TABLE tmp_a AS SELECT a.*,%s FROM attribute \\\n",
    "        AS a LEFT JOIN %s AS b ON a.cat_ = b.cat_;\"%(','.join(['b.%s'%col for col in proportion_columns]),table_name)\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"DROP TABLE IF EXISTS attribute;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"CREATE TABLE attribute AS SELECT * FROM tmp_a;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        # Print\n",
    "        return_message = \"--> Proportion of pixel-based classification '%s' computed\"%basemap\n",
    "    except:\n",
    "        return_message += \"ERROR: Computation of proportion of pixel-based classification '%s' failed. Please check for problem.\"%basemap\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetPixelModal(basemap, zonemap, prefixcolumn=\"\"):        \n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        # Get mode of pixel-based classification for each segments\n",
    "        output_csv = CategoStats(basemap, zonemap, cl_list=pixel_classes_list, colpref=prefixcolumn,\n",
    "                                 prop=False, mode=True, countnullformode=True)\n",
    "        # Joint attribute from OBIA classification and modal class from pixel-based classification\n",
    "        mode_raster = '%s_%s_mode'%(basemap,zonemap)\n",
    "        gscript.run_command('db.in.ogr', overwrite=True, input=output_csv, output=mode_raster)\n",
    "        sql_query = \"DROP TABLE IF EXISTS tmp_a\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"CREATE TABLE tmp_a AS SELECT a.*,b.%s_mode \\\n",
    "        FROM attribute AS a LEFT JOIN %s AS b ON a.cat_ = b.cat_;\"%(prefixcolumn,mode_raster)\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"DROP TABLE IF EXISTS attribute;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        sql_query = \"CREATE TABLE attribute AS SELECT * FROM tmp_a;\"\n",
    "        gscript.run_command('db.execute', overwrite=True, sql=sql_query)\n",
    "        return_message = \"--> Modal class of pixel-based classification '%s' computed\"%basemap\n",
    "    except:\n",
    "        return_message += \"ERROR: Computation of modal class of pixel-based classification '%s' failed. Please check for problem.\"%basemap\n",
    "    return  return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ExportFeatureCsv(tile_cat):        \n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        ## Export attribute table with all features to .csv file\n",
    "        output_csv = os.path.join(config_parameters['outputfolder_classfeatures'],'features_tile_%s.csv'%tile_cat)\n",
    "        gscript.run_command('db.select', overwrite=True, sql=\"SELECT * FROM attribute\", separator='comma', output=output_csv)\n",
    "        CsvChangeEmptyByO(output_csv, sep=',')\n",
    "        return_message += \"--> Attribute table with segment feature exported to csv\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Export attribute table with feature statistics to csv failed. Please check for problem.\"\n",
    "\n",
    "    # Return\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DeleteTmpData(tile_cat):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    #Delete layers that are not needed anymore\n",
    "    list_of_tmp_rast = ['mask_copy',]\n",
    "    list_of_tmp_vect = ['tmp_tile',]\n",
    "    try:\n",
    "        # Remove mask if exists\n",
    "        if \"MASK@%s\"%tile_cat in gscript.list_strings(type=\"raster\",mapset=tile_cat):\n",
    "            gscript.run_command('r.mask', flags='r')\n",
    "        # Remove layers not needed anymore \n",
    "        gscript.run_command('g.remove', quiet=True, flags='f', type='vector', name=','.join(list_of_tmp_vect))    \n",
    "        gscript.run_command('g.remove', quiet=True, flags='f', type='raster', name=','.join(list_of_tmp_rast))\n",
    "        return_message += \"--> Mask and temporary layers have been deleted\"\n",
    "    except:\n",
    "        return_message = \"WARNING: Something went wrong during the deleting of temporary layer. Please check.\"\n",
    "    #Return\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetTileFeatures(current_tile):\n",
    "    start_tile = start_processing() \n",
    "    #Declare empty list for saving output messages\n",
    "    output_message = [] \n",
    "    #Launch mapset and create it if not exists\n",
    "    message = launch_mapset(current_tile)  \n",
    "    [output_message.append(a) for a in message]\n",
    "#    print \"\\n\".join(message)\n",
    "    #Add access to other mapset with input data\n",
    "    message = GetMapsetsAccess()  \n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Define computational region and mask\n",
    "    message = DefineComputationRegion(current_tile) \n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Unzip attributes from OBIA classification and import as SQlite table\n",
    "    message = GetObiaAttributes(current_tile) \n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Get nDSM value\n",
    "    message = GetObiaNdsm(current_tile)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Compute proportion and modal value of ORTHO_LC\n",
    "    message = GetPixelProportion(data['ortho_lc'][0], \"segmentation\", prefixcolumn=data['ortho_lc'][0])  \n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Compute modal value SENTI_LC\n",
    "    message = GetPixelModal(data['senti_lc'][0], \"segmentation\", prefixcolumn=data['senti_lc'][0]) \n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Compute modal value SENT2AGRI\n",
    "    message = GetPixelModal(data['senti_croptype'][0], \"segmentation\", prefixcolumn=data['senti_croptype'][0]) \n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Compute modal value MASK CROP \n",
    "    #message = GetPixelModal(data['binary_crop'][0], \"segmentation\", prefixcolumn=data['binary_crop'][0]) \n",
    "    #output_message.append(message)\n",
    "#    print message\n",
    "    #Compute modal value MASK SIGEC\n",
    "    message = GetPixelModal(data['binary_agri'][0], \"segmentation\", prefixcolumn=data['binary_agri'][0]) \n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Compute modal value MASK FOREST (Gembloux)\n",
    "    message = GetPixelModal(data['binary_forest'][0], \"segmentation\", prefixcolumn=data['binary_forest'][0]) \n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Compute modal value MASK HYDRO (Squelette vecto)\n",
    "    message = GetPixelModal(data['binary_hydro'][0], \"segmentation\", prefixcolumn=data['binary_hydro'][0]) \n",
    "    output_message.append(message)\n",
    "#    print message    \n",
    "    #Compute modal value MASK ROADNET (Squelette vecto)\n",
    "    message = GetPixelModal(data['binary_roadnet'][0], \"segmentation\", prefixcolumn=data['binary_roadnet'][0]) \n",
    "    output_message.append(message)\n",
    "#    print message    \n",
    "    #Compute modal value MASK BUILT (Squelette vecto)\n",
    "    message = GetPixelModal(data['binary_built'][0], \"segmentation\", prefixcolumn=data['binary_built'][0]) \n",
    "    output_message.append(message)\n",
    "#    print message    \n",
    "    #Export GRASS GIS SQlite table to csv\n",
    "    message = ExportFeatureCsv(current_tile)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Delete temporary layers and MASK\n",
    "    message = DeleteTmpData(current_tile)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Print processing time\n",
    "    message = print_processing_time(start_tile, \"Extraction of classification feature for tile '%s' achieved in \"%current_tile)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    #Export Log file\n",
    "    fout = open(os.path.join(config_parameters['outputfolder_Logfile'],\"Log_feature_extrac_tile_%s.txt\"%current_tile),\"w\")\n",
    "    [fout.writelines('%s\\n'%content) for content in output_message]\n",
    "    fout.close()\n",
    "    # Print end\n",
    "    print print_processing_time(start_tile,\"Processing of tile %s achieved in \"%current_tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder '../../../Results/Classification_features' already exists\n",
      "The folder '../../../Results/Log_file' already exists\n"
     ]
    }
   ],
   "source": [
    "# Check and create folder if needed\n",
    "check_create_dir(config_parameters['outputfolder_classfeatures'])\n",
    "check_create_dir(config_parameters['outputfolder_Logfile'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Location 'WALOUS_31370' already exist\",\n",
       " \"'PERMANENT' mapset already exists in location 'WALOUS_31370'\",\n",
       " \"You are now working in mapset 'WALOUS_31370/PERMANENT'\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create mapset \n",
    "launch_mapset(\"PERMANENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import list of tiles to file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.techcoil.com/blog/how-to-save-and-load-objects-to-and-from-file-in-python-via-facilities-from-the-pickle-module/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'177',\n",
       " u'178',\n",
       " u'184',\n",
       " u'185',\n",
       " u'186',\n",
       " u'187',\n",
       " u'247',\n",
       " u'254',\n",
       " u'255',\n",
       " u'256',\n",
       " u'257',\n",
       " u'258',\n",
       " u'259',\n",
       " u'260',\n",
       " u'276',\n",
       " u'277',\n",
       " u'278',\n",
       " u'279',\n",
       " u'281',\n",
       " u'282',\n",
       " u'285',\n",
       " u'287',\n",
       " u'288',\n",
       " u'305',\n",
       " u'401',\n",
       " u'402',\n",
       " u'413',\n",
       " u'414',\n",
       " u'425',\n",
       " u'426',\n",
       " u'437',\n",
       " u'450',\n",
       " u'461',\n",
       " u'462',\n",
       " u'492',\n",
       " u'493',\n",
       " u'498',\n",
       " u'499',\n",
       " u'518',\n",
       " u'544',\n",
       " u'545',\n",
       " u'546',\n",
       " u'572',\n",
       " u'607',\n",
       " u'608',\n",
       " u'629',\n",
       " u'630',\n",
       " u'631',\n",
       " u'632',\n",
       " u'655',\n",
       " u'656',\n",
       " u'666',\n",
       " u'667',\n",
       " u'680',\n",
       " u'685',\n",
       " u'711',\n",
       " u'817',\n",
       " u'1059',\n",
       " u'1068',\n",
       " u'1069',\n",
       " u'1128',\n",
       " u'1157',\n",
       " u'1158',\n",
       " u'1177',\n",
       " u'1178',\n",
       " u'1179',\n",
       " u'1180',\n",
       " u'1181',\n",
       " u'1182',\n",
       " u'1183',\n",
       " u'1197',\n",
       " u'1205',\n",
       " u'1207',\n",
       " u'1208',\n",
       " u'1216',\n",
       " u'1217',\n",
       " u'1252',\n",
       " u'1253',\n",
       " u'1734',\n",
       " u'1789',\n",
       " u'1790',\n",
       " u'1791',\n",
       " u'1792',\n",
       " u'1793',\n",
       " u'1839',\n",
       " u'1840',\n",
       " u'1841',\n",
       " u'1842',\n",
       " u'1843',\n",
       " u'1844',\n",
       " u'1846',\n",
       " u'1847',\n",
       " u'1848',\n",
       " u'1875',\n",
       " u'1876',\n",
       " u'1892',\n",
       " u'1893',\n",
       " u'1894',\n",
       " u'1895',\n",
       " u'1896',\n",
       " u'1897',\n",
       " u'1914',\n",
       " u'1982',\n",
       " u'1986',\n",
       " u'1987',\n",
       " u'2016',\n",
       " u'2017',\n",
       " u'2018',\n",
       " u'2019',\n",
       " u'2020',\n",
       " u'2021',\n",
       " u'2022',\n",
       " u'2023',\n",
       " u'2024',\n",
       " u'2025',\n",
       " u'2028',\n",
       " u'2039',\n",
       " u'2040',\n",
       " u'2041',\n",
       " u'2042',\n",
       " u'2043',\n",
       " u'2044',\n",
       " u'2045',\n",
       " u'2138',\n",
       " u'2139',\n",
       " u'2140',\n",
       " u'2141',\n",
       " u'2146',\n",
       " u'2147',\n",
       " u'2153',\n",
       " u'2154',\n",
       " u'2197',\n",
       " u'2198',\n",
       " u'2211',\n",
       " u'2212',\n",
       " u'2213',\n",
       " u'2214',\n",
       " u'2219',\n",
       " u'2334',\n",
       " u'2335',\n",
       " u'2396',\n",
       " u'2397',\n",
       " u'2398',\n",
       " u'2399',\n",
       " u'2400',\n",
       " u'2401',\n",
       " u'2480',\n",
       " u'2481',\n",
       " u'2482',\n",
       " u'2483',\n",
       " u'2484',\n",
       " u'2485',\n",
       " u'2486',\n",
       " u'2487',\n",
       " u'2488',\n",
       " u'2494',\n",
       " u'2495',\n",
       " u'2496',\n",
       " u'2516',\n",
       " u'2517',\n",
       " u'2518',\n",
       " u'2520',\n",
       " u'2521',\n",
       " u'2522',\n",
       " u'2523',\n",
       " u'2524',\n",
       " u'2525',\n",
       " u'2526',\n",
       " u'2527',\n",
       " u'2538',\n",
       " u'2539',\n",
       " u'2540',\n",
       " u'2541',\n",
       " u'2542',\n",
       " u'2543',\n",
       " u'2544',\n",
       " u'2545',\n",
       " u'2546',\n",
       " u'2664',\n",
       " u'2665',\n",
       " u'2666',\n",
       " u'2770',\n",
       " u'2771',\n",
       " u'2772',\n",
       " u'2773',\n",
       " u'2774',\n",
       " u'2817',\n",
       " u'2820',\n",
       " u'2821',\n",
       " u'2895',\n",
       " u'2912',\n",
       " u'2949',\n",
       " u'2956',\n",
       " u'3048',\n",
       " u'3054',\n",
       " u'3077',\n",
       " u'3079',\n",
       " u'3098',\n",
       " u'3205',\n",
       " u'3219',\n",
       " u'3283',\n",
       " u'3287',\n",
       " u'3288',\n",
       " u'3292',\n",
       " u'3303',\n",
       " u'3304',\n",
       " u'3305',\n",
       " u'3306',\n",
       " u'3307',\n",
       " u'3308',\n",
       " u'3309',\n",
       " u'3310',\n",
       " u'3384',\n",
       " u'3385',\n",
       " u'3404',\n",
       " u'3405',\n",
       " u'3406',\n",
       " u'3407',\n",
       " u'3408',\n",
       " u'3409',\n",
       " u'3410',\n",
       " u'3510',\n",
       " u'3512',\n",
       " u'3544',\n",
       " u'3629',\n",
       " u'3630',\n",
       " u'3679',\n",
       " u'3719',\n",
       " u'3721',\n",
       " u'3723',\n",
       " u'3724',\n",
       " u'3726',\n",
       " u'3727',\n",
       " u'3728',\n",
       " u'3825',\n",
       " u'3826',\n",
       " u'3830',\n",
       " u'3831',\n",
       " u'3838',\n",
       " u'3839',\n",
       " u'3840',\n",
       " u'3871',\n",
       " u'3872',\n",
       " u'3888',\n",
       " u'3932',\n",
       " u'3933',\n",
       " u'3939',\n",
       " u'3966',\n",
       " u'3967',\n",
       " u'4003',\n",
       " u'4004',\n",
       " u'4019',\n",
       " u'4064',\n",
       " u'4065',\n",
       " u'4085',\n",
       " u'4086',\n",
       " u'4099',\n",
       " u'4108',\n",
       " u'4109',\n",
       " u'4110',\n",
       " u'4134',\n",
       " u'4146',\n",
       " u'4147',\n",
       " u'4149',\n",
       " u'4157',\n",
       " u'4324',\n",
       " u'4325',\n",
       " u'4326',\n",
       " u'4343',\n",
       " u'4344',\n",
       " u'4407',\n",
       " u'4441',\n",
       " u'4691',\n",
       " u'4692',\n",
       " u'4693',\n",
       " u'4704',\n",
       " u'4708',\n",
       " u'4748',\n",
       " u'4754',\n",
       " u'4755',\n",
       " u'4781',\n",
       " u'4785',\n",
       " u'4787',\n",
       " u'4797',\n",
       " u'4798',\n",
       " u'4808',\n",
       " u'4809',\n",
       " u'4810',\n",
       " u'4811',\n",
       " u'4813',\n",
       " u'4814',\n",
       " u'4816',\n",
       " u'4993',\n",
       " u'5027',\n",
       " u'5028',\n",
       " u'5029',\n",
       " u'5035',\n",
       " u'5036',\n",
       " u'5050',\n",
       " u'5054',\n",
       " u'5062',\n",
       " u'5063',\n",
       " u'5064',\n",
       " u'5065',\n",
       " u'5066',\n",
       " u'5082',\n",
       " u'5101',\n",
       " u'5267',\n",
       " u'5293',\n",
       " u'5294',\n",
       " u'5320',\n",
       " u'5337',\n",
       " u'5350',\n",
       " u'5351',\n",
       " u'5352',\n",
       " u'5359',\n",
       " u'5360',\n",
       " u'5361',\n",
       " u'5396',\n",
       " u'5398',\n",
       " u'5445',\n",
       " u'5462',\n",
       " u'5464',\n",
       " u'5491',\n",
       " u'5511',\n",
       " u'5563',\n",
       " u'5572',\n",
       " u'5648',\n",
       " u'5662',\n",
       " u'5663',\n",
       " u'5758',\n",
       " u'5761',\n",
       " u'5762',\n",
       " u'5763',\n",
       " u'5787',\n",
       " u'5788',\n",
       " u'5789',\n",
       " u'5792',\n",
       " u'5796',\n",
       " u'5797',\n",
       " u'5817',\n",
       " u'5818',\n",
       " u'5820',\n",
       " u'5830',\n",
       " u'5843',\n",
       " u'5844',\n",
       " u'5845',\n",
       " u'5846',\n",
       " u'5847',\n",
       " u'5848',\n",
       " u'5849',\n",
       " u'5851',\n",
       " u'5920',\n",
       " u'5921',\n",
       " u'5929',\n",
       " u'5930',\n",
       " u'5931',\n",
       " u'5934',\n",
       " u'5935',\n",
       " u'5936',\n",
       " u'6040',\n",
       " u'6061',\n",
       " u'6164',\n",
       " u'6192',\n",
       " u'6194',\n",
       " u'6217',\n",
       " u'6229',\n",
       " u'6231',\n",
       " u'6297',\n",
       " u'6325',\n",
       " u'6326',\n",
       " u'6327',\n",
       " u'6333',\n",
       " u'6351',\n",
       " u'6357']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(config_parameters['list_tiles'], 'rb') as outputfile: \n",
    "    tile_list = pickle.load(outputfile) \n",
    "tile_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get a list of classes in pixel-based classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '5', '6', '11', '12', '31', '32', '41', '42', '91', '92', '93', '94']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import list of class of 'ortho_lc' map\n",
    "with open(config_parameters['pixel_classes_list'], 'rb') as outputfile: \n",
    "    pixel_classes_list = pickle.load(outputfile) \n",
    "pixel_classes_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract classification features by segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define number of cores\n",
    "ncores = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to process 375 tiles on 10 cores\n"
     ]
    }
   ],
   "source": [
    "# Define current tile\n",
    "print \"Going to process %s tiles on %s cores\"%(len(tile_list),ncores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing on tile 1128\n",
      "Start processing on tile 1179\n",
      "Start processing on tile 1217\n",
      "Start processing on tile 1197\n",
      "Start processing on tile 1846\n",
      "Start processing on tile 711\n",
      "Start processing on tile 656\n",
      "Start processing on tile 2016\n",
      "Start processing on tile 1840\n",
      "Start processing on tile 1790\n",
      "Start processing on tile 2021\n",
      "Start processing on tile 1897\n",
      "Start processing on tile 2043\n",
      "Start processing on tile 1892\n",
      "Start processing on tile 2140\n",
      "Start processing on tile 2028\n",
      "Start processing on tile 2154\n",
      "Start processing on tile 2213\n",
      "Start processing on tile 2396\n",
      "Start processing on tile 2401\n",
      "Start processing on tile 2397\n",
      "Start processing on tile 2044\n",
      "Start processing on tile 2141\n",
      "Start processing on tile 2214\n",
      "Start processing on tile 2197\n",
      "Start processing on tile 1252\n",
      "Start processing on tile 1893\n",
      "Start processing on tile 1157\n",
      "Start processing on tile 2480\n",
      "Start processing on tile 1205\n",
      "Start processing on tile 666\n",
      "Start processing on tile 817\n",
      "Start processing on tile 1180\n",
      "Start processing on tile 2022\n",
      "Start processing on tile 2219\n",
      "Start processing on tile 1847\n",
      "Start processing on tile 1841\n",
      "Start processing on tile 2398\n",
      "Start processing on tile 1914\n",
      "Start processing on tile 2045\n",
      "Start processing on tile 2146\n",
      "Start processing on tile 1894\n",
      "Start processing on tile 2198\n",
      "Start processing on tile 1253\n",
      "Start processing on tile 2481\n",
      "Start processing on tile 1181\n",
      "Start processing on tile 2147\n",
      "Start processing on tile 1059\n",
      "Start processing on tile 667\n",
      "Start processing on tile 2334\n",
      "Start processing on tile 2211\n",
      "Start processing on tile 1791\n",
      "Start processing on tile 2399\n",
      "Start processing on tile 1842\n",
      "Start processing on tile 1734\n",
      "Start processing on tile 1207\n",
      "Start processing on tile 1982\n",
      "Start processing on tile 1895\n",
      "Start processing on tile 2138\n",
      "Start processing on tile 2482\n",
      "Start processing on tile 1158\n",
      "Start processing on tile 2039\n",
      "Start processing on tile 2023\n",
      "Start processing on tile 2212\n",
      "Start processing on tile 1068\n",
      "Start processing on tile 680\n",
      "Start processing on tile 2400\n",
      "Start processing on tile 2335\n",
      "Start processing on tile 2153\n",
      "Start processing on tile 1848\n",
      "Start processing on tile 1182\n",
      "Start processing on tile 2484\n",
      "Start processing on tile 1896\n",
      "Start processing on tile 2494\n",
      "Start processing on tile 2483\n",
      "Start processing on tile 2139\n",
      "Start processing on tile 2017\n",
      "Start processing on tile 1789\n",
      "Start processing on tile 2518\n",
      "Start processing on tile 2524\n",
      "Start processing on tile 685\n",
      "Start processing on tile 1792\n",
      "Start processing on tile 1208\n",
      "Start processing on tile 1986\n",
      "Start processing on tile 1875\n",
      "Start processing on tile 1843\n",
      "Start processing on tile 1069\n",
      "Start processing on tile 2040\n",
      "Start processing on tile 2495\n",
      "Start processing on tile 2539\n",
      "Start processing on tile 1183\n",
      "Start processing on tile 2544\n",
      "Start processing on tile 2485\n",
      "Start processing on tile 2666\n",
      "Start processing on tile 2525\n",
      "Start processing on tile 1876\n",
      "Start processing on tile 2774\n",
      "Start processing on tile 2912\n",
      "Start processing on tile 1793\n",
      "Start processing on tile 1177\n",
      "Start processing on tile 2024\n",
      "Start processing on tile 2520\n",
      "Start processing on tile 1987\n",
      "Start processing on tile 1844\n",
      "Start processing on tile 2496\n",
      "Start processing on tile 2041\n",
      "Start processing on tile 2770\n",
      "Start processing on tile 3077\n",
      "Start processing on tile 2540\n",
      "Start processing on tile 1216\n",
      "Start processing on tile 2817\n",
      "Start processing on tile 2486\n",
      "Start processing on tile 2949\n",
      "Start processing on tile 2545\n",
      "Start processing on tile 2526\n",
      "Start processing on tile 3283\n",
      "Start processing on tile 2516\n",
      "Start processing on tile 3304\n",
      "Start processing on tile 2771\n",
      "Start processing on tile 3079\n",
      "Start processing on tile 2521\n",
      "Start processing on tile 3309\n",
      "Start processing on tile 3405\n",
      "Start processing on tile 2820\n",
      "Start processing on tile 3410\n",
      "Start processing on tile 2541\n",
      "Start processing on tile 3406\n",
      "Start processing on tile 1839\n",
      "Start processing on tile 2956\n",
      "Start processing on tile 2025\n",
      "Start processing on tile 2487\n",
      "Start processing on tile 2546\n",
      "Start processing on tile 2042\n",
      "Start processing on tile 3510\n",
      "Start processing on tile 3407\n",
      "Start processing on tile 2522\n",
      "Start processing on tile 3305\n",
      "Start processing on tile 3098\n",
      "Start processing on tile 2517\n",
      "Start processing on tile 2772\n",
      "Start processing on tile 2527\n",
      "Start processing on tile 2018\n",
      "Start processing on tile 3287\n",
      "Start processing on tile 1178\n",
      "Start processing on tile 3306\n",
      "Start processing on tile 2821\n",
      "Start processing on tile 2542\n",
      "Start processing on tile 3307\n",
      "Start processing on tile 3310\n",
      "Start processing on tile 2664\n",
      "Start processing on tile 3048\n",
      "Start processing on tile 3512\n",
      "Start processing on tile 2488\n",
      "Start processing on tile 2773\n",
      "Start processing on tile 3408\n",
      "Start processing on tile 3630\n",
      "Start processing on tile 2523\n",
      "Start processing on tile 3384\n",
      "Start processing on tile 3288\n",
      "Start processing on tile 2538\n",
      "Start processing on tile 2895\n",
      "Start processing on tile 3409\n",
      "Start processing on tile 3205\n",
      "Start processing on tile 3308\n",
      "Start processing on tile 3724\n",
      "Start processing on tile 2543\n",
      "Start processing on tile 3826\n",
      "Start processing on tile 2665\n",
      "Start processing on tile 3840\n",
      "Start processing on tile 3933\n",
      "Start processing on tile 3054\n",
      "Start processing on tile 4004\n",
      "Start processing on tile 4086\n",
      "Start processing on tile 3544\n",
      "Start processing on tile 4134\n",
      "Start processing on tile 4324\n",
      "Start processing on tile 3385\n",
      "Start processing on tile 4407\n",
      "Start processing on tile 4704\n",
      "Start processing on tile 3726\n",
      "Start processing on tile 4781\n",
      "Start processing on tile 3219\n",
      "Start processing on tile 3679\n",
      "Start processing on tile 3292\n",
      "Start processing on tile 3830\n",
      "Start processing on tile 4808\n",
      "Start processing on tile 4814\n",
      "Start processing on tile 3404\n",
      "Start processing on tile 2019\n",
      "Start processing on tile 5029\n",
      "Start processing on tile 5062\n",
      "Start processing on tile 4019\n",
      "Start processing on tile 3629\n",
      "Start processing on tile 3939\n",
      "Start processing on tile 3871\n",
      "Start processing on tile 4099\n",
      "Start processing on tile 4441\n",
      "Start processing on tile 4325\n",
      "Start processing on tile 4708\n",
      "Start processing on tile 3727\n",
      "Start processing on tile 4809\n",
      "Start processing on tile 3831\n",
      "Start processing on tile 3303\n",
      "Start processing on tile 4785\n",
      "Start processing on tile 4146\n",
      "Start processing on tile 3719\n",
      "Start processing on tile 4816\n",
      "Start processing on tile 5035\n",
      "Start processing on tile 5063\n",
      "Start processing on tile 5082\n",
      "Start processing on tile 4064\n",
      "Start processing on tile 5320\n",
      "Start processing on tile 3966\n",
      "Start processing on tile 4691\n",
      "Start processing on tile 4326\n",
      "Start processing on tile 3872\n",
      "Start processing on tile 4748\n",
      "Start processing on tile 4108\n",
      "Start processing on tile 4787\n",
      "Start processing on tile 3721\n",
      "Start processing on tile 3838\n",
      "Start processing on tile 4993\n",
      "Start processing on tile 5337\n",
      "Start processing on tile 5359\n",
      "Start processing on tile 5064\n",
      "Start processing on tile 3728\n",
      "Start processing on tile 4065\n",
      "Start processing on tile 5101\n",
      "Start processing on tile 5036\n",
      "Start processing on tile 3967\n",
      "Start processing on tile 4754\n",
      "Start processing on tile 4109\n",
      "Start processing on tile 2020\n",
      "Start processing on tile 4343\n",
      "Start processing on tile 3723\n",
      "Start processing on tile 3888\n",
      "Start processing on tile 3839\n",
      "Start processing on tile 3825\n",
      "Start processing on tile 5027\n",
      "Start processing on tile 5065\n",
      "Start processing on tile 4810\n",
      "Start processing on tile 4147\n",
      "Start processing on tile 4797\n",
      "Start processing on tile 5350\n",
      "Start processing on tile 5360\n",
      "Start processing on tile 4692\n",
      "Start processing on tile 4085\n",
      "Start processing on tile 5050\n",
      "Start processing on tile 5267\n",
      "Start processing on tile 5351\n",
      "Start processing on tile 4003\n",
      "Start processing on tile 5361\n",
      "Start processing on tile 4110\n",
      "Start processing on tile 3932\n",
      "Start processing on tile 4755\n",
      "Start processing on tile 4344\n",
      "Start processing on tile 5445\n",
      "Start processing on tile 5293\n",
      "Start processing on tile 5028\n",
      "Start processing on tile 5396\n",
      "Start processing on tile 4798\n",
      "Start processing on tile 5563\n",
      "Start processing on tile 5758\n",
      "Start processing on tile 5788\n",
      "Start processing on tile 5817\n",
      "Start processing on tile 5462\n",
      "Start processing on tile 5844\n",
      "Start processing on tile 4149\n",
      "Start processing on tile 4693\n",
      "Start processing on tile 4811\n",
      "Start processing on tile 5066\n",
      "Start processing on tile 5352\n",
      "Start processing on tile 5054\n",
      "Start processing on tile 5464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing on tile 5849\n",
      "Start processing on tile 5930\n",
      "Start processing on tile 5398\n",
      "Start processing on tile 6040\n",
      "Start processing on tile 6217\n",
      "Start processing on tile 5572\n",
      "Start processing on tile 5294\n",
      "Start processing on tile 6326\n",
      "Start processing on tile 5845\n",
      "Start processing on tile 5818\n",
      "Start processing on tile 5789\n",
      "Start processing on tile 4813\n",
      "Start processing on tile 4157\n",
      "Start processing on tile 6229\n",
      "Start processing on tile 5851\n",
      "Start processing on tile 5491\n",
      "Start processing on tile 6327\n",
      "Start processing on tile 5648\n",
      "Start processing on tile 5846\n",
      "Start processing on tile 5511\n",
      "Start processing on tile 6231\n",
      "Start processing on tile 6061\n",
      "Start processing on tile 5931\n",
      "Start processing on tile 5820\n",
      "Start processing on tile 5920\n",
      "Start processing on tile 5792\n",
      "Start processing on tile 6333\n",
      "Start processing on tile 5761\n",
      "Start processing on tile 5847\n",
      "Start processing on tile 6297\n",
      "Start processing on tile 5921\n",
      "Start processing on tile 5934\n",
      "Start processing on tile 5796\n",
      "Start processing on tile 5662\n",
      "Start processing on tile 6164\n",
      "Start processing on tile 5848\n",
      "Start processing on tile 5830\n",
      "Start processing on tile 5929\n",
      "Start processing on tile 6192\n",
      "Start processing on tile 6325\n",
      "Start processing on tile 6351\n",
      "Start processing on tile 5935\n",
      "Start processing on tile 5762\n",
      "Start processing on tile 5797\n",
      "Start processing on tile 5843\n",
      "Start processing on tile 5936\n",
      "Start processing on tile 6357\n",
      "Start processing on tile 6194\n",
      "Start processing on tile 5663\n",
      "Start processing on tile 5763\n",
      "Start processing on tile 5787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Computation (on 20 cores) achieved in 4 hours and 19 minutes and 49.9 seconds'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch processes in parallel\n",
    "start_parallel = start_processing()\n",
    "p = Pool(ncores)\n",
    "output = p.map(GetTileFeatures, tile_list[:])  # Launch the processes for as many items in the list (if function with a return, the returned results are ordered thanks to 'map' function)\n",
    "p.close()\n",
    "p.join()\n",
    "# Print\n",
    "print_processing_time(start_parallel, \"Computation (on %s cores) achieved in \"%ncores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Check log file for ERRORS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375 log files in the folder\n"
     ]
    }
   ],
   "source": [
    "# Get list of csv with classification feature of individual tiles\n",
    "import glob\n",
    "list_log = glob.glob(os.path.join(config_parameters['outputfolder_Logfile'],\"Log_feature_extrac_tile_*.txt\"))\n",
    "print \"%s log files in the folder\"%len(list_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tile(s) faced an ERROR during the processing.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare new counter\n",
    "count = 0\n",
    "# Declare new list that will contain list of tile with error\n",
    "tile_error_list = []\n",
    "# Loop on list of log file\n",
    "for logfile in list_log:\n",
    "    got_error = False\n",
    "    tile_num = os.path.splitext(os.path.basename(logfile))[0].split(\"_\")[-1]\n",
    "    fin = open(logfile, 'r')\n",
    "    for row in fin:\n",
    "        if row[:5] == \"ERROR\":  # If at least one line have error message, the whole file will be counted as 1 error\n",
    "            got_error = True\n",
    "    if got_error:    \n",
    "        count += 1\n",
    "        tile_error_list.append(tile_num)  # Add tile number to the list\n",
    "# Print\n",
    "print \"%s tile(s) faced an ERROR during the processing.\\n\"%count\n",
    "\n",
    "# Update tile list with only tiles that have ERROR in log \n",
    "print \"\\n\".join([\"Error on tile %s\"%(a) for a in tile_error_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tile_error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
