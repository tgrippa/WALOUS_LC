{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><font size=\"6\">WALOUS</font></strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><font size=\"6\">Fusion LC classifications results</font></strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><font size=\"6\">Postprocessing - Resampling 1m Vectorisation etc..</font></strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WALOUS_OCS_FUSION - Copyright (C) <2020> <Service Public de Wallonie (SWP), Belgique,\n",
    "\t\t\t\t\t          \t\tInstitut Scientifique de Service Public (ISSeP), Belgique,\n",
    "\t\t\t\t\t\t\t\t\tUniversité catholique de Louvain (UCLouvain), Belgique,\n",
    "\t\t\t\t\t\t\t\t\tUniversité Libre de Bruxelles (ULB), Belgique>\n",
    "\t\t\t\t\t\t \t\t\t\t\t\t\t\n",
    "\t\n",
    "List of the contributors to the development of WALOUS_OCS_FUSION: see LICENSE file.\n",
    "Description and complete License: see LICENSE file.\n",
    "\t\n",
    "This program (WALOUS_OCS_FUSION) is free software: \n",
    "you can redistribute it and/or modify it under the terms of the \n",
    "GNU General Public License as published by the Free Software \n",
    "Foundation, either version 3 of the License, or (at your option) \n",
    "any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program (see COPYING file).  If not, \n",
    "see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This python code implement the method developed by ANAGEO (ULB). \n",
    "\n",
    "Code developped on Linux Mint 18.1 (Ubuntu Xenial 16.04) and GRASS GIS 7.3.svn (r71315)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is a Javascript section of code for building the Jupyter notebook's table of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define working environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.14 (default, Oct 12 2017, 15:50:02) [GCC]\n"
     ]
    }
   ],
   "source": [
    "# Import libraries needed for setting parameters of operating system \n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import tempfile\n",
    "import subprocess\n",
    "import glob\n",
    "import pickle\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import multiprocessing and functools libraries\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Add folder with SCR provided belong to this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add local module to the path\n",
    "src = os.path.abspath('/export/miro/cbassine/fusion/RF_fusion/WALOUS-master/SRC')\n",
    "if src not in sys.path:\n",
    "    sys.path.append(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Setup environment variables for TAIS DESKTOP (Linux Mint + GRASS Dev) **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please edit the file in `../SRC/config.py`, containing the configuration parameters, according to your own computer setup. The following cell is used to run this file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run /export/miro/cbassine/fusion/RF_fusion/WALOUS-master/SRC/config_postprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'list_tiles': '/export/miro/cbassine/fusion/RF_fusion/Postprocess6/list_tiles', 'outputfolder_Logfile': '/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Log_file', 'permanent_mapset': 'PERMANENT', 'GRASSBIN': '/usr/bin/grass78', 'locationepsg': '31370', 'outputfolder': '/export/miro/cbassine/fusion/RF_fusion/Postprocess6', 'outputfolder_Vecteur': '/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur', 'gisdb': '/export/miro/cbassine/GRASSDATA', 'location': 'WALOUS_31370', 'PYTHONLIB': '/usr/bin/python2.7', 'njobs': 6, 'outputfolder_Raster': '/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Raster', 'GISBASE': '/usr/lib64/grass78'}\n"
     ]
    }
   ],
   "source": [
    "print config_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"module load gdal/2.2.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions that setup the environmental variables\n",
    "import environ_variables as envi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LESS = -M -I -R \t\n",
      "BASH_ENV = /usr/share/lmod/7.6.1/init/bash \t\n",
      "CPU = x86_64 \t\n",
      "BASH_FUNC_module%% = () {  eval $($LMOD_CMD bash \"$@\") && eval $(${LMOD_SETTARG_CMD:-:} -s sh)\n",
      "} \t\n",
      "SSH_CONNECTION = 10.36.1.8 57890 10.36.22.8 22 \t\n",
      "SHELL = /bin/bash \t\n",
      "XDG_DATA_DIRS = /usr/share \t\n",
      "HISTSIZE = 1000 \t\n",
      "_ModuleTable003_ = aSIsfSx9LG1wYXRoQT17Ii91c3Ivc2hhcmUvbW9kdWxlcyIsIi91c3Ivc2hhcmUvbG1vZC9tb2R1bGVmaWxlcyIsfSxbInN5c3RlbUJhc2VNUEFUSCJdPSIvdXNyL3NoYXJlL2xtb2QvbW9kdWxlZmlsZXMiLH0= \t\n",
      "LESS_ADVANCED_PREPROCESSOR = no \t\n",
      "MANPATH = /usr/lib64/mpi/gcc/openmpi/share/man:/usr/local/man:/usr/local/share/man:/usr/share/man \t\n",
      "JAVA_HOME = /usr/lib64/jvm/jre-1.8.0-openjdk \t\n",
      "PROFILEREAD = true \t\n",
      "XDG_RUNTIME_DIR = /run/user/49919 \t\n",
      "JPY_PARENT_PID = 1463 \t\n",
      "PYTHONPATH = /export/apps/os151/OTB-7.0.0/lib/otb/python:/export/apps/os151/gdal-3.0.1/gdal/lib64/python3.6/site-packages:/usr/lib64/grass78/etc/python:/usr/lib64/grass78/etc/python/grass:/usr/lib64/grass78/etc/python/grass/script \t\n",
      "GISRC = /export/homes/cbassine/.grass7/rc \t\n",
      "XDG_SESSION_ID = 1337 \t\n",
      "DBUS_SESSION_BUS_ADDRESS = unix:path=/run/user/49919/bus \t\n",
      "CONFIG_SITE = /usr/share/site/x86_64-unknown-linux-gnu \t\n",
      "HOSTNAME = geo08 \t\n",
      "_ModuleTable002_ = ImFjdGl2ZSIsWyJ1c2VyTmFtZSJdPSJlbmdlIix9LGdkYWw9e1siZm4iXT0iL3Vzci9zaGFyZS9tb2R1bGVzL2dkYWwvMy4wLjEubHVhIixbImZ1bGxOYW1lIl09ImdkYWwvMy4wLjEiLFsibG9hZE9yZGVyIl09Mixwcm9wVD17fSxbInN0YWNrRGVwdGgiXT0yLFsic3RhdHVzIl09ImFjdGl2ZSIsWyJ1c2VyTmFtZSJdPSJnZGFsIix9LFsibmV0Y2RmLW9wZW5tcGkiXT17WyJmbiJdPSIvdXNyL3NoYXJlL21vZHVsZXMvbmV0Y2RmLW9wZW5tcGkvNC42LjEiLFsiZnVsbE5hbWUiXT0ibmV0Y2RmLW9wZW5tcGkvNC42LjEiLFsibG9hZE9yZGVyIl09MSxwcm9wVD17fSxbInN0YWNrRGVwdGgiXT0zLFsic3RhdHVzIl09ImFjdGl2ZSIsWyJ1c2VyTmFtZSJdPSJuZXRjZGYtb3Blbm1w \t\n",
      "MAIL = /var/mail/cbassine \t\n",
      "LS_COLORS = no=00:fi=00:di=01;34:ln=00;36:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=41;33;01:ex=00;32:*.cmd=00;32:*.exe=01;32:*.com=01;32:*.bat=01;32:*.btm=01;32:*.dll=01;32:*.tar=00;31:*.tbz=00;31:*.tgz=00;31:*.rpm=00;31:*.deb=00;31:*.arj=00;31:*.taz=00;31:*.lzh=00;31:*.lzma=00;31:*.zip=00;31:*.zoo=00;31:*.z=00;31:*.Z=00;31:*.gz=00;31:*.bz2=00;31:*.tb2=00;31:*.tz2=00;31:*.tbz2=00;31:*.xz=00;31:*.avi=01;35:*.bmp=01;35:*.dl=01;35:*.fli=01;35:*.gif=01;35:*.gl=01;35:*.jpg=01;35:*.jpeg=01;35:*.mkv=01;35:*.mng=01;35:*.mov=01;35:*.mp4=01;35:*.mpg=01;35:*.pcx=01;35:*.pbm=01;35:*.pgm=01;35:*.png=01;35:*.ppm=01;35:*.svg=01;35:*.tga=01;35:*.tif=01;35:*.webm=01;35:*.webp=01;35:*.wmv=01;35:*.xbm=01;35:*.xcf=01;35:*.xpm=01;35:*.aiff=00;32:*.ape=00;32:*.au=00;32:*.flac=00;32:*.m4a=00;32:*.mid=00;32:*.mp3=00;32:*.mpc=00;32:*.ogg=00;32:*.voc=00;32:*.wav=00;32:*.wma=00;32:*.wv=00;32: \t\n",
      "C_INCLUDE_PATH = /usr/lib64/mpi/gcc/openmpi/include \t\n",
      "GOPATH = /export/homes/cbassine/go:/usr/share/go/1.9/contrib \t\n",
      "GRASSBIN = /usr/bin/grass78 \t\n",
      "JAVA_ROOT = /usr/lib64/jvm/jre-1.8.0-openjdk \t\n",
      "GOROOT = /usr/lib64/go/1.9 \t\n",
      "MINICOM = -c on \t\n",
      "CSHEDIT = emacs \t\n",
      "LESSOPEN = lessopen.sh %s \t\n",
      "LMOD_FULL_SETTARG_SUPPORT = no \t\n",
      "CPLUS_INCLUDE_PATH = /usr/lib64/mpi/gcc/openmpi/include \t\n",
      "CVS_RSH = ssh \t\n",
      "USER = cbassine \t\n",
      "PROJ_LIB = /export/apps/os151/gdal-3.0.1/gdal/share/proj \t\n",
      "SHLVL = 1 \t\n",
      "BASH_FUNC_ml%% = () {  eval $($LMOD_DIR/ml_cmd \"$@\")\n",
      "} \t\n",
      "XKEYSYMDB = /usr/X11R6/lib/X11/XKeysymDB \t\n",
      "GOARCH = amd64 \t\n",
      "MODULESHOME = /usr/share/lmod/lmod \t\n",
      "JAVA_BINDIR = /usr/lib64/jvm/jre-1.8.0-openjdk/bin \t\n",
      "_ModuleTable001_ = X01vZHVsZVRhYmxlXz17WyJNVHZlcnNpb24iXT0zLFsiY19yZWJ1aWxkVGltZSJdPWZhbHNlLFsiY19zaG9ydFRpbWUiXT1mYWxzZSxkZXB0aFQ9e30sZmFtaWx5PXt9LG1UPXtPVEI9e1siZm4iXT0iL3Vzci9zaGFyZS9tb2R1bGVzL09UQi83LjAuMC5sdWEiLFsiZnVsbE5hbWUiXT0iT1RCLzcuMC4wIixbImxvYWRPcmRlciJdPTMscHJvcFQ9e30sWyJzdGFja0RlcHRoIl09MSxbInN0YXR1cyJdPSJhY3RpdmUiLFsidXNlck5hbWUiXT0iT1RCIix9LGVuZ2U9e1siZm4iXT0iL3Vzci9zaGFyZS9tb2R1bGVzL2VuZ2UvMS4wLjAubHVhIixbImZ1bGxOYW1lIl09ImVuZ2UvMS4wLjAiLFsibG9hZE9yZGVyIl09NCxwcm9wVD17fSxbInN0YWNrRGVwdGgiXT0wLFsic3RhdHVzIl09 \t\n",
      "LMOD_VERSION = 7.6.1 \t\n",
      "LS_OPTIONS = -N --color=tty -T 0 \t\n",
      "XNLSPATH = /usr/X11R6/lib/X11/nls \t\n",
      "_ = /export/homes/cbassine/.local/bin/jupyter \t\n",
      "MODULEPATH = /usr/share/modules:/usr/share/lmod/modulefiles \t\n",
      "MACHTYPE = x86_64-suse-linux \t\n",
      "XDG_CONFIG_DIRS = /etc/xdg \t\n",
      "WINDOWMANAGER = xterm \t\n",
      "COLORTERM = 1 \t\n",
      "_LMFILES_ = /usr/share/modules/netcdf-openmpi/4.6.1:/usr/share/modules/gdal/3.0.1.lua:/usr/share/modules/OTB/7.0.0.lua:/usr/share/modules/enge/1.0.0.lua \t\n",
      "PAGER = cat \t\n",
      "LMOD_DIR = /usr/share/lmod/lmod/libexec \t\n",
      "LIBGL_DEBUG = quiet \t\n",
      "LMOD_PKG = /usr/share/lmod/lmod \t\n",
      "HOME = /export/homes/cbassine \t\n",
      "LD_LIBRARY_PATH = /export/apps/os151/OTB-7.0.0/lib64:/export/apps/os151/OTB-7.0.0/lib:/export/apps/os151/gdal-3.0.1/gdal/lib64:/usr/lib64/mpi/gcc/openmpi/lib64:/usr/lib64/grass78/lib \t\n",
      "LANG = en_US.UTF-8 \t\n",
      "LIBRARY_PATH = /usr/lib64/mpi/gcc/openmpi/lib64 \t\n",
      "G_BROKEN_FILENAMES = 1 \t\n",
      "_ModuleTable_Sz_ = 3 \t\n",
      "OSTYPE = linux \t\n",
      "G_FILENAME_ENCODING = @locale,UTF-8,ISO-8859-15,CP1252 \t\n",
      "LMOD_CMD = /usr/share/lmod/lmod/libexec/lmod \t\n",
      "HOST = geo08 \t\n",
      "GIT_PAGER = cat \t\n",
      "GPG_TTY = /dev/pts/5 \t\n",
      "FROM_HEADER =  \t\n",
      "LESSCLOSE = lessclose.sh %s %s \t\n",
      "SSH_TTY = /dev/pts/5 \t\n",
      "KERNEL_LAUNCH_TIMEOUT = 40 \t\n",
      "CPATH = /usr/lib64/mpi/gcc/openmpi/include \t\n",
      "JRE_HOME = /usr/lib64/jvm/jre \t\n",
      "MORE = -sl \t\n",
      "LMOD_SETTARG_CMD = : \t\n",
      "HOSTTYPE = x86_64 \t\n",
      "SSH_CLIENT = 10.36.1.8 57890 22 \t\n",
      "LOGNAME = cbassine \t\n",
      "PATH = /export/homes/cbassine/.local/bin:/export/apps/os151/enge/bin:/export/homes/cbassine/.otb/bin-7.0:/export/apps/os151/OTB-7.0.0/bin:/export/apps/os151/gdal-3.0.1/gdal/bin_p3:/export/apps/os151/gdal-3.0.1/gdal/bin:/usr/lib64/mpi/gcc/openmpi/bin:/usr/local/bin:/usr/bin:/bin:/usr/lib/mit/sbin:/usr/lib64/grass78/bin:/usr/lib64/grass78/scripts:/usr/lib64/grass78/lib \t\n",
      "GISBASE = /usr/lib64/grass78 \t\n",
      "TERM = xterm-color \t\n",
      "LMOD_PREPEND_BLOCK = normal \t\n",
      "LMOD_COLORIZE = no \t\n",
      "GOOS = linux \t\n",
      "LESSKEY = /etc/lesskey.bin \t\n",
      "GDAL_DIR = /export/apps/os151/gdal-3.0.1/gdal \t\n",
      "DISPLAY = localhost:11.0 \t\n",
      "PYTHONSTARTUP = /etc/pythonstart \t\n",
      "OLDPWD = /export/homes/cbassine \t\n",
      "LOADEDMODULES = netcdf-openmpi/4.6.1:gdal/3.0.1:OTB/7.0.0:enge/1.0.0 \t\n",
      "CLICOLOR = 1 \t\n",
      "PWD = /export/homes/cbassine/fusion/RF_fusion/WALOUS-master \t\n",
      "OTB_APPLICATION_PATH = /export/homes/cbassine/.otb/applications-7.0:/export/apps/os151/OTB-7.0.0/lib/otb/applications \t\n",
      "PYTHONLIB = /usr/bin/python2.7 \t\n",
      "GIS_LOCK = $$ \t\n",
      "MPLBACKEND = module://ipykernel.pylab.backend_inline \t\n",
      "XAUTHLOCALHOSTNAME = geo08 \t\n"
     ]
    }
   ],
   "source": [
    "# Set environmental variables\n",
    "envi.setup_environmental_variables() \n",
    "# Display current environment variables of your computer\n",
    "envi.print_environmental_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** GRASS GIS Python libraries **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRASSBIN: /usr/bin/grass78\n",
      "GISBASE: /usr/lib64/grass78\n"
     ]
    }
   ],
   "source": [
    "from grass_session import Session\n",
    "# Import libraries needed to launch GRASS GIS in the jupyter notebook\n",
    "import grass.script.setup as gsetup\n",
    "# Import libraries needed to call GRASS using Python\n",
    "import grass.script as gscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Other functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function that check existance and create GRASS GIS database folder if needed\n",
    "from grass_database import check_gisdb, check_location, check_mapset, working_mapset\n",
    "# Import functions for processing time information\n",
    "from processing_time import start_processing, print_processing_time\n",
    "# Import function that generate a random name in the GRASS GIS environement\n",
    "from random_layer_name import random_layer_name\n",
    "# Import function that check and create folder\n",
    "from mkdir import check_create_dir\n",
    "# Import function that check if GRASS GIS add-on is installed and install it if needed\n",
    "from gextension import check_install_addon\n",
    "# Import function for .gzip archive management\n",
    "from gzip_management import decompress_gzip\n",
    "# Import function for computation of proportion of categorical raster in zones (segments)\n",
    "from compute_proportion_categorical import CategoStats\n",
    "# Import function for getting list of class of a raster\n",
    "from data_prep import data_prep\n",
    "# Import function the allow sorting strings with number as if they was number (natural order)\n",
    "from sorting_natural import natural_keys\n",
    "# Import function that compute ERP on csv file\n",
    "from EquivalentReferenceProbability import ComputeERPfromCsv\n",
    "# Import function that replace \"empty\" values from output .csv to zero\n",
    "from CsvEmptyValues import CsvChangeEmptyByO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function that check and create folder\n",
    "from mkdir import check_create_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function that generate a random name in the GRASS GIS environement\n",
    "from random_layer_name import random_layer_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function that check existance and create GRASS GIS database folder if needed\n",
    "from grass_database import check_gisdb, check_location, check_mapset, working_mapset\n",
    "# Import functions for processing time information\n",
    "from processing_time import start_processing, print_processing_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_mapset(mapset):\n",
    "    #Declare empty list that will contain the messages to return\n",
    "    return_message = []\n",
    "    # Check if the location exists and create it if not, with the CRS defined by the epsg code \n",
    "    return_message.append(check_location(config_parameters[\"gisdb\"],config_parameters['location'],config_parameters[\"locationepsg\"]))\n",
    "    # Check if mapset exists\n",
    "    return_message.append(check_mapset(config_parameters[\"gisdb\"],config_parameters['location'],mapset))\n",
    "    # Change the current working GRASS GIS session mapset\n",
    "    return_message.append(working_mapset(config_parameters[\"gisdb\"],config_parameters['location'],mapset))\n",
    "    # Check if a DB connexion exist and create it if not exists\n",
    "    gscript.run_command('db.connect', quiet=True, flags='c')\n",
    "    # Return\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMapsetsAccess(list_mapsets):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        # Add mapsets with input data to the GRASS GIS research path\n",
    "        for mapset in list_mapsets:\n",
    "            gscript.run_command('g.mapsets', quiet=True, mapset=mapset, operation=\"add\")\n",
    "        return_message = \"Access to other mapset added\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Add access to other Mapsets failed. Please check for problem.\"\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DefineComputationRegionAndMask(tile_cat,resamp_resolution='1', grow_mmu='16'):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        return_message = \"Working on tile '%s'\\n\"%tile_cat\n",
    "        # 'Grow' parameter is used to expend the computational region ouside of the current tile to deal with bordering objects smaller than MMU\n",
    "        gscript.run_command('g.region', flags='a', raster='RF_fusion_tile_%s'%tile_cat, \n",
    "                            res=resamp_resolution, grow=grow_mmu)\n",
    "        # Define MASK for clipping at the end\n",
    "        gscript.run_command('r.mask', overwrite=True, quiet=True, raster='RF_fusion_tile_%s'%tile_cat) \n",
    "        gscript.run_command('g.copy', overwrite=True, quiet=True, raster='MASK,MASK_tile25') #25cm resolution mask following the original limit of the tile\n",
    "        gscript.run_command('r.mask', quiet=True, flags='r') #Remove mask\n",
    "        # Define MASK for processing (overlapping with the neighboring tiles)\n",
    "        gscript.run_command('r.buffer', overwrite=True, quiet=True, input='MASK_tile25', \n",
    "                            output='MASK_tmp', distances=grow_mmu)\n",
    "        rulefile = gscript.tempfile()\n",
    "        with open(rulefile, 'w') as f:\n",
    "            f.write('2 = 1\\n* = *') #Reclass rule\n",
    "        gscript.run_command('r.reclass', overwrite=True, quiet=True, input='MASK_tmp', output='MASK_processing', rules=rulefile)\n",
    "        # Print\n",
    "        return_message += \"--> Setting of computational region and masks succeeded.\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Setting of computional region and masks failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resamp(tile_cat):\n",
    "    #Resample classification \n",
    "    return_message = ''\n",
    "    try:\n",
    "        gscript.run_command('r.mask', overwrite=True, quiet=True, raster='MASK_processing') \n",
    "        gscript.run_command('r.resamp.stats', overwrite=True, quiet=True, input='fusion_lc', \n",
    "                            output='resamp', method='mode')\n",
    "        #Ensure for CEL type by creating a new map using r.mapcalc\n",
    "        gscript.mapcalc('resamp_tmp=int(resamp)', overwrite=True, quiet=True) \n",
    "        gscript.run_command('g.rename', overwrite=True, quiet=True, raster='resamp_tmp,resamp')\n",
    "        #Make a copy of the resampled map, nammed ' that will be used as first tmp map for the reclassification\n",
    "        gscript.run_command('g.copy', overwrite=True, quiet=True, raster='resamp,reclass_tmp')\n",
    "        return_message += \"--> Resampling succeeded.\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Resampling for tile '%s' failed. Please check for problem.\"%tile_cat\n",
    "    return return_message   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetForestryMask(tile_cat, schrink_growth_radius, overwrite=True):\n",
    "    #Create forest mask\n",
    "    return_message = ''\n",
    "    try:\n",
    "        #Initial forest mask (class 8 and 9 dans la fusion)\n",
    "        formula = \"forestmask_binary=if((resamp==8||resamp==9),1,null())\"\n",
    "        gscript.mapcalc(formula, overwrite=overwrite, quiet=True)\n",
    "        #Moving window modal filter\n",
    "        gscript.run_command('r.neighbors', overwrite=True, quiet=True, input='forestmask_binary',\n",
    "                            output='forestmask_binary_neighbors', method='mode', size='5')\n",
    "        gscript.run_command('g.rename', overwrite=True, quiet=True, raster='forestmask_binary_neighbors,forestmask_binary')\n",
    "        #Schrinking\n",
    "        gscript.run_command('r.grow', overwrite=True, quiet=True, input='forestmask_binary',\n",
    "                            output='forestmask_binary_shrink', radius='-%s'%schrink_growth_radius, old='1', new='1')\n",
    "        #Growing\n",
    "        gscript.run_command('r.grow', overwrite=True, quiet=True, input='forestmask_binary_shrink',\n",
    "                            output='forestmask_binary_grow', radius='%s'%schrink_growth_radius, old='1', new='1')\n",
    "        gscript.run_command('g.remove', flags='f', quiet=True, type='raster', name='forestmask_binary_shrink')\n",
    "        gscript.run_command('g.rename', overwrite=True, quiet=True, raster='forestmask_binary_grow,forestmask_binary')\n",
    "        # Print\n",
    "        return_message += \"--> Creation of forest mask succeeded.\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Creation of forest mask failed for tile '%s' failed. Please check for problem.\"%tile_cat\n",
    "    return return_message   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Function to generate and execute an SQL insert query based on input 'table_name','head' and 'value_dict'. \n",
    "The key of the dictionnary 'value_dict' should will be the first column of the table (unique id) and the values should\n",
    "contain a list with the values (the other columns). Please be sure that len('head') == 1+len(value_dict[key])\n",
    "\"\"\"\n",
    "def SqlInsert(table_name, header, value_dict, overwrite=True):\n",
    "    sql_query = gscript.tempfile()\n",
    "    fsql = open(sql_query, 'w')\n",
    "    fsql.write('BEGIN TRANSACTION;\\n')\n",
    "    if gscript.db_table_exist(table_name):\n",
    "        if overwrite:\n",
    "            fsql.write('DROP TABLE %s;\\n' % table_name)\n",
    "        else:\n",
    "            gscript.fatal(_(\"Table %s already exists. Use 'overwrite=True' to overwrite\" % table_name))\n",
    "    create_statement = 'CREATE TABLE ' + table_name + ' (cat int PRIMARY KEY);\\n'\n",
    "    fsql.write(create_statement)\n",
    "    for col in header[1:]:\n",
    "        if col.split('_')[-1] == 'cat':  # Mode column should be integer\n",
    "            addcol_statement = 'ALTER TABLE %s ADD COLUMN %s integer;\\n' % (table_name, col)\n",
    "        else: # Proportions column should be double precision\n",
    "            addcol_statement = 'ALTER TABLE %s ADD COLUMN %s double precision;\\n' % (table_name, col)\n",
    "        fsql.write(addcol_statement)\n",
    "    for key in value_dict:\n",
    "            insert_statement = 'INSERT INTO %s VALUES (%s, %s);\\n' % (table_name, key, ','.join([str(x) for x in value_dict[key]]))\n",
    "            fsql.write(insert_statement)\n",
    "    fsql.write('END TRANSACTION;')\n",
    "    fsql.close()\n",
    "    gscript.run_command('db.execute', input=sql_query, quiet=True)\n",
    "\n",
    "'''\n",
    "Function to compute shape statistics for each clump and import it as table in GRASS GIS\n",
    "'''\n",
    "def GetClumpShapeStatistics(overwrite=True):\n",
    "    # Path to temporary file for 'r.object.geometry' output\n",
    "    tmp_csv = \"%s_robjectgeometry\"%gscript.tempfile() #definit tmp_csv comme un fichier temporaire\n",
    "    # Compute shape statistics for each clump\n",
    "    gscript.run_command('r.object.geometry', overwrite=True, flags='m', input='clump', output=tmp_csv) #calculates geometry parameters for raster objects\n",
    "    ### clump from \"r.clump\" recategorizes data in a raster map by grouping cells that form physically discrete areas into unique categories\n",
    "    # Load csv content in python dictionnary\n",
    "    incsv = open(tmp_csv, 'r')\n",
    "    reader = csv.reader(incsv, delimiter='|')\n",
    "    header = reader.next()\n",
    "    value_dict = {row[0]:row[1:] for row in reader}\n",
    "    incsv.close()\n",
    "    # Insert SQL\n",
    "    table_name = \"geom\"\n",
    "    SqlInsert(table_name, header, value_dict, overwrite=True)\n",
    "    \n",
    "'''\n",
    "Function to retrieve the land cover class of each clump and import it as table in GRASS GIS\n",
    "'''\n",
    "#recuperation de la classe de LC pour chaque groupe (clump) \n",
    "def GetClumpLCClass(overwrite=True):\n",
    "    # Path to temporary file for 'r.object.geometry' output\n",
    "    tmp_csv = \"%s_runivar\"%gscript.tempfile() \n",
    "    # Compute r.univar to get class label of the clump\n",
    "    gscript.run_command('r.univar', overwrite=True, quiet=True, flags='t', map='reclass_tmp', zones='clump', output=tmp_csv)\n",
    "    ## r.univar = calculates univariate statistics from the non-null cells of a raster map, flag -t for a table output\n",
    "    # Load csv content in python dictionnary\n",
    "    incsv = open(tmp_csv, 'r')\n",
    "    reader = csv.reader(incsv, delimiter='|')\n",
    "    reader.next() # Skip the first row (header)\n",
    "    header = [\"cat\",\"label\"] # Create a header with custom column name\n",
    "    value_dict = {row[0]:row[4:5] for row in reader} #Take only the column corresponding to 'min'\n",
    "    incsv.close()\n",
    "    # Insert SQL\n",
    "    table_name = \"label\"\n",
    "    SqlInsert(table_name, header, value_dict, overwrite)\n",
    "\n",
    "'''\n",
    "Function to know information on each clump to know if it belong to the forestry mask\n",
    "'''\n",
    "def GetForestMaskInfo(overwrite=True):\n",
    "    # Path to temporary file for 'r.object.geometry' output\n",
    "    #tmp_csv = \"%s_rzonalclasses_forest\"%gscript.tempfile()\n",
    "    tmp_csv = \"%s_rzonalcount_forest\"%gscript.tempfile()\n",
    "    #gscript.run_command('r.zonal.classes', flags='n', overwrite=True, quiet=True,\n",
    "                        #zone_map='clump', raster='forestmask_binary', statistics='mode', csvfile=tmp_csv)\n",
    "    gscript.run_command('r.stats.zonal', overwrite=True, quiet=True,\n",
    "                        cover='forestmask_binary', base='clump', method='count', output='rzonal_sum')\n",
    "    gscript.run_command('r.stats.zonal', overwrite=True, quiet=True,\n",
    "                        cover='clump', base='clump', method='count', output='rzonal_count')\n",
    "    #formula = \"proportion=if(((rzonal_sum/rzonal_count)>=0.5),1,null())\"\n",
    "    formula= \"proportion=(float(rzonal_sum)/float(rzonal_count)>=0.5?1:0)\"\n",
    "    gscript.run_command('r.mapcalc',expression=formula, overwrite=overwrite, quiet=True)\n",
    "    gscript.run_command('r.univar', overwrite=True, quiet=True, flags='t', map='proportion', zones='clump', output=tmp_csv)\n",
    "    ## r.zonal.classes = calculates zonal classes proportion describing raster areas's composition\n",
    "    # Load csv content in python dictionnary\n",
    "    incsv = open(tmp_csv, 'r')\n",
    "    #incsv_count = open(tmp_csv_count, 'r')\n",
    "    reader = csv.reader(incsv, delimiter='|')\n",
    "    reader.next() # Skip the first row (header)\n",
    "    header = [\"cat\",\"forest_mask\"] # Create a header with custom column name\n",
    "    #value_dict = {row[0]:(row[1] if row[1]!=\"NULL\" else '0') for row in reader} #Take only the column corresponding to 'min'    #value_dict = {row[0]:row[2] if row[2]>0.5 else '0' for row in reader_count}\n",
    "    value_dict={row[0]:row[4] for row in reader}\n",
    "    incsv.close()\n",
    "    #Insert SQL\n",
    "    table_name = \"forestry_mask\"\n",
    "    SqlInsert(table_name, header, value_dict, overwrite)\n",
    "\n",
    "'''\n",
    "Function to retrieve the neighborhood of each clump and import it as table in GRASS GIS\n",
    "'''\n",
    "def GetClumpNeighbor(overwrite=True):\n",
    "    # Path to temporary file for 'r.object.geometry' output\n",
    "    tmp_csv = \"%s_neighbor\"%gscript.tempfile()\n",
    "    # Compute neighborhood matrix\n",
    "    gscript.run_command('r.neighborhoodmatrix', overwrite=True, flags='l', input='clump', output=tmp_csv) #Calculates geometry parameters for raster objects, -l length of common border\n",
    "    #r.neighborhoodmatrix identifies all adjacency relations between objects \n",
    "    #(aka segments or clumps identified by identical integer cell values of adjacent pixels) \n",
    "    # in a raster map and exports these as a 2xn matrix where n is the number of neighborhood relations \n",
    "    # with each relation listed in both directions (i.e. if a is neighbor of b, the list will contain a,b and b,a). \n",
    "    # If a path to an output file is specified, the matrix will be written to that file, \n",
    "    #otherwise it will be sent to standard output.\n",
    "    \n",
    "    # Load csv content in python dictionnary\n",
    "    incsv = open(tmp_csv, 'r')\n",
    "    reader = csv.reader(incsv, delimiter='|')\n",
    "    header = [\"cat\",\"sega\",\"segb\",\"border_count\"] # Create a header\n",
    "    value_dict = {id_:row[:] for id_,row in enumerate(reader)}\n",
    "    incsv.close()\n",
    "    # Insert SQL\n",
    "    table_name = \"rmatrix\"\n",
    "    SqlInsert(table_name, header, value_dict, overwrite)\n",
    "\n",
    "\"\"\" \n",
    "Function to pivot rmatrix table to horizontal table with proportion to each class\n",
    "\"\"\"\n",
    "def GetNeighborClassProportion(overwrite=True):\n",
    "    global labels_list #fction qui permet de modifier une variable depuis le corps d'une fonction\n",
    "    ### Table 'tmp_a'\n",
    "    table_name = \"tmp_a\"\n",
    "    sql_query = gscript.tempfile()\n",
    "    fsql = open(sql_query, 'w')\n",
    "    fsql.write('BEGIN TRANSACTION;\\n')\n",
    "    if gscript.db_table_exist(table_name):\n",
    "        if overwrite:\n",
    "            fsql.write('DROP TABLE %s;\\n'%table_name)\n",
    "        else:\n",
    "            gscript.fatal(_(\"Table %s already exists. Use 'overwrite=True' to overwrite\"%table_name))\n",
    "    create_statement = 'CREATE TABLE %s AS '%table_name\n",
    "    create_statement += 'SELECT a.sega, b.label, border_count FROM rmatrix AS a '\n",
    "    create_statement += 'LEFT JOIN label AS b ON a.segb=b.cat;\\n'\n",
    "    fsql.write(create_statement)\n",
    "    fsql.write('END TRANSACTION;')\n",
    "    fsql.close()\n",
    "    gscript.run_command('db.execute', input=sql_query, quiet=True)\n",
    "    \n",
    "    ### Table 'tmp_b'\n",
    "    table_name = \"tmp_b\"\n",
    "    sql_query = gscript.tempfile()\n",
    "    fsql = open(sql_query, 'w')\n",
    "    fsql.write('BEGIN TRANSACTION;\\n')\n",
    "    if gscript.db_table_exist(table_name):\n",
    "        if overwrite:\n",
    "            fsql.write('DROP TABLE %s;\\n'%table_name)\n",
    "        else:\n",
    "            gscript.fatal(_(\"Table %s already exists. Use 'overwrite=True' to overwrite\"%table_name))\n",
    "    create_statement = 'CREATE TABLE %s AS WITH '%table_name\n",
    "    create_statement += 'border_lenght AS (SELECT sega, sum(border_count) AS sum_border FROM tmp_a GROUP BY sega),'\n",
    "    create_statement += 'tempotable AS (SELECT a.sega, a.label, round((a.border_count*1.0/b.sum_border*1.0),8) AS percent_border FROM tmp_a AS a LEFT JOIN border_lenght AS b ON a.sega=b.sega)'\n",
    "    create_statement += 'SELECT sega AS seg, label, sum(percent_border) AS percent_border FROM tempotable GROUP BY sega, label ORDER BY sega, label;\\n'\n",
    "    create_statement += 'UPDATE %s SET percent_border=1.0 WHERE percent_border>0.9999;\\n'%table_name\n",
    "    create_statement += 'UPDATE %s SET percent_border=0.0 WHERE percent_border<0.0001;\\n'%table_name\n",
    "    fsql.write(create_statement)\n",
    "    fsql.write('END TRANSACTION;')\n",
    "    fsql.close()\n",
    "    gscript.run_command('db.execute', input=sql_query, quiet=True)\n",
    "    \n",
    "    ### Table 'pivot_prop_label'\n",
    "    table_name = \"pivot_prop_label\"\n",
    "    # Get distinct values for 'label' class\n",
    "    distinctlabelquery=\"SELECT DISTINCT label FROM tmp_b ORDER BY 1\"\n",
    "#    labels_list = [x[0] for x in gscript.db_select(distinctlabelquery)] #According to classes that exist in the table\n",
    "    labels_list = ['1','2','21','3','4','5','6','7','8','9','80','90','202'] #Forcing according to classes that should be included in the table\n",
    "    # Declaration of colums for the pivot table\n",
    "    columns=[\"seg INTEGER\",]\n",
    "    [columns.append(\"prop_%s NUMERIC\"%label) for label in labels_list]\n",
    "    # Crosstab query argument\n",
    "    crosstabquery = \"SELECT seg, label, percent_border FROM tmp_b ORDER  BY 1,2\"\n",
    "    # Built complete sql query\n",
    "    sql_query = gscript.tempfile()\n",
    "    fsql = open(sql_query, 'w')\n",
    "    fsql.write('BEGIN TRANSACTION;\\n')\n",
    "    if gscript.db_table_exist(table_name):\n",
    "        if overwrite:\n",
    "            fsql.write('DROP TABLE %s;\\n'%table_name)\n",
    "        else:\n",
    "            gscript.fatal(_(\"Table %s already exists. Use 'overwrite=True' to overwrite\"%table_name))\n",
    "    # Create statement for the pivot table\n",
    "    pivot_statement = \"SELECT seg, \"\n",
    "    pivot_statement += ', '.join([\"SUM(CASE WHEN label = '%s' THEN percent_border END) AS prop_%s\"%(cl,cl) for cl in labels_list])\n",
    "    pivot_statement += \" FROM tmp_b GROUP BY seg\"\n",
    "    create_statement = \"CREATE TABLE %s AS %s;\\n\"%(table_name,pivot_statement)\n",
    "    fsql.write(create_statement)\n",
    "    # List of update queries to update each column\n",
    "    [fsql.write(\"UPDATE %s SET prop_%s=0.0 WHERE prop_%s is null;\\n\"%(table_name,label,label)) for label in labels_list]\n",
    "    fsql.write('END TRANSACTION;')\n",
    "    fsql.close()\n",
    "    gscript.run_command('db.execute', input=sql_query, quiet=True)\n",
    "\n",
    "\"\"\" \n",
    "Function to \n",
    "\"\"\"\n",
    "\n",
    "def AddLabelNthNeighbor(tile_cat, overwrite=True):\n",
    "    # The trick was found here: https://stackoverflow.com/questions/8436919/second-maximum-and-minimum-values\n",
    "    # To be able to run the command directly in GRASS, be sure the version of SQlite used in compilation is >3.25\n",
    "    # The function used here is available only for recent version https://stackoverflow.com/questions/50332436/syntax-error-when-using-row-number-in-sqlite3r\n",
    "    # Get the largest, second largest and third largest value\n",
    "    ### SQL query\n",
    "    table_name = \"rank_prop\"\n",
    "    sql_query = gscript.tempfile()\n",
    "    fsql = open(sql_query, 'w')\n",
    "    fsql.write('BEGIN TRANSACTION;\\n')\n",
    "    if gscript.db_table_exist('tmp_c'):\n",
    "        if overwrite:\n",
    "            fsql.write(\"DROP TABLE tmp_c;\\n\")\n",
    "        else:\n",
    "            gscript.fatal(_(\"Table 'tmp_c' already exists. Use 'overwrite=True' to overwrite\"))\n",
    "    subquery = \"SELECT seg, percent_border, row_number() OVER ( \"\n",
    "    subquery += \"PARTITION BY seg order by percent_border DESC) as rnDesc FROM tmp_B\"\n",
    "    create_statement = \"CREATE TABLE tmp_c AS \"\n",
    "    create_statement += 'SELECT seg, '\n",
    "    create_statement += 'MAX(CASE when rnDesc = 1 THEN percent_border END) as first_prop, '\n",
    "    create_statement += 'MAX(CASE when rnDesc = 2 THEN percent_border END) as second_prop, '\n",
    "    create_statement += 'MAX(CASE when rnDesc = 3 THEN percent_border END) as third_prop '\n",
    "    create_statement += 'from(%s) as SubQueryAlias GROUP BY seg;\\n'%subquery\n",
    "    fsql.write(create_statement)\n",
    "\n",
    "    if gscript.db_table_exist(table_name):\n",
    "        if overwrite:\n",
    "            fsql.write(\"DROP TABLE %s;\\n\"%table_name)\n",
    "        else:\n",
    "            gscript.fatal(_(\"Table '%s' already exists. Use 'overwrite=True' to overwrite\"%table_name))\n",
    "    create_statement = \"CREATE TABLE %s AS \"%table_name\n",
    "    create_statement += 'SELECT a.*,b.first_prop,b.second_prop,b.third_prop FROM pivot_prop_label AS a LEFT JOIN tmp_C AS b ON a.seg=b.seg;\\n'\n",
    "    fsql.write(create_statement)\n",
    "    alter_statement = \"ALTER TABLE %s ADD COLUMN first_label integer;\\n\"%table_name\n",
    "    alter_statement += \"ALTER TABLE %s ADD COLUMN second_label integer;\\n\"%table_name\n",
    "    alter_statement += \"ALTER TABLE %s ADD COLUMN third_label integer;\\n\"%table_name\n",
    "    fsql.write(alter_statement)   \n",
    "    update_queries = []\n",
    "    for label in labels_list:\n",
    "        update_queries.append(\"UPDATE {t} SET first_label={l} WHERE first_prop=prop_{l}\".format(t=table_name, l=label))\n",
    "        update_queries.append(\"UPDATE {t} SET second_label={l} WHERE second_prop=prop_{l}\".format(t=table_name, l=label))\n",
    "        update_queries.append(\"UPDATE {t} SET third_label={l} WHERE third_prop=prop_{l}\".format(t=table_name, l=label))\n",
    "    fsql.write(\";\\n\".join(update_queries))\n",
    "    fsql.write(\";\\n\")\n",
    "    fsql.write('END TRANSACTION;')\n",
    "    fsql.close()    \n",
    "    # Bash file\n",
    "    bash_sqlite = gscript.tempfile()\n",
    "    bash = open(bash_sqlite, 'w')\n",
    "    bash.write('sqlite3 /export/miro/cbassine/GRASSDATA/WALOUS_31370/%s/sqlite/sqlite.db < %s'%(tile_cat,sql_query))\n",
    "    bash.close() \n",
    "    try:\n",
    "        subprocess.check_call(['bash', bash_sqlite], stderr=subprocess.STDOUT, )\n",
    "    except subprocess.CalledProcessError:\n",
    "        message =  \"There was an error in the execution of the bash script.\\nPlease check and fix.\"\n",
    "\n",
    "\"\"\" \n",
    "Function to join all information together\n",
    "\"\"\"\n",
    "def GetFinalJoinedTable(overwrite=True):\n",
    "    ### Table 'pivot_final'\n",
    "    table_name = \"pivot_final\"\n",
    "    sql_query = gscript.tempfile()\n",
    "    fsql = open(sql_query, 'w')\n",
    "    fsql.write('BEGIN TRANSACTION;\\n')\n",
    "    if gscript.db_table_exist(table_name):\n",
    "        if overwrite:\n",
    "            fsql.write('DROP TABLE %s;\\n'%table_name)\n",
    "        else:\n",
    "            gscript.fatal(_(\"Table %s already exists. Use 'overwrite=True' to overwrite\"%table_name))\n",
    "    create_statement = 'CREATE TABLE %s AS '%table_name\n",
    "    create_statement += 'SELECT a.cat AS seg, a.label, g.area, f.forest_mask, p.* FROM label AS a '\n",
    "    create_statement += 'LEFT JOIN geom AS g ON a.cat=g.cat '\n",
    "    create_statement += 'LEFT JOIN forestry_mask AS f ON a.cat=f.cat '\n",
    "    create_statement += 'LEFT JOIN rank_prop AS p ON a.cat=p.seg ;\\n'\n",
    "    fsql.write(create_statement)\n",
    "    fsql.write(\"ALTER TABLE %s ADD COLUMN reclass integer;\\n\"%table_name)   \n",
    "    fsql.write('END TRANSACTION;')\n",
    "    fsql.close()\n",
    "    gscript.run_command('db.execute', input=sql_query, quiet=True)\n",
    "\n",
    "\"\"\" \n",
    "Function to remove all intermediate tables\n",
    "\"\"\"\n",
    "def RemoveIntermediateTables(overwrite=True):\n",
    "    list_tables_to_remove = ['label','forestry_mask','geom','rmatrix','tmp_a','tmp_b','tmp_c','pivot_prop_label','rank_prop']\n",
    "    sql_query = gscript.tempfile()\n",
    "    fsql = open(sql_query, 'w')\n",
    "    fsql.write('BEGIN TRANSACTION;\\n')\n",
    "    for table_name in list_tables_to_remove:\n",
    "        if gscript.db_table_exist(table_name):\n",
    "            if overwrite:\n",
    "                fsql.write('DROP TABLE %s;\\n'%table_name)\n",
    "            else:\n",
    "                gscript.fatal(_(\"Table %s already exists. Use 'overwrite=True' to overwrite\"%table_name))\n",
    "    fsql.write('END TRANSACTION;')\n",
    "    fsql.close()\n",
    "    gscript.run_command('db.execute', input=sql_query, quiet=True)\n",
    "    \n",
    "\"\"\" \n",
    "Wrapper function that create clump and compute neighborhood information for reclassification using rules\n",
    "\"\"\"\n",
    "def GetNeighborStat(tile_cat, overwrite=True):\n",
    "    # Define region based on 1m resampled LC\n",
    "    gscript.run_command('g.region', raster='reclass_tmp')\n",
    "    # Clump to get unique ID for each LC patch\n",
    "    gscript.run_command('r.clump', overwrite=True, quiet=True,\n",
    "                        flags='d', input='reclass_tmp', output='clump')  # flag '-d' to clump also diagonal cells\n",
    "    GetClumpShapeStatistics(overwrite=True)\n",
    "    GetClumpLCClass(overwrite=True)\n",
    "    GetForestMaskInfo(overwrite=True)\n",
    "    GetClumpNeighbor(overwrite=True)\n",
    "    GetNeighborClassProportion(overwrite=True)\n",
    "    AddLabelNthNeighbor(tile_cat, overwrite=True)\n",
    "    GetFinalJoinedTable(overwrite=True)\n",
    "    RemoveIntermediateTables(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReclassAccordingToRule(tile_cat, list_case_statement, intermediate=True, overwrite=True):\n",
    "    #Reclassify clump layer according to CASE statements \n",
    "    return_message = ''    \n",
    "    try:\n",
    "        #Recompute clumps and neighborhood information\n",
    "        GetNeighborStat(tile_cat, overwrite=True)\n",
    "        #Update SQLite table with reclass column \n",
    "        return_message = ''\n",
    "        table_name = \"pivot_final\"\n",
    "        if not gscript.db_table_exist(table_name):\n",
    "            gscript.fatal(_(\"Table '%s' already exists. Use 'overwrite=True' to overwrite\"%table_name))\n",
    "        sql_query = gscript.tempfile()\n",
    "        fsql = open(sql_query, 'w')\n",
    "        fsql.write('BEGIN TRANSACTION;\\n')\n",
    "        fsql.write(\"UPDATE {t} SET reclass = NULL;\\n\".format(t=table_name))\n",
    "        for case_statement in list_case_statement:\n",
    "            fsql.write(\"UPDATE {t} SET reclass = ({case});\\n\".format(t=table_name, case=case_statement))\n",
    "        fsql.write(\"UPDATE {t} SET reclass = label WHERE reclass IS NULL;\\n\".format(t=table_name))\n",
    "        fsql.write('END TRANSACTION;')\n",
    "        fsql.close() \n",
    "        gscript.run_command('db.execute', input=sql_query, quiet=True)\n",
    "        #Create r.reclass rule file and reclass the clump map.\n",
    "        query = \"SELECT seg, reclass FROM pivot_final\"\n",
    "        reclass_rule = gscript.tempfile()\n",
    "        reclass = open(reclass_rule, 'w')\n",
    "        [reclass.write(\"%s = %s\\n\"%(x[0],x[1])) for x in gscript.db_select(query)]\n",
    "        reclass.close()\n",
    "        #r.reclass\n",
    "        if intermediate:\n",
    "            output_name = 'reclass_tmp'\n",
    "        else:\n",
    "            output_name = 'resamp_mmu'\n",
    "        gscript.run_command('r.reclass', overwrite=True, input='clump', output=output_name, rules=reclass_rule)\n",
    "        #Create a 'hard' copy of the reclassed raster\n",
    "        gscript.mapcalc('%s_tmp=%s'%(output_name,output_name),overwrite=True,quiet=True)\n",
    "        gscript.run_command('g.rename',overwrite=True,quiet=True,raster='%s_tmp,%s'%(output_name,output_name))\n",
    "        gscript.run_command('r.out.gdal', overwrite=True, input='%s'%(output_name), output='/export/miro/cbassine/tmp/%s.tif'%(output_name), format='GTiff', createopt='COMPRESS=DEFLATE')\n",
    "        # Print\n",
    "        return_message += \"--> Reclassification of clumps succeeded.\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Reclassification of clumps failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClipToTileBorder(tile_cat, rasterlist):\n",
    "    #Clipping raster to match tile's border \n",
    "    return_message = ''\n",
    "    for rastername in rasterlist:\n",
    "        try:\n",
    "            gscript.run_command('r.mask', overwrite=True, quiet=True, raster='MASK_tile25') \n",
    "            gscript.run_command('r.clip', overwrite=True, quiet=True,\n",
    "                                input='%s'%rastername, output='tmp_%s'%rastername)\n",
    "            gscript.run_command('r.mask', quiet=True, flags='r') \n",
    "            gscript.run_command('g.rename', overwrite=True, quiet=\n",
    "                                True, raster='tmp_%s,%s'%(rastername,rastername))\n",
    "            return_message += \"--> Clip raster '%s' to correspond to tile border.\"%rastername\n",
    "        except:\n",
    "            return_message += \"ERROR: Clipping raster '%s' to tile border failed for cutline '%s'. Please check for problem.\"%(rastername,tile_cat)\n",
    "        if rastername != rasterlist[-1]: return_message += \"\\n\"\n",
    "    return return_message   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ColorizeRaster(tile_cat, rasterlist):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    for rastername in rasterlist:\n",
    "        try:\n",
    "            gscript.run_command('r.colors', map=rastername, rules=data['color_file'])\n",
    "            return_message += \"--> Application of colors table succeeded.\"\n",
    "        except:\n",
    "            return_message += \"ERROR: Application of colors table on raster failed for tile %s. Please check for problem.\"%tile_cat\n",
    "        if rastername != rasterlist[-1]: return_message += \"\\n\"\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorize(tile_cat):\n",
    "    #Resample classification \n",
    "    return_message = ''\n",
    "    try:\n",
    "        gscript.run_command('r.to.vect', flags='s', overwrite=True, quiet=True,\n",
    "                            input='RF_fusion_tile_%s'%tile_cat, output='vect', type='area', column='class')\n",
    "        #gscript.run_command('r.to.vect', overwrite=True, quiet=True,\n",
    "                            #input='resamp_mmu', output='vect_staircase', type='area', column='class')\n",
    "        return_message += \"--> Vectorization succeeded.\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Vectorization of raster map failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def VectorSmooth(tile_cat, thresh_value=\"1000000\", iter_value=\"2\"):\n",
    "    #Resample classification \n",
    "    return_message = ''\n",
    "    try:\n",
    "        gscript.run_command('v.generalize', overwrite=True, quiet=True, input='vect', type='area', output='vect_smooth', \n",
    "                            method='chaiken', threshold=thresh_value, iterations=iter_value)\n",
    "        return_message += \"--> Smoothing of vector layer succeeded.\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Smoothing of vector layer failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def VectorGeneralize(tile_cat, thresh_value=\"10000000\", iter_value=\"3\"):\n",
    "    #Resample classification \n",
    "    return_message = ''\n",
    "    try:\n",
    "        gscript.run_command('v.generalize', overwrite=True, quiet=True, input='vect', type='area', output='vect_generalize', \n",
    "                            method='douglas', threshold=thresh_value, iterations=iter_value)\n",
    "        return_message += \"--> Smoothing of vector layer succeeded.\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Smoothing of vector layer failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ColorizeVector(tile_cat):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        gscript.run_command('v.colors', map='vect', use='attr',\n",
    "                            column='class', rules=data['color_file'])\n",
    "        gscript.run_command('v.colors', map='vect_staircase', use='attr',\n",
    "                            column='class', rules=data['color_file'])\n",
    "        gscript.run_command('v.colors', map='vect_smooth', use='attr',\n",
    "                            column='class', rules=data['color_file'])\n",
    "        return_message += \"--> Application of colors table for vector layer succeeded.\"\n",
    "    except:\n",
    "        return_message += \"ERROR: Application of colors table on vector failed for tile %s. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExportRast(tile_cat, rasterlist):\n",
    "    global list_rast_fusion\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    for rastername in rasterlist:\n",
    "        print rastername\n",
    "        try:\n",
    "        # Export raster\n",
    "            export_dir = os.path.join(config_parameters['outputfolder_Raster'],rastername)\n",
    "            #check_create_dir(export_dir)\n",
    "            export_path = os.path.join(export_dir,\"LC_%s_tile_%s.tif\"%(rastername,tile_cat))\n",
    "            gscript.run_command('r.out.gdal', quiet=True, overwrite=True, input=rastername, output=export_path,\n",
    "                                format='GTiff', createopt='COMPRESS=DEFLATE') #Use flag c to not export colortable. Flag m to not export non-standard format of meta-data\n",
    "            return_message += \"--> Export of raster '%s' succeeded.\"%rastername\n",
    "        except:\n",
    "            return_message += \"ERROR: Export of raster '%s' failed for cutline '%s'. Please check for problem.\"%(rastername,tile_cat)\n",
    "        if rastername != rasterlist[-1]: return_message += \"\\n\"\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExportVect(tile_cat, vectlist):\n",
    "    global list_rast_fusion\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    for vectname in vectlist:\n",
    "        print vectname\n",
    "        try:\n",
    "            # Export vector\n",
    "            export_dir = os.path.join(config_parameters['outputfolder_Vecteur'],vectname)\n",
    "            print export_dir\n",
    "            #check_create_dir(export_dir, quiet=False)\n",
    "            export_path = os.path.join(export_dir, \"LC_%s_tile_%s.gpkg\"%(vectname,tile_cat))\n",
    "            print export_path\n",
    "            gscript.run_command('v.out.ogr', quiet=False, overwrite=True,  input=vectname,\n",
    "                                output=export_path, format='GPKG', flags='m') #Use flag c to not export colortable. Flag m to not export non-standard format of meta-data\n",
    "            return_message += \"--> Export of vector succeeded.\"\n",
    "        except:\n",
    "            return_message += \"ERROR: Export of vector failed for cutline '%s'. Please check for problem.\"%tile_cat\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean(tile_cat):\n",
    "    #Declare empty string that will contain the messages to return\n",
    "    return_message = ''\n",
    "    try:\n",
    "        for layer in list_rast_fusion:\n",
    "            gscript.run_command('g.remove', quiet=True, flags='f', type=\"raster\", name=layer)\n",
    "        return_message += \"--> Mapset cleaned\"\n",
    "    except:\n",
    "        return_message += \"ERROR: during mapset cleaning. Please check for problem.\"\n",
    "    return return_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Worker(tile_cat):\n",
    "    import subprocess\n",
    "    start_tile = start_processing() \n",
    "    print \"Start processing on tile %s\"%tile_cat\n",
    "    #Declare empty list for saving output messages\n",
    "    output_message = [] \n",
    "    \n",
    "    # Launch mapset\n",
    "    message = launch_mapset(tile_cat)  \n",
    "    [output_message.append(a) for a in message]\n",
    "    print \"\\n\".join(message)\n",
    "\n",
    "    # Allow access to other mapset \n",
    "    message = GetMapsetsAccess([\"FUSIONS\"])\n",
    "    output_message.append(message)\n",
    "    print message\n",
    "    \n",
    "    # Define computional region and mask\n",
    "    message = DefineComputationRegionAndMask(tile_cat,resamp_resolution='1', grow_mmu='16')\n",
    "    output_message.append(message)\n",
    "    print message    \n",
    "\n",
    "    # Resample\n",
    "    #message = Resamp(tile_cat)\n",
    "    #output_message.append(message)\n",
    "    #print message \n",
    "    \n",
    "    # Create forestry mask\n",
    "    #message = GetForestryMask(tile_cat, schrink_growth_radius='15', overwrite=True)\n",
    "    #output_message.append(message)\n",
    "    #print message \n",
    "\n",
    "    # 1. Reclassification (removing MMU) according to rules \n",
    "    # MMU of 15m everywhere with special rule to prevent growing of buildings from small patches sharing the largest border with a building\n",
    "    #message = ReclassAccordingToRule(tile_cat,\n",
    "     #   [\"CASE WHEN area < 15 AND label not in (11,18,19,21,26,28,29,31,38,39,58,59) THEN CASE WHEN first_label = 2 THEN second_label ELSE first_label END END\",],\n",
    "          #overwrite=True, intermediate=True)\n",
    "    #output_message.append(message)\n",
    "    #print message \n",
    "    \n",
    "    #2. Reclassification (removing MMU) according to rules \n",
    "    # MMU of 500m in forest only for 8 and 9\n",
    "    #message = ReclassAccordingToRule(tile_cat,\n",
    "     #   [\"CASE WHEN forest_mask = 1 AND area < 500 THEN CASE WHEN label in (8,9) THEN first_label ELSE label END END\",],\n",
    "      #  overwrite=True, intermediate=True)\n",
    "    #output_message.append(message)\n",
    "    #print message \n",
    "    \n",
    "    # 3. Reclassification (removing MMU) according to rules \n",
    "    # MMU of 500m for the crops\n",
    "    #message = ReclassAccordingToRule(tile_cat,\n",
    "     #   [\"CASE WHEN label = 6 AND area < 500 THEN CASE WHEN first_label = 2 THEN second_label ELSE first_label END END\",],\n",
    "      #  overwrite=True, intermediate=True)\n",
    "    #output_message.append(message)\n",
    "    #print message \n",
    "    \n",
    "    # Reclassification (removing MMU) according to rules \n",
    "    # MMU of 500m for the crops\n",
    "    #message = ReclassAccordingToRule(tile_cat,\n",
    "     #   [\"CASE WHEN label = 6 AND area < 500 THEN first_label ELSE label END\",],\n",
    "      #  overwrite=True, intermediate=True)\n",
    "    #output_message.append(message)\n",
    "    #print message \n",
    "    \n",
    "    # 4. Reclassification (removing MMU) according to rules \n",
    "    # MMU de 200m pour les patches mixtes de sols nus et sols imperméabilisés\n",
    "    #message = ReclassAccordingToRule(tile_cat,\n",
    "    #    [\"CASE WHEN label in (1,4) AND area < 200 THEN CASE WHEN first_label in (1,4) THEN first_label ELSE label END END\",],\n",
    "    #    overwrite=True, intermediate=False)\n",
    "    #output_message.append(message)\n",
    "    \n",
    "    # Clip raster to match the extend of the initial tiles\n",
    "    #message = ClipToTileBorder(tile_cat, ['resamp_mmu'])\n",
    "    #output_message.append(message)\n",
    "    #print message \n",
    "\n",
    "    # ColorizeRaster\n",
    "    #message = ColorizeRaster(tile_cat, ['resamp_mmu'])\n",
    "    #output_message.append(message)\n",
    "#    print message\n",
    "    \n",
    "    # ExportRast \n",
    "    #message = ExportRast(tile_cat, ['resamp_mmu'])\n",
    "    #output_message.append(message)\n",
    "#    print message\n",
    "\n",
    "    # Vectorize\n",
    "    message = Vectorize(tile_cat)\n",
    "    output_message.append(message)\n",
    "    print message \n",
    "\n",
    "    # Vector - Smoothing\n",
    "    #message = VectorSmooth(tile_cat, thresh_value=\"10000000\", iter_value=\"3\")\n",
    "    #output_message.append(message)\n",
    "    #print message \n",
    "\n",
    "    # Vector - Generalization\n",
    "    #message = VectorSmooth()\n",
    "    #output_message.append(message)\n",
    "#    print message \n",
    "\n",
    "    # ColorizeVector\n",
    "    #message = ColorizeVector(tile_cat)\n",
    "    #output_message.append(message)\n",
    "    #print message \n",
    "\n",
    "    # ExportVect \n",
    "    #message = ExportVect(tile_cat, ['vect','vect_smooth','vect_staircase'])\n",
    "    message = ExportVect(tile_cat, ['vect'])\n",
    "    output_message.append(message)\n",
    "    print message\n",
    "\n",
    "    # Clean \n",
    "    #message = Clean(tile_cat)\n",
    "    #output_message.append(message)\n",
    "    #print message\n",
    "\n",
    "    #Print processing time\n",
    "    message = print_processing_time(start_tile, \"Prediction for tile '%s' achieved in \"%tile_cat)\n",
    "    output_message.append(message)\n",
    "#    print message\n",
    "    \n",
    "    #Export Log file\n",
    "    fout = open(os.path.join(config_parameters['outputfolder_Logfile'],\"Log_Prediction_tile_%s.txt\"%tile_cat),\"w\")\n",
    "    [fout.writelines('%s\\n'%content) for content in output_message]\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder '/export/miro/cbassine/fusion/RF_fusion/Postprocess6' already exists\n",
      "The folder '/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Log_file' has been created\n",
      "The folder '/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Raster' already exists\n",
      "The folder '/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur' already exists\n"
     ]
    }
   ],
   "source": [
    "# Check and create folder if needed\n",
    "check_create_dir(config_parameters['outputfolder'])\n",
    "check_create_dir(config_parameters['outputfolder_Logfile'])\n",
    "check_create_dir(config_parameters['outputfolder_Raster'])\n",
    "check_create_dir(config_parameters['outputfolder_Vecteur'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import fusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run /export/miro/cbassine/fusion/RF_fusion/WALOUS-master/SRC/config_postprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Location 'WALOUS_31370' already exist\",\n",
       " \"'FUSIONS' mapset already exists in location 'WALOUS_31370'\",\n",
       " \"You are now working in mapset 'WALOUS_31370/FUSIONS'\"]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create mapset \n",
    "launch_mapset(\"FUSIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 262 paths in the list\n"
     ]
    }
   ],
   "source": [
    "# Create a list of paths to files with a specific name prefix\n",
    "list_of_raster=[]\n",
    "list_file = glob.glob(os.path.join(data['fusion_folder'][1],\"RF_fusion_tile_*.tif\"))\n",
    "[list_of_raster.append((os.path.splitext(a)[0].split(os.sep)[-1],a)) for a in list_file]\n",
    "print \"There are %s paths in the list\"%len(list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '10', '15', '3', '4', '8', '7', '14', '11', '17', '20', '16', '13', '0', '19', '6', '5', '18', '23', '24', '9', '12', '22', '25', '21', '30', '35', '26', '39', '31', '37', '304', '44', '43', '32', '28', '42', '47', '49', '38', '51', '56', '40', '52', '50', '57', '59', '45', '48', '46', '36', '54', '62', '58', '60', '65', '61', '72', '71', '68', '67', '66', '34', '79', '78', '69', '27', '76', '63', '84', '70', '74', '64', '77', '86', '73', '83', '80', '88', '91', '81', '89', '55', '82', '96', '95', '93', '97', '85', '100', '90', '87', '103', '101', '107', '94', '105', '306', '108', '114', '106', '113', '111', '99', '98', '117', '112', '110', '104', '109', '127', '122', '119', '123', '118', '126', '75', '121', '116', '129', '128', '124', '120', '309', '310', '311', '315', '313', '312', '319', '308', '115', '307', '323', '149', '151', '125', '152', '321', '155', '318', '324', '322', '161', '159', '316', '92', '314', '150', '166', '164', '165', '168', '317', '169', '162', '170', '158', '171', '173', '174', '175', '167', '156', '176', '178', '320', '179', '177', '163', '157', '153', '183', '182', '181', '172', '160', '184', '154', '186', '187', '195', '194', '190', '199', '191', '192', '180', '200', '188', '205', '204', '189', '198', '201', '197', '202', '211', '193', '212', '207', '196', '203', '217', '219', '218', '215', '210', '209', '223', '214', '208', '185', '224', '221', '222', '230', '220', '213', '228', '233', '206', '236', '226', '237', '227', '242', '239', '229', '231', '240', '235', '243', '216', '238', '249', '225', '250', '244', '232', '248', '247', '252', '253', '251', '241', '255', '234', '245', '254', '261', '257', '260', '246', '258', '259', '256', '300', '301', '302', '303', '305']\n"
     ]
    }
   ],
   "source": [
    "list_for_import=[]\n",
    "list_file = glob.glob(os.path.join(data['fusion_folder'][1],\"RF_fusion_tile_*.tif\"))\n",
    "#[list_for_import.append((os.path.splitext(a)[0].split(os.sep)[-1].split(os.sep)[-1])) for a in list_file]\n",
    "[list_for_import.append((a[-20:-4]).split('_')[-1]) for a in list_file]\n",
    "print list_for_import"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#POUR IMPORT DANS GRASS MANUEL PARCE QUE ERREUR\n",
    "# Input contains an invalid SRS. WKT definition:\n",
    "#LOCAL_CS[\"Belge 1972 / Belgian Lambert 72\",GEOGCS[\"Belge\n",
    "#1972\",DATUM[\"unknown\",SPHEROID[\"unretrievable - using\n",
    "#WGS84\",6378137,298.257223563],TOWGS84[-99.059,53.322,-112.486,0.419,-0.83,1.885,-1]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433]],AUTHORITY[\"EPSG\",\"31370\"],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]\n",
    "#ERROR: Unable to convert input map projection information to GRASS format.\n",
    "\n",
    "import grass.script as gscript\n",
    "\n",
    "list=['1', '2', '21', '20', '39', '77', '79', '78', '97', '98', '96', '99', '100', '115', '119', '116', '118', '117', '134', '135', '138', '136', '137', '153', '155', '154', '156', '157', '172', '173', '174', '175', '176', '177', '179', '178', '191', '192', '193', '194', '195', '196', '197', '198', '210', '211', '212', '213', '214', '216', '215', '229', '230', '231', '232', '233', '235', '234', '249', '250', '251', '252', '254', '253', '268', '269', '270', '272', '271', '274', '273', '287', '288', '289', '291', '290', '292', '293', '294', '295', '296', '297', '298', '306', '308', '307', '309', '311', '310', '312', '313', '314', '315', '316', '317', '325', '326', '328', '327', '329', '331', '330', '332', '333', '336', '334', '335', '345', '346', '347', '344', '348', '350', '351', '349', '352', '355', '353', '354', '362', '363', '365', '366', '364', '369', '367', '368', '371', '370', '372', '374', '373', '381', '383', '382', '384', '385', '386', '389', '387', '390', '388', '391', '392', '400', '402', '403', '401', '404', '405', '406', '408', '407', '409', '411', '410', '419', '420', '421', '422', '423', '424', '425', '426', '427', '429', '428', '438', '439', '440', '441', '443', '442', '445', '446', '444', '447', '448', '450', '451', '449', '452', '457', '458', '459', '460', '461', '462', '463', '464', '465', '466', '468', '467', '469', '470', '471', '476', '477', '478', '479', '480', '481', '482', '483', '484', '485', '486', '487', '488', '490', '489', '496', '497', '498', '499', '500', '502', '504', '503', '501', '505', '506', '510', '508', '509', '507', '515', '516', '517', '519', '518', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '534', '536', '537', '535', '538', '540', '539', '541', '542', '543', '545', '544', '546', '548', '547', '552', '553', '554', '555', '556', '557', '558', '559', '561', '560', '562', '563', '564', '565', '566', '568', '567', '571', '572', '573', '576', '575', '574', '577', '579', '578', '580', '581', '582', '584', '583', '585', '588', '586', '587', '590', '591', '594', '593', '592', '595', '596', '597', '598', '599', '600', '601', '602', '604', '603', '608', '605', '606', '607', '609', '610', '612', '611', '613', '614', '615', '616', '617', '618', '619', '620', '621', '622', '623', '624', '627', '625', '626', '628', '629', '630', '631', '632', '633', '634', '635', '636', '637', '638', '639', '640', '641', '642', '643', '644', '646', '645', '647', '648', '650', '649', '651', '652', '653', '655', '654', '656', '657', '658', '660', '659', '661', '662', '664', '666', '663', '667', '668', '671', '669', '670', '672', '673', '674', '675', '676', '677', '680', '681', '682', '683', '685', '686', '687', '688', '689', '690', '691', '694', '693', '695', '692', '700', '701', '702', '704', '705', '707', '706', '708', '709', '710', '713', '712', '711', '725', '724', '728', '726', '727', '730', '729', '731', '732', '743', '744', '745', '748', '747', '746', '750', '749', '751', '763', '764', '765', '768', '767', '766', '784', '785', '786', '805']\n",
    "for r in list:\n",
    "    gscript.run_command('r.in.gdal', overwrite=True, input=\"K:\\\\fusion\\\\RF_fusion\\\\Results_RW\\\\fusion_bytile_LB72\\RF_fusion_tile_%s.tif\"%r, output=\"RF_fusion_tile_%s\"%r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1',\n",
       " u'2',\n",
       " u'3',\n",
       " u'4',\n",
       " u'5',\n",
       " u'6',\n",
       " u'7',\n",
       " u'8',\n",
       " u'9',\n",
       " u'10',\n",
       " u'11',\n",
       " u'12',\n",
       " u'13',\n",
       " u'14',\n",
       " u'15',\n",
       " u'16',\n",
       " u'17',\n",
       " u'18',\n",
       " u'19',\n",
       " u'20',\n",
       " u'21',\n",
       " u'22',\n",
       " u'23',\n",
       " u'24',\n",
       " u'25',\n",
       " u'26',\n",
       " u'27',\n",
       " u'28',\n",
       " u'29',\n",
       " u'30',\n",
       " u'31',\n",
       " u'32',\n",
       " u'33',\n",
       " u'34',\n",
       " u'35',\n",
       " u'36',\n",
       " u'37',\n",
       " u'38',\n",
       " u'39',\n",
       " u'40',\n",
       " u'41',\n",
       " u'42',\n",
       " u'43',\n",
       " u'44',\n",
       " u'45',\n",
       " u'46',\n",
       " u'47',\n",
       " u'48',\n",
       " u'49',\n",
       " u'50',\n",
       " u'51',\n",
       " u'52',\n",
       " u'53',\n",
       " u'54',\n",
       " u'55',\n",
       " u'56',\n",
       " u'57',\n",
       " u'58',\n",
       " u'59',\n",
       " u'60',\n",
       " u'61',\n",
       " u'62',\n",
       " u'63',\n",
       " u'64',\n",
       " u'65',\n",
       " u'66',\n",
       " u'67',\n",
       " u'68',\n",
       " u'69',\n",
       " u'70',\n",
       " u'71',\n",
       " u'72',\n",
       " u'73',\n",
       " u'74',\n",
       " u'75',\n",
       " u'76',\n",
       " u'77',\n",
       " u'78',\n",
       " u'79',\n",
       " u'80',\n",
       " u'81',\n",
       " u'82',\n",
       " u'83',\n",
       " u'84',\n",
       " u'85',\n",
       " u'86',\n",
       " u'87',\n",
       " u'88',\n",
       " u'89',\n",
       " u'90',\n",
       " u'91',\n",
       " u'92',\n",
       " u'93',\n",
       " u'94',\n",
       " u'95',\n",
       " u'96',\n",
       " u'97',\n",
       " u'98',\n",
       " u'99',\n",
       " u'100',\n",
       " u'101',\n",
       " u'102',\n",
       " u'103',\n",
       " u'104',\n",
       " u'105',\n",
       " u'106',\n",
       " u'107',\n",
       " u'108',\n",
       " u'109',\n",
       " u'110',\n",
       " u'111',\n",
       " u'112',\n",
       " u'113',\n",
       " u'114',\n",
       " u'115',\n",
       " u'116',\n",
       " u'117',\n",
       " u'118',\n",
       " u'119',\n",
       " u'120',\n",
       " u'121',\n",
       " u'122',\n",
       " u'123',\n",
       " u'124',\n",
       " u'125',\n",
       " u'126',\n",
       " u'127',\n",
       " u'128',\n",
       " u'129',\n",
       " u'130',\n",
       " u'131',\n",
       " u'132',\n",
       " u'133',\n",
       " u'134',\n",
       " u'135',\n",
       " u'136',\n",
       " u'137',\n",
       " u'138',\n",
       " u'139',\n",
       " u'140',\n",
       " u'141',\n",
       " u'142',\n",
       " u'143',\n",
       " u'144',\n",
       " u'145',\n",
       " u'146',\n",
       " u'147',\n",
       " u'148',\n",
       " u'149',\n",
       " u'150',\n",
       " u'151',\n",
       " u'152',\n",
       " u'153',\n",
       " u'154',\n",
       " u'155',\n",
       " u'156',\n",
       " u'157',\n",
       " u'158',\n",
       " u'159',\n",
       " u'160',\n",
       " u'161',\n",
       " u'162',\n",
       " u'163',\n",
       " u'164',\n",
       " u'165',\n",
       " u'166',\n",
       " u'167',\n",
       " u'168',\n",
       " u'169',\n",
       " u'170',\n",
       " u'171',\n",
       " u'172',\n",
       " u'173',\n",
       " u'174',\n",
       " u'175',\n",
       " u'176',\n",
       " u'177',\n",
       " u'178',\n",
       " u'179',\n",
       " u'180',\n",
       " u'181',\n",
       " u'182',\n",
       " u'183',\n",
       " u'184',\n",
       " u'185',\n",
       " u'186',\n",
       " u'187',\n",
       " u'188',\n",
       " u'189',\n",
       " u'190',\n",
       " u'191',\n",
       " u'192',\n",
       " u'193',\n",
       " u'194',\n",
       " u'195',\n",
       " u'196',\n",
       " u'197',\n",
       " u'198',\n",
       " u'199',\n",
       " u'200',\n",
       " u'201',\n",
       " u'202',\n",
       " u'203',\n",
       " u'204',\n",
       " u'205',\n",
       " u'206',\n",
       " u'207',\n",
       " u'208',\n",
       " u'209',\n",
       " u'210',\n",
       " u'211',\n",
       " u'212',\n",
       " u'213',\n",
       " u'214',\n",
       " u'215',\n",
       " u'216',\n",
       " u'217',\n",
       " u'218',\n",
       " u'219',\n",
       " u'220',\n",
       " u'221',\n",
       " u'222',\n",
       " u'223',\n",
       " u'224',\n",
       " u'225',\n",
       " u'226',\n",
       " u'227',\n",
       " u'228',\n",
       " u'229',\n",
       " u'230',\n",
       " u'231',\n",
       " u'232',\n",
       " u'233',\n",
       " u'234',\n",
       " u'235',\n",
       " u'236',\n",
       " u'237',\n",
       " u'238',\n",
       " u'239',\n",
       " u'240',\n",
       " u'241',\n",
       " u'242',\n",
       " u'243',\n",
       " u'244',\n",
       " u'245',\n",
       " u'246',\n",
       " u'247',\n",
       " u'248',\n",
       " u'249',\n",
       " u'250',\n",
       " u'251',\n",
       " u'252',\n",
       " u'253',\n",
       " u'254',\n",
       " u'255',\n",
       " u'256',\n",
       " u'257',\n",
       " u'258',\n",
       " u'259',\n",
       " u'260',\n",
       " u'261',\n",
       " u'262',\n",
       " u'263',\n",
       " u'264',\n",
       " u'265',\n",
       " u'266',\n",
       " u'267',\n",
       " u'268',\n",
       " u'269',\n",
       " u'270',\n",
       " u'271',\n",
       " u'272',\n",
       " u'273',\n",
       " u'274',\n",
       " u'275',\n",
       " u'276',\n",
       " u'277',\n",
       " u'278',\n",
       " u'279',\n",
       " u'280',\n",
       " u'281',\n",
       " u'282',\n",
       " u'283',\n",
       " u'284',\n",
       " u'285',\n",
       " u'286',\n",
       " u'287',\n",
       " u'288',\n",
       " u'289',\n",
       " u'290',\n",
       " u'291',\n",
       " u'292',\n",
       " u'293',\n",
       " u'294',\n",
       " u'295',\n",
       " u'296',\n",
       " u'297',\n",
       " u'298',\n",
       " u'299',\n",
       " u'300',\n",
       " u'301',\n",
       " u'302',\n",
       " u'303',\n",
       " u'304',\n",
       " u'305',\n",
       " u'306',\n",
       " u'307',\n",
       " u'308',\n",
       " u'309',\n",
       " u'310',\n",
       " u'311',\n",
       " u'312',\n",
       " u'313',\n",
       " u'314',\n",
       " u'315',\n",
       " u'316',\n",
       " u'317',\n",
       " u'318',\n",
       " u'319',\n",
       " u'320',\n",
       " u'321',\n",
       " u'322',\n",
       " u'323',\n",
       " u'324',\n",
       " u'325',\n",
       " u'326',\n",
       " u'327',\n",
       " u'328',\n",
       " u'329',\n",
       " u'330',\n",
       " u'331',\n",
       " u'332',\n",
       " u'333',\n",
       " u'334',\n",
       " u'335',\n",
       " u'336',\n",
       " u'337',\n",
       " u'338',\n",
       " u'339',\n",
       " u'340',\n",
       " u'341',\n",
       " u'342',\n",
       " u'343',\n",
       " u'344',\n",
       " u'345',\n",
       " u'346',\n",
       " u'347',\n",
       " u'348',\n",
       " u'349',\n",
       " u'350',\n",
       " u'351',\n",
       " u'352',\n",
       " u'353',\n",
       " u'354',\n",
       " u'355',\n",
       " u'356',\n",
       " u'357',\n",
       " u'358',\n",
       " u'359',\n",
       " u'360',\n",
       " u'361',\n",
       " u'362',\n",
       " u'363',\n",
       " u'364',\n",
       " u'365',\n",
       " u'366',\n",
       " u'367',\n",
       " u'368',\n",
       " u'369',\n",
       " u'370',\n",
       " u'371',\n",
       " u'372',\n",
       " u'373',\n",
       " u'374',\n",
       " u'375',\n",
       " u'376',\n",
       " u'377',\n",
       " u'378',\n",
       " u'379',\n",
       " u'380',\n",
       " u'381',\n",
       " u'382',\n",
       " u'383',\n",
       " u'384',\n",
       " u'385',\n",
       " u'386',\n",
       " u'387',\n",
       " u'388',\n",
       " u'389',\n",
       " u'390',\n",
       " u'391',\n",
       " u'392',\n",
       " u'393',\n",
       " u'394',\n",
       " u'395',\n",
       " u'396',\n",
       " u'397',\n",
       " u'398',\n",
       " u'399',\n",
       " u'400',\n",
       " u'401',\n",
       " u'402',\n",
       " u'403',\n",
       " u'404',\n",
       " u'405',\n",
       " u'406',\n",
       " u'407',\n",
       " u'408',\n",
       " u'409',\n",
       " u'410',\n",
       " u'411',\n",
       " u'412',\n",
       " u'413',\n",
       " u'414',\n",
       " u'415',\n",
       " u'416',\n",
       " u'417',\n",
       " u'418',\n",
       " u'419',\n",
       " u'420',\n",
       " u'421',\n",
       " u'422',\n",
       " u'423',\n",
       " u'424',\n",
       " u'425',\n",
       " u'426',\n",
       " u'427',\n",
       " u'428',\n",
       " u'429',\n",
       " u'430',\n",
       " u'431',\n",
       " u'432',\n",
       " u'433',\n",
       " u'434',\n",
       " u'435',\n",
       " u'436',\n",
       " u'437',\n",
       " u'438',\n",
       " u'439',\n",
       " u'440',\n",
       " u'441',\n",
       " u'442',\n",
       " u'443',\n",
       " u'444',\n",
       " u'445',\n",
       " u'446',\n",
       " u'447',\n",
       " u'448',\n",
       " u'449',\n",
       " u'450',\n",
       " u'451',\n",
       " u'452',\n",
       " u'453',\n",
       " u'454',\n",
       " u'455',\n",
       " u'456',\n",
       " u'457',\n",
       " u'458',\n",
       " u'459',\n",
       " u'460',\n",
       " u'461',\n",
       " u'462',\n",
       " u'463',\n",
       " u'464',\n",
       " u'465',\n",
       " u'466',\n",
       " u'467',\n",
       " u'468',\n",
       " u'469',\n",
       " u'470',\n",
       " u'471',\n",
       " u'472',\n",
       " u'473',\n",
       " u'474',\n",
       " u'475',\n",
       " u'476',\n",
       " u'477',\n",
       " u'478',\n",
       " u'479',\n",
       " u'480',\n",
       " u'481',\n",
       " u'482',\n",
       " u'483',\n",
       " u'484',\n",
       " u'485',\n",
       " u'486',\n",
       " u'487',\n",
       " u'488',\n",
       " u'489',\n",
       " u'490',\n",
       " u'491',\n",
       " u'492',\n",
       " u'493',\n",
       " u'494',\n",
       " u'495',\n",
       " u'496',\n",
       " u'497',\n",
       " u'498',\n",
       " u'499',\n",
       " u'500',\n",
       " u'501',\n",
       " u'502',\n",
       " u'503',\n",
       " u'504',\n",
       " u'505',\n",
       " u'506',\n",
       " u'507',\n",
       " u'508',\n",
       " u'509',\n",
       " u'510',\n",
       " u'511',\n",
       " u'512',\n",
       " u'513',\n",
       " u'514',\n",
       " u'515',\n",
       " u'516',\n",
       " u'517',\n",
       " u'518',\n",
       " u'519',\n",
       " u'520',\n",
       " u'521',\n",
       " u'522',\n",
       " u'523',\n",
       " u'524',\n",
       " u'525',\n",
       " u'526',\n",
       " u'527',\n",
       " u'528',\n",
       " u'529',\n",
       " u'530',\n",
       " u'531',\n",
       " u'532',\n",
       " u'533',\n",
       " u'534',\n",
       " u'535',\n",
       " u'536',\n",
       " u'537',\n",
       " u'538',\n",
       " u'539',\n",
       " u'540',\n",
       " u'541',\n",
       " u'542',\n",
       " u'543',\n",
       " u'544',\n",
       " u'545',\n",
       " u'546',\n",
       " u'547',\n",
       " u'548',\n",
       " u'549',\n",
       " u'550',\n",
       " u'551',\n",
       " u'552',\n",
       " u'553',\n",
       " u'554',\n",
       " u'555',\n",
       " u'556',\n",
       " u'557',\n",
       " u'558',\n",
       " u'559',\n",
       " u'560',\n",
       " u'561',\n",
       " u'562',\n",
       " u'563',\n",
       " u'564',\n",
       " u'565',\n",
       " u'566',\n",
       " u'567',\n",
       " u'568',\n",
       " u'569',\n",
       " u'570',\n",
       " u'571',\n",
       " u'572',\n",
       " u'573',\n",
       " u'574',\n",
       " u'575',\n",
       " u'576',\n",
       " u'577',\n",
       " u'578',\n",
       " u'579',\n",
       " u'580',\n",
       " u'581',\n",
       " u'582',\n",
       " u'583',\n",
       " u'584',\n",
       " u'585',\n",
       " u'586',\n",
       " u'587',\n",
       " u'588',\n",
       " u'589',\n",
       " u'590',\n",
       " u'591',\n",
       " u'592',\n",
       " u'593',\n",
       " u'594',\n",
       " u'595',\n",
       " u'596',\n",
       " u'597',\n",
       " u'598',\n",
       " u'599',\n",
       " u'600',\n",
       " u'601',\n",
       " u'602',\n",
       " u'603',\n",
       " u'604',\n",
       " u'605',\n",
       " u'606',\n",
       " u'607',\n",
       " u'608',\n",
       " u'609',\n",
       " u'610',\n",
       " u'611',\n",
       " u'612',\n",
       " u'613',\n",
       " u'614',\n",
       " u'615',\n",
       " u'616',\n",
       " u'617',\n",
       " u'618',\n",
       " u'619',\n",
       " u'620',\n",
       " u'621',\n",
       " u'622',\n",
       " u'623',\n",
       " u'624',\n",
       " u'625',\n",
       " u'626',\n",
       " u'627',\n",
       " u'628',\n",
       " u'629',\n",
       " u'630',\n",
       " u'631',\n",
       " u'632',\n",
       " u'633',\n",
       " u'634',\n",
       " u'635',\n",
       " u'636',\n",
       " u'637',\n",
       " u'638',\n",
       " u'639',\n",
       " u'640',\n",
       " u'641',\n",
       " u'642',\n",
       " u'643',\n",
       " u'644',\n",
       " u'645',\n",
       " u'646',\n",
       " u'647',\n",
       " u'648',\n",
       " u'649',\n",
       " u'650',\n",
       " u'651',\n",
       " u'652',\n",
       " u'653',\n",
       " u'654',\n",
       " u'655',\n",
       " u'656',\n",
       " u'657',\n",
       " u'658',\n",
       " u'659',\n",
       " u'660',\n",
       " u'661',\n",
       " u'662',\n",
       " u'663',\n",
       " u'664',\n",
       " u'665',\n",
       " u'666',\n",
       " u'667',\n",
       " u'668',\n",
       " u'669',\n",
       " u'670',\n",
       " u'671',\n",
       " u'672',\n",
       " u'673',\n",
       " u'674',\n",
       " u'675',\n",
       " u'676',\n",
       " u'677',\n",
       " u'678',\n",
       " u'679',\n",
       " u'680',\n",
       " u'681',\n",
       " u'682',\n",
       " u'683',\n",
       " u'684',\n",
       " u'685',\n",
       " u'686',\n",
       " u'687',\n",
       " u'688',\n",
       " u'689',\n",
       " u'690',\n",
       " u'691',\n",
       " u'692',\n",
       " u'693',\n",
       " u'694',\n",
       " u'695',\n",
       " u'696',\n",
       " u'697',\n",
       " u'698',\n",
       " u'699',\n",
       " u'700',\n",
       " u'701',\n",
       " u'702',\n",
       " u'703',\n",
       " u'704',\n",
       " u'705',\n",
       " u'706',\n",
       " u'707',\n",
       " u'708',\n",
       " u'709',\n",
       " u'710',\n",
       " u'711',\n",
       " u'712',\n",
       " u'713',\n",
       " u'714',\n",
       " u'715',\n",
       " u'716',\n",
       " u'717',\n",
       " u'718',\n",
       " u'719',\n",
       " u'720',\n",
       " u'721',\n",
       " u'722',\n",
       " u'723',\n",
       " u'724',\n",
       " u'725',\n",
       " u'726',\n",
       " u'727',\n",
       " u'728',\n",
       " u'729',\n",
       " u'730',\n",
       " u'731',\n",
       " u'732',\n",
       " u'733',\n",
       " u'734',\n",
       " u'735',\n",
       " u'736',\n",
       " u'737',\n",
       " u'738',\n",
       " u'739',\n",
       " u'740',\n",
       " u'741',\n",
       " u'742',\n",
       " u'743',\n",
       " u'744',\n",
       " u'745',\n",
       " u'746',\n",
       " u'747',\n",
       " u'748',\n",
       " u'749',\n",
       " u'750',\n",
       " u'751',\n",
       " u'752',\n",
       " u'753',\n",
       " u'754',\n",
       " u'755',\n",
       " u'756',\n",
       " u'757',\n",
       " u'758',\n",
       " u'759',\n",
       " u'760',\n",
       " u'761',\n",
       " u'762',\n",
       " u'763',\n",
       " u'764',\n",
       " u'765',\n",
       " u'766',\n",
       " u'767',\n",
       " u'768',\n",
       " u'769',\n",
       " u'770',\n",
       " u'771',\n",
       " u'772',\n",
       " u'773',\n",
       " u'774',\n",
       " u'775',\n",
       " u'776',\n",
       " u'777',\n",
       " u'778',\n",
       " u'779',\n",
       " u'780',\n",
       " u'781',\n",
       " u'782',\n",
       " u'783',\n",
       " u'784',\n",
       " u'785',\n",
       " u'786',\n",
       " u'787',\n",
       " u'788',\n",
       " u'789',\n",
       " u'790',\n",
       " u'791',\n",
       " u'792',\n",
       " u'793',\n",
       " u'794',\n",
       " u'795',\n",
       " u'796',\n",
       " u'797',\n",
       " u'798',\n",
       " u'799',\n",
       " u'800',\n",
       " u'801',\n",
       " u'802',\n",
       " u'803',\n",
       " u'804',\n",
       " u'805',\n",
       " u'806',\n",
       " u'807',\n",
       " u'808',\n",
       " u'809',\n",
       " u'810',\n",
       " u'811',\n",
       " u'812',\n",
       " u'813',\n",
       " u'814',\n",
       " u'815',\n",
       " u'816',\n",
       " u'817',\n",
       " u'818',\n",
       " u'819',\n",
       " u'820',\n",
       " u'821',\n",
       " u'822',\n",
       " u'823',\n",
       " u'824',\n",
       " u'825',\n",
       " u'826',\n",
       " u'827',\n",
       " u'828',\n",
       " u'829',\n",
       " u'830',\n",
       " u'831',\n",
       " u'832',\n",
       " u'833',\n",
       " u'834',\n",
       " u'835',\n",
       " u'836',\n",
       " u'837',\n",
       " u'838',\n",
       " u'839',\n",
       " u'840',\n",
       " u'841',\n",
       " u'842',\n",
       " u'843',\n",
       " u'844',\n",
       " u'845',\n",
       " u'846',\n",
       " u'847',\n",
       " u'848',\n",
       " u'849',\n",
       " u'850',\n",
       " u'851',\n",
       " u'852',\n",
       " u'853',\n",
       " u'854',\n",
       " u'855',\n",
       " u'856',\n",
       " u'857',\n",
       " u'858',\n",
       " u'859',\n",
       " u'860',\n",
       " u'861',\n",
       " u'862',\n",
       " u'863',\n",
       " u'864',\n",
       " u'865',\n",
       " u'866',\n",
       " u'867',\n",
       " u'868',\n",
       " u'869',\n",
       " u'870',\n",
       " u'871',\n",
       " u'872',\n",
       " u'873',\n",
       " u'874',\n",
       " u'875',\n",
       " u'876',\n",
       " u'877',\n",
       " u'878',\n",
       " u'879',\n",
       " u'880',\n",
       " u'881',\n",
       " u'882',\n",
       " u'883',\n",
       " u'884',\n",
       " u'885',\n",
       " u'886',\n",
       " u'887',\n",
       " u'888',\n",
       " u'889',\n",
       " u'890',\n",
       " u'891',\n",
       " u'892',\n",
       " u'893',\n",
       " u'894',\n",
       " u'895',\n",
       " u'896',\n",
       " u'897',\n",
       " u'898',\n",
       " u'899',\n",
       " u'900',\n",
       " u'901',\n",
       " u'902',\n",
       " u'903',\n",
       " u'904',\n",
       " u'905',\n",
       " u'906',\n",
       " u'907',\n",
       " u'908',\n",
       " u'909',\n",
       " u'910',\n",
       " u'911',\n",
       " u'912',\n",
       " u'913',\n",
       " u'914',\n",
       " u'915',\n",
       " u'916',\n",
       " u'917',\n",
       " u'918',\n",
       " u'919',\n",
       " u'920',\n",
       " u'921',\n",
       " u'922',\n",
       " u'923',\n",
       " u'924',\n",
       " u'925',\n",
       " u'926',\n",
       " u'927',\n",
       " u'928',\n",
       " u'929',\n",
       " u'930',\n",
       " u'931',\n",
       " u'932',\n",
       " u'933',\n",
       " u'934',\n",
       " u'935',\n",
       " u'936',\n",
       " u'937',\n",
       " u'938',\n",
       " u'939',\n",
       " u'940',\n",
       " u'941',\n",
       " u'942',\n",
       " u'943',\n",
       " u'944',\n",
       " u'945',\n",
       " u'946',\n",
       " u'947',\n",
       " u'948',\n",
       " u'949',\n",
       " u'950',\n",
       " u'951',\n",
       " u'952',\n",
       " u'953',\n",
       " u'954',\n",
       " u'955',\n",
       " u'956',\n",
       " u'957',\n",
       " u'958',\n",
       " u'959',\n",
       " u'960',\n",
       " u'961',\n",
       " u'962',\n",
       " u'963',\n",
       " u'964',\n",
       " u'965',\n",
       " u'966',\n",
       " u'967',\n",
       " u'968',\n",
       " u'969',\n",
       " u'970',\n",
       " u'971',\n",
       " u'972',\n",
       " u'973',\n",
       " u'974',\n",
       " u'975',\n",
       " u'976',\n",
       " u'977',\n",
       " u'978',\n",
       " u'979',\n",
       " u'980',\n",
       " u'981',\n",
       " u'982',\n",
       " u'983',\n",
       " u'984',\n",
       " u'985',\n",
       " u'986',\n",
       " u'987',\n",
       " u'988',\n",
       " u'989',\n",
       " u'990',\n",
       " u'991',\n",
       " u'992',\n",
       " u'993',\n",
       " u'994',\n",
       " u'995',\n",
       " u'996',\n",
       " u'997',\n",
       " u'998',\n",
       " u'999',\n",
       " u'1000',\n",
       " ...]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open (config_parameters['list_tiles'],'rb') as outputfile:\n",
    "    tile_aoi=pickle.load(outputfile)\n",
    "tile_aoi"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Get list of cat that are included in the shapefile with tiles to be processed\n",
    "import geopandas as gpd\n",
    "gdf = gpd.read_file(data['tiles'][1])\n",
    "tiles_aoi = list(gdf.cat)\n",
    "gdf = None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Keep only tiles number that are both exists in the folder containing all LC .tif files and included in the AOI to be processed\n",
    "#list_file = [(os.path.splitext(os.path.split(x)[-1])[0],x) for x in list_file if int(os.path.splitext(os.path.split(x)[-1])[0].split(\"_\")[-1]) in tiles_aoi]\n",
    "# Create list of cat to be processed\n",
    "list_cat = [x[0].split(\"_\")[-1] for x in list_file]\n",
    "print \"%s TIF files will be imported (contained in the AOI to be processed)\"%len(list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete existing raster from previous versions processings\n",
    "for rast in list_of_raster:\n",
    "    gscript.run_command('g.remove', flags='f', type='raster', name=rast[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import individual rasters (for each tile) --ERREUR\n",
    "start_import = start_processing()\n",
    "for rast in list_of_raster:\n",
    "    gscript.run_command('r.in.gdal', overwrite=True, input=rast[1] , output=rast[0])\n",
    "print_processing_time(start_import, \"Import achieved in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create virtual raster\n",
    "gscript.run_command('r.buildvrt', overwrite=True, \n",
    "                    input=\",\".join([a[0] for a in list_of_raster]), \n",
    "                    output='fusion_lc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply functions on each tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of cores to use\n",
    "ncores = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_cat=[]\n",
    "#for i in range(800,810):\n",
    "#    list_cat.append(str(i))\n",
    "list_cat = ['300','301','302','303','304','305','306','307','308','309','310','311','312','313','314','315','316','317','318','319','320','321','322','323','324']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Tiles interesecting Marche commune\n",
    "list_cat=['17']\n",
    "#list_cat=['39', '77', '79', '78', '97', '98', '96', '99', '100','115', '119', '116', '118', '117', '134', '135', '138', '136', '137', '153', '155', '154', '156', '157', '172', '173', '174', '175', '176', '177', '179', '178', '191', '192', '193', '194', '195', '196', '197', '198', '210', '211', '212', '213', '214', '216', '215', '229', '230', '231', '232', '233', '235', '234', '249', '250', '251', '252', '254', '253', '268', '269', '270', '272', '271', '274', '273', '287', '288', '289', '291', '290', '292', '293', '294', '295', '296', '297', '298', '306', '308', '307', '309', '311', '310', '312', '313', '314', '315', '316', '317', '325', '326', '328', '327', '329', '331', '330', '332', '333', '336', '334', '335', '345', '346', '347', '344', '348', '350', '351', '349', '352', '355', '353', '354', '362', '363', '365', '366', '364', '369', '367', '368', '371', '370', '372', '374', '373', '381', '383', '382', '384', '385', '386', '389', '387', '390', '388', '391', '392', '400', '402', '403', '401', '404', '405', '406', '408', '407', '409', '411', '410', '419', '420', '421', '422', '423', '424', '425', '426', '427', '429', '428', '438', '439', '440', '441', '443', '442', '445', '446', '444', '447', '448', '450', '451', '449', '452', '457', '458', '459', '460', '461', '462', '463', '464', '465', '466', '468', '467', '469', '470', '471', '476', '477', '478', '479', '480', '481', '482', '483', '484', '485', '486', '487', '488', '490', '489', '496', '497', '498', '499', '500', '502', '504', '503', '501', '505', '506', '510', '508', '509', '507', '515', '516', '517', '519', '518', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '534', '536', '537', '535', '538', '540', '539', '541', '542', '543', '545', '544', '546', '548', '547', '552', '553', '554', '555', '556', '557', '558', '559', '561', '560', '562', '563', '564', '565', '566', '568', '567', '571', '572', '573', '576', '575', '574', '577', '579', '578', '580', '581', '582', '584', '583', '585', '588', '586', '587', '590', '591', '594', '593', '592', '595', '596', '597', '598', '599', '600', '601', '602', '604', '603', '608', '605', '606', '607', '609', '610', '612', '611', '613', '614', '615', '616', '617', '618', '619', '620', '621', '622', '623', '624', '627', '625', '626', '628', '629', '630', '631', '632', '633', '634', '635', '636', '637', '638', '639', '640', '641', '642', '643', '644', '646', '645', '647', '648', '650', '649', '651', '652', '653', '655', '654', '656', '657', '658', '660', '659', '661', '662', '664', '666', '663', '667', '668', '671', '669', '670', '672', '673', '674', '675', '676', '677', '680', '681', '682', '683', '685', '686', '687', '688', '689', '690', '691', '694', '693', '695', '692', '700', '701', '702', '704', '705', '707', '706', '708', '709', '710', '713', '712', '711', '725', '724', '728', '726', '727', '730', '729', '731', '732', '743', '744', '745', '748', '747', '746', '750', '749', '751', '763', '764', '765', '768', '767', '766', '784', '785', '786', '805','834','835','836','837','838','801']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Test worker on one specific tile\n",
    "Worker(list_cat[list_cat.index(\"5293\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing on tile 300\n",
      "Start processing on tile 301\n",
      "Start processing on tile 302\n",
      "Start processing on tile 305\n",
      "Start processing on tile 306\n",
      "Start processing on tile 303\n",
      "Start processing on tile 307\n",
      "Start processing on tile 308\n",
      "Start processing on tile 310\n",
      "Start processing on tile 312\n",
      "Start processing on tile 311\n",
      "Start processing on tile 304\n",
      "Start processing on tile 314\n",
      "Start processing on tile 315\n",
      "Start processing on tile 309\n",
      "Start processing on tile 313\n",
      "Location 'WALOUS_31370' already exist\n",
      "'302' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/302'Location 'WALOUS_31370' already exist\n",
      "'301' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/301'\n",
      "\n",
      "Location 'WALOUS_31370' already exist\n",
      "'305' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/305'Location 'WALOUS_31370' already exist\n",
      "'300' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/300'Location 'WALOUS_31370' already exist\n",
      "'306' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/306'\n",
      "\n",
      "\n",
      "Location 'WALOUS_31370' already exist\n",
      "'307' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/307'\n",
      "Location 'WALOUS_31370' already exist\n",
      "'304' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/304'\n",
      "Location 'WALOUS_31370' already exist\n",
      "'314' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/314'Location 'WALOUS_31370' already exist\n",
      "'303' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/303'Location 'WALOUS_31370' already exist\n",
      "'310' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/310'Location 'WALOUS_31370' already exist\n",
      "'315' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/315'Location 'WALOUS_31370' already exist\n",
      "'312' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/312'\n",
      "Location 'WALOUS_31370' already exist\n",
      "'308' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/308'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Location 'WALOUS_31370' already exist\n",
      "'313' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/313'\n",
      "Access to other mapset added\n",
      "Access to other mapset added\n",
      "Access to other mapset added\n",
      "Location 'WALOUS_31370' already exist\n",
      "'309' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/309'Access to other mapset added\n",
      "\n",
      "Access to other mapset added\n",
      "Access to other mapset added\n",
      "Access to other mapset added\n",
      "Location 'WALOUS_31370' already exist\n",
      "'311' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/311'\n",
      "Access to other mapset added\n",
      "Access to other mapset added\n",
      "Access to other mapset added\n",
      "Access to other mapset added\n",
      "Access to other mapset added\n",
      "Access to other mapset added\n",
      "Access to other mapset added\n",
      "Access to other mapset added\n",
      "Access to other mapset added\n",
      "Working on tile '314'\n",
      "--> Setting of computational region and masks succeeded.Working on tile '302'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "\n",
      "Working on tile '312'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "Working on tile '311'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "Working on tile '303'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "Working on tile '308'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "Working on tile '310'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "Working on tile '309'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "Working on tile '307'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "Working on tile '301'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "Working on tile '300'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "Working on tile '305'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "Working on tile '304'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "Working on tile '306'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "Working on tile '315'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "Working on tile '313'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_302.gpkg\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_314.gpkg\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_312.gpkg\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_303.gpkg\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_309.gpkg\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_307.gpkg\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_311.gpkg\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_308.gpkg\n",
      "--> Export of vector succeeded.\n",
      "Start processing on tile 316\n",
      "Location 'WALOUS_31370' already exist\n",
      "'316' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/316'\n",
      "Access to other mapset added\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_301.gpkg\n",
      "--> Export of vector succeeded.\n",
      "Start processing on tile 317\n",
      "Location 'WALOUS_31370' already exist\n",
      "'317' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/317'\n",
      "Access to other mapset added\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_304.gpkg\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_310.gpkg\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_305.gpkg\n",
      "Working on tile '317'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "Working on tile '316'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_300.gpkg\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_306.gpkg\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_313.gpkg\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_315.gpkg\n",
      "--> Export of vector succeeded.\n",
      "Start processing on tile 318\n",
      "Location 'WALOUS_31370' already exist\n",
      "'318' mapset already exists in location 'WALOUS_31370'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are now working in mapset 'WALOUS_31370/318'\n",
      "Access to other mapset added\n",
      "Working on tile '318'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "--> Export of vector succeeded.\n",
      "Start processing on tile 319\n",
      "Location 'WALOUS_31370' already exist\n",
      "'319' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/319'\n",
      "Access to other mapset added\n",
      "Working on tile '319'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_318.gpkg\n",
      "--> Export of vector succeeded.\n",
      "Start processing on tile 320\n",
      "Location 'WALOUS_31370' already exist\n",
      "'320' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/320'\n",
      "Access to other mapset added\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_317.gpkg\n",
      "Working on tile '320'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "--> Export of vector succeeded.\n",
      "Start processing on tile 321\n",
      "Location 'WALOUS_31370' already exist\n",
      "'321' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/321'\n",
      "Access to other mapset added\n",
      "--> Export of vector succeeded.\n",
      "Start processing on tile 322\n",
      "Location 'WALOUS_31370' already exist\n",
      "'322' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/322'\n",
      "Access to other mapset added\n",
      "Working on tile '322'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "Working on tile '321'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "--> Export of vector succeeded.\n",
      "Start processing on tile 323\n",
      "Location 'WALOUS_31370' already exist\n",
      "'323' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/323'\n",
      "Access to other mapset added\n",
      "Working on tile '323'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_316.gpkg\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_322.gpkg\n",
      "--> Export of vector succeeded.\n",
      "Start processing on tile 324\n",
      "Location 'WALOUS_31370' already exist\n",
      "'324' mapset already exists in location 'WALOUS_31370'\n",
      "You are now working in mapset 'WALOUS_31370/324'\n",
      "Access to other mapset added\n",
      "Working on tile '324'\n",
      "--> Setting of computational region and masks succeeded.\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_320.gpkg\n",
      "--> Export of vector succeeded.\n",
      "--> Export of vector succeeded.\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_324.gpkg\n",
      "--> Export of vector succeeded.\n",
      "--> Export of vector succeeded.\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_319.gpkg\n",
      "--> Export of vector succeeded.\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_323.gpkg\n",
      "--> Vectorization succeeded.\n",
      "vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect\n",
      "/export/miro/cbassine/fusion/RF_fusion/Postprocess6/Vecteur/vect/LC_vect_tile_321.gpkg\n",
      "--> Export of vector succeeded.\n",
      "--> Export of vector succeeded.\n",
      "--> Export of vector succeeded.\n",
      "--> Export of vector succeeded.\n",
      "--> Export of vector succeeded.\n",
      "--> Export of vector succeeded.\n",
      "--> Export of vector succeeded.\n",
      "--> Export of vector succeeded.\n",
      "--> Export of vector succeeded.\n",
      "--> Export of vector succeeded.\n",
      "--> Export of vector succeeded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Computation (on 16 cores) achieved in 36 minutes and 24.8 seconds'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch processes in parallel\n",
    "start_parallel = start_processing()\n",
    "p = Pool(ncores)\n",
    "#output = p.map(Worker, tile_list[1:2])  # Launch the processes for as many items in the list (if function with a return, the returned results are ordered thanks to 'map' function)\n",
    "output=p.map(Worker, list_cat[:])\n",
    "p.close()\n",
    "p.join()\n",
    "# Print\n",
    "print_processing_time(start_parallel, \"Computation (on %s cores) achieved in \"%ncores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check log file for ERRORS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810 log files in the folder\n"
     ]
    }
   ],
   "source": [
    "# Get list of csv with classification feature of individual tiles\n",
    "import glob\n",
    "list_log = glob.glob(os.path.join(config_parameters['outputfolder_Logfile'],\"Log_Prediction_tile_*.txt\"))\n",
    "print \"%s log files in the folder\"%len(list_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374 tile(s) faced an ERROR during the processing.\n",
      "\n",
      "Error on tile 3\n",
      "Error on tile 10\n",
      "Error on tile 9\n",
      "Error on tile 6\n",
      "Error on tile 7\n",
      "Error on tile 8\n",
      "Error on tile 4\n",
      "Error on tile 5\n",
      "Error on tile 1\n",
      "Error on tile 144\n",
      "Error on tile 145\n",
      "Error on tile 146\n",
      "Error on tile 147\n",
      "Error on tile 148\n",
      "Error on tile 64\n",
      "Error on tile 128\n",
      "Error on tile 149\n",
      "Error on tile 16\n",
      "Error on tile 65\n",
      "Error on tile 32\n",
      "Error on tile 160\n",
      "Error on tile 208\n",
      "Error on tile 48\n",
      "Error on tile 112\n",
      "Error on tile 129\n",
      "Error on tile 130\n",
      "Error on tile 150\n",
      "Error on tile 80\n",
      "Error on tile 131\n",
      "Error on tile 224\n",
      "Error on tile 132\n",
      "Error on tile 133\n",
      "Error on tile 134\n",
      "Error on tile 135\n",
      "Error on tile 240\n",
      "Error on tile 136\n",
      "Error on tile 137\n",
      "Error on tile 138\n",
      "Error on tile 17\n",
      "Error on tile 139\n",
      "Error on tile 140\n",
      "Error on tile 33\n",
      "Error on tile 141\n",
      "Error on tile 142\n",
      "Error on tile 143\n",
      "Error on tile 151\n",
      "Error on tile 161\n",
      "Error on tile 225\n",
      "Error on tile 209\n",
      "Error on tile 66\n",
      "Error on tile 81\n",
      "Error on tile 152\n",
      "Error on tile 49\n",
      "Error on tile 34\n",
      "Error on tile 241\n",
      "Error on tile 113\n",
      "Error on tile 18\n",
      "Error on tile 162\n",
      "Error on tile 256\n",
      "Error on tile 67\n",
      "Error on tile 82\n",
      "Error on tile 163\n",
      "Error on tile 257\n",
      "Error on tile 180\n",
      "Error on tile 226\n",
      "Error on tile 242\n",
      "Error on tile 50\n",
      "Error on tile 19\n",
      "Error on tile 114\n",
      "Error on tile 68\n",
      "Error on tile 227\n",
      "Error on tile 258\n",
      "Error on tile 164\n",
      "Error on tile 51\n",
      "Error on tile 243\n",
      "Error on tile 83\n",
      "Error on tile 35\n",
      "Error on tile 259\n",
      "Error on tile 181\n",
      "Error on tile 69\n",
      "Error on tile 52\n",
      "Error on tile 165\n",
      "Error on tile 228\n",
      "Error on tile 244\n",
      "Error on tile 53\n",
      "Error on tile 36\n",
      "Error on tile 84\n",
      "Error on tile 166\n",
      "Error on tile 260\n",
      "Error on tile 70\n",
      "Error on tile 245\n",
      "Error on tile 182\n",
      "Error on tile 22\n",
      "Error on tile 71\n",
      "Error on tile 54\n",
      "Error on tile 167\n",
      "Error on tile 23\n",
      "Error on tile 72\n",
      "Error on tile 261\n",
      "Error on tile 37\n",
      "Error on tile 168\n",
      "Error on tile 85\n",
      "Error on tile 101\n",
      "Error on tile 55\n",
      "Error on tile 158\n",
      "Error on tile 246\n",
      "Error on tile 183\n",
      "Error on tile 11\n",
      "Error on tile 169\n",
      "Error on tile 38\n",
      "Error on tile 184\n",
      "Error on tile 56\n",
      "Error on tile 120\n",
      "Error on tile 159\n",
      "Error on tile 86\n",
      "Error on tile 12\n",
      "Error on tile 247\n",
      "Error on tile 262\n",
      "Error on tile 73\n",
      "Error on tile 170\n",
      "Error on tile 199\n",
      "Error on tile 57\n",
      "Error on tile 24\n",
      "Error on tile 185\n",
      "Error on tile 13\n",
      "Error on tile 248\n",
      "Error on tile 171\n",
      "Error on tile 263\n",
      "Error on tile 200\n",
      "Error on tile 74\n",
      "Error on tile 186\n",
      "Error on tile 121\n",
      "Error on tile 87\n",
      "Error on tile 25\n",
      "Error on tile 14\n",
      "Error on tile 58\n",
      "Error on tile 187\n",
      "Error on tile 122\n",
      "Error on tile 102\n",
      "Error on tile 59\n",
      "Error on tile 26\n",
      "Error on tile 75\n",
      "Error on tile 15\n",
      "Error on tile 88\n",
      "Error on tile 40\n",
      "Error on tile 264\n",
      "Error on tile 123\n",
      "Error on tile 188\n",
      "Error on tile 27\n",
      "Error on tile 103\n",
      "Error on tile 201\n",
      "Error on tile 76\n",
      "Error on tile 265\n",
      "Error on tile 124\n",
      "Error on tile 60\n",
      "Error on tile 189\n",
      "Error on tile 89\n",
      "Error on tile 28\n",
      "Error on tile 202\n",
      "Error on tile 266\n",
      "Error on tile 41\n",
      "Error on tile 125\n",
      "Error on tile 104\n",
      "Error on tile 304\n",
      "Error on tile 61\n",
      "Error on tile 90\n",
      "Error on tile 42\n",
      "Error on tile 275\n",
      "Error on tile 29\n",
      "Error on tile 126\n",
      "Error on tile 190\n",
      "Error on tile 203\n",
      "Error on tile 217\n",
      "Error on tile 43\n",
      "Error on tile 105\n",
      "Error on tile 91\n",
      "Error on tile 62\n",
      "Error on tile 127\n",
      "Error on tile 276\n",
      "Error on tile 44\n",
      "Error on tile 305\n",
      "Error on tile 218\n",
      "Error on tile 267\n",
      "Error on tile 63\n",
      "Error on tile 204\n",
      "Error on tile 219\n",
      "Error on tile 30\n",
      "Error on tile 236\n",
      "Error on tile 45\n",
      "Error on tile 320\n",
      "Error on tile 92\n",
      "Error on tile 106\n",
      "Error on tile 31\n",
      "Error on tile 277\n",
      "Error on tile 46\n",
      "Error on tile 255\n",
      "Error on tile 337\n",
      "Error on tile 237\n",
      "Error on tile 278\n",
      "Error on tile 220\n",
      "Error on tile 205\n",
      "Error on tile 47\n",
      "Error on tile 93\n",
      "Error on tile 321\n",
      "Error on tile 322\n",
      "Error on tile 338\n",
      "Error on tile 238\n",
      "Error on tile 279\n",
      "Error on tile 221\n",
      "Error on tile 206\n",
      "Error on tile 94\n",
      "Error on tile 416\n",
      "Error on tile 339\n",
      "Error on tile 323\n",
      "Error on tile 239\n",
      "Error on tile 340\n",
      "Error on tile 107\n",
      "Error on tile 324\n",
      "Error on tile 222\n",
      "Error on tile 95\n",
      "Error on tile 207\n",
      "Error on tile 432\n",
      "Error on tile 280\n",
      "Error on tile 417\n",
      "Error on tile 433\n",
      "Error on tile 341\n",
      "Error on tile 434\n",
      "Error on tile 356\n",
      "Error on tile 281\n",
      "Error on tile 223\n",
      "Error on tile 342\n",
      "Error on tile 108\n",
      "Error on tile 282\n",
      "Error on tile 435\n",
      "Error on tile 418\n",
      "Error on tile 343\n",
      "Error on tile 357\n",
      "Error on tile 109\n",
      "Error on tile 358\n",
      "Error on tile 436\n",
      "Error on tile 283\n",
      "Error on tile 110\n",
      "Error on tile 284\n",
      "Error on tile 359\n",
      "Error on tile 437\n",
      "Error on tile 299\n",
      "Error on tile 360\n",
      "Error on tile 375\n",
      "Error on tile 453\n",
      "Error on tile 285\n",
      "Error on tile 111\n",
      "Error on tile 361\n",
      "Error on tile 376\n",
      "Error on tile 454\n",
      "Error on tile 512\n",
      "Error on tile 300\n",
      "Error on tile 377\n",
      "Error on tile 455\n",
      "Error on tile 318\n",
      "Error on tile 286\n",
      "Error on tile 378\n",
      "Error on tile 456\n",
      "Error on tile 301\n",
      "Error on tile 513\n",
      "Error on tile 379\n",
      "Error on tile 319\n",
      "Error on tile 514\n",
      "Error on tile 380\n",
      "Error on tile 302\n",
      "Error on tile 303\n",
      "Error on tile 491\n",
      "Error on tile 530\n",
      "Error on tile 492\n",
      "Error on tile 531\n",
      "Error on tile 472\n",
      "Error on tile 493\n",
      "Error on tile 393\n",
      "Error on tile 532\n",
      "Error on tile 549\n",
      "Error on tile 394\n",
      "Error on tile 494\n",
      "Error on tile 473\n",
      "Error on tile 395\n",
      "Error on tile 495\n",
      "Error on tile 533\n",
      "Error on tile 430\n",
      "Error on tile 474\n",
      "Error on tile 396\n",
      "Error on tile 397\n",
      "Error on tile 475\n",
      "Error on tile 569\n",
      "Error on tile 550\n",
      "Error on tile 412\n",
      "Error on tile 570\n",
      "Error on tile 398\n",
      "Error on tile 399\n",
      "Error on tile 431\n",
      "Error on tile 413\n",
      "Error on tile 414\n",
      "Error on tile 551\n",
      "Error on tile 415\n",
      "Error on tile 720\n",
      "Error on tile 721\n",
      "Error on tile 736\n",
      "Error on tile 511\n",
      "Error on tile 678\n",
      "Error on tile 722\n",
      "Error on tile 665\n",
      "Error on tile 737\n",
      "Error on tile 679\n",
      "Error on tile 723\n",
      "Error on tile 752\n",
      "Error on tile 753\n",
      "Error on tile 738\n",
      "Error on tile 589\n",
      "Error on tile 800\n",
      "Error on tile 769\n",
      "Error on tile 754\n",
      "Error on tile 755\n",
      "Error on tile 756\n",
      "Error on tile 787\n",
      "Error on tile 770\n",
      "Error on tile 757\n",
      "Error on tile 696\n",
      "Error on tile 802\n",
      "Error on tile 739\n",
      "Error on tile 771\n",
      "Error on tile 788\n",
      "Error on tile 758\n",
      "Error on tile 697\n",
      "Error on tile 803\n",
      "Error on tile 772\n",
      "Error on tile 698\n",
      "Error on tile 789\n",
      "Error on tile 740\n",
      "Error on tile 759\n",
      "Error on tile 804\n",
      "Error on tile 790\n",
      "Error on tile 773\n",
      "Error on tile 684\n",
      "Error on tile 760\n",
      "Error on tile 774\n",
      "Error on tile 741\n",
      "Error on tile 791\n",
      "Error on tile 761\n",
      "Error on tile 775\n",
      "Error on tile 714\n",
      "Error on tile 792\n",
      "Error on tile 742\n",
      "Error on tile 762\n",
      "Error on tile 776\n",
      "Error on tile 715\n",
      "Error on tile 793\n",
      "Error on tile 703\n",
      "Error on tile 777\n",
      "Error on tile 716\n",
      "Error on tile 794\n",
      "Error on tile 717\n",
      "Error on tile 778\n",
      "Error on tile 779\n",
      "Error on tile 795\n",
      "Error on tile 733\n",
      "Error on tile 796\n",
      "Error on tile 780\n",
      "Error on tile 718\n",
      "Error on tile 734\n",
      "Error on tile 797\n",
      "Error on tile 735\n",
      "Error on tile 798\n",
      "Error on tile 781\n",
      "Error on tile 799\n",
      "Error on tile 719\n",
      "Error on tile 782\n",
      "Error on tile 783\n"
     ]
    }
   ],
   "source": [
    "# Declare new counter\n",
    "count = 0\n",
    "# Declare new list that will contain list of tile with error\n",
    "tile_error_list = []\n",
    "# Loop on list of log file\n",
    "for logfile in list_log:\n",
    "    got_error = False\n",
    "    tile_num = os.path.splitext(os.path.basename(logfile))[0].split(\"_\")[-1]\n",
    "    fin = open(logfile, 'r')\n",
    "    for row in fin:\n",
    "        if row[:5] == \"ERROR\":  # If at least one line have error message, the whole file will be counted as 1 error\n",
    "            got_error = True\n",
    "    if got_error:    \n",
    "        count += 1\n",
    "        tile_error_list.append(tile_num)  # Add tile number to the list\n",
    "# Print\n",
    "print \"%s tile(s) faced an ERROR during the processing.\\n\"%count\n",
    "\n",
    "# Update tile list with only tiles that have ERROR in log \n",
    "print \"\\n\".join([\"Error on tile %s\"%(a) for a in tile_error_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create VRT with all raster products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create mapset \n",
    "launch_mapset(\"POSTPROCESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add access to other mapsets\n",
    "GetMapsetsAccess([\"%s\"%cat for cat in list_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate VRT\n",
    "gscript.run_command('r.buildvrt', overwrite=True, \n",
    "                    input=\",\".join([\"forestmask_binary@%s\"%cat for cat in list_cat]), \n",
    "                    output='forestmask_binary_vrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate VRT\n",
    "gscript.run_command('r.buildvrt', overwrite=True, \n",
    "                    input=\",\".join([\"resamp@%s\"%cat for cat in list_cat]), \n",
    "                    output='resamp_vrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate VRT\n",
    "gscript.run_command('r.buildvrt', overwrite=True, \n",
    "                    input=\",\".join([\"reclass_tmp@%s\"%cat for cat in list_cat]), \n",
    "                    output='reclass_tmp_vrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate VRT\n",
    "gscript.run_command('r.buildvrt', overwrite=True, \n",
    "                    input=\",\".join([\"resamp_mmu@%s\"%cat for cat in list_cat]), \n",
    "                    output='resamp_mmu_vrt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract vectorial outputs at the 'commune' level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import layers for the whole wallonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run ../SRC/config_postprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapset \n",
    "launch_mapset(\"PERMANENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Communes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import vector layer of the belgian communes\n",
    "gscript.run_command('v.import', overwrite=True, \n",
    "                    epsg='31370', input=data['communes'][1], output=data['communes'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of communes ID\n",
    "list_com = [code \n",
    "            for code \n",
    "            in gscript.read_command('v.db.select', flags='c', map=data['communes'][0], columns='cd_munty_r').split('\\n') \n",
    "            if len(code)>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cadastral blocks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import vector layer of the belgian communes\n",
    "gscript.run_command('v.import', overwrite=True, \n",
    "                    epsg='3812', input=data['CaPa'][1], output=data['CaPa'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract LC proportion by CaPa for each commune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of communes ID intersecting MARCHE area\n",
    "list_com = ['61012','83012','83028','83034','83040','91030','91064','91120']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define region based on the 1m spatial resolution raster LC output\n",
    "g.region raster=clip_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.to.rast --overwrite input=CaPa output=CaPa use=attr attribute_column=cat label_column=CaPaKey memory=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract polygons for each 'commune'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.db.addcolumn map=test_overlay@3219 columns=\"class integer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.db.update map=test_overlay@3219 column=class query_column=a_class where=\"b_class is null\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.db.update map=test_overlay@3219 column=class query_column=a_class where=\"(a_class is not null) AND (b_class is not null) \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.dissolve input=test_overlay@3219 column=class output=test_dissolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
